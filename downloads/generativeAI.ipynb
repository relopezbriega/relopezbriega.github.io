{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89da3202-39dc-4b14-819e-6c26c0eb2703",
   "metadata": {},
   "source": [
    "# Modelos Generativos de Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bb091d-dbbc-4ead-9d47-31e195bb5600",
   "metadata": {},
   "source": [
    "*Esta notebook fue creada originalmente como un blog post por [Raúl E. López Briega](https://relopezbriega.github.io/cv/) en [Matemáticas, Analisis de datos y Python](https://relopezbriega.github.io). El contenido esta bajo la licencia BSD.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd28132-1022-4860-89de-bc7b38507f6a",
   "metadata": {},
   "source": [
    "<img alt=\"Modelos generativos de Deep Learning\" title=\"Modelos generativos de Deep Learning\" src=\"https://relopezbriega.github.io/images/generativeIA.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e4366-7cf9-4de5-afe0-af62d662d02b",
   "metadata": {},
   "source": [
    "\n",
    "> Los modelos generativos son un facilitador clave de la creatividad de las máquinas, ya que les permiten ir más allá de lo que han visto antes y crear algo nuevo.\n",
    "\n",
    "**[Ian Goodfellow](https://en.wikipedia.org/wiki/Ian_Goodfellow)**\n",
    "\n",
    "## El arte de crear: Modelos generativos de deep learning\n",
    "\n",
    "La [inteligencia artificial](https://relopezbriega.github.io/blog/2017/06/05/introduccion-a-la-inteligencia-artificial/) ha evolucionado rápidamente en los últimos años, y uno de los campos más emocionantes es el de los [modelos generativos](https://es.wikipedia.org/wiki/Inteligencia_artificial_generativa). Desde crear imágenes hiperrealistas hasta generar textos que parecen escritos por humanos, los [modelos generativos](https://es.wikipedia.org/wiki/Inteligencia_artificial_generativa) de [deep learning](https://relopezbriega.github.io/blog/2017/06/13/introduccion-al-deep-learning/) están transformando industrias enteras. Pero, ¿qué hay detrás de esta magia? En artículo, exploraremos las técnicas más populares, cómo funcionan y cómo empezar a usarlas en tus propios proyectos.\n",
    "\n",
    "## Modelos generativos: Qué son y por qué importan\n",
    "\n",
    "Los [modelos generativos](https://es.wikipedia.org/wiki/Inteligencia_artificial_generativa) son un tipo de [red neuronal](https://relopezbriega.github.io/blog/2016/08/02/redes-neuronales-convolucionales-con-tensorflow/) diseñada para crear nuevos datos que imitan un conjunto de datos existente. A diferencia de los [modelos discriminativos](https://en.wikipedia.org/wiki/Discriminative_model), que predicen etiquetas o categorizan resultados, los [modelos generativos](https://es.wikipedia.org/wiki/Inteligencia_artificial_generativa) producen algo nuevo. \n",
    "\n",
    "Por ejemplo, si entrenas un [modelo generativo](https://es.wikipedia.org/wiki/Inteligencia_artificial_generativa) con miles de imágenes de paisajes, puede generar paisajes que nunca antes existieron. Esta capacidad los hace especialmente valiosos en campos como el diseño gráfico, la música, el cine y la investigación científica. Y también es la responsable de la proliferación de imáges, videos y audios falsos generados por computadora que inundaron internet.\n",
    "\n",
    "## El papel de los autoencoders: Aprender a reconstruir\n",
    "\n",
    "Uno de los [modelos generativos](https://es.wikipedia.org/wiki/Inteligencia_artificial_generativa) más simples y efectivos es el [autoencoder](https://es.wikipedia.org/wiki/Autocodificador). Este modelo aprende a comprimir datos en una representación más pequeña (codificador) y luego reconstruirlos (decodificador). Al hacerlo, el [autoencoder](https://es.wikipedia.org/wiki/Autocodificador) *aprende* las características más importantes de los datos. Veamos un pequeño ejemplo en [Python](https://www.python.org/) de un [autoencoder](https://es.wikipedia.org/wiki/Autocodificador) simple para comprimir y reconstruir imágenes en escala de grises.\n",
    "\n",
    "### Ejemplo en Python:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ec03f4-d64b-4302-a878-aadb17dbc1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6946  \n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6931 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6931 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6931 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6931 \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6931 \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6931 \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6930 \n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6930\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6930 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a4730299370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "input_data = Input(shape=(784,))\n",
    "codificado = Dense(32, activation='relu')(input_data)\n",
    "decodificado = Dense(784, activation='sigmoid')(codificado)\n",
    "\n",
    "autoencoder = Model(input_data, decodificado)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Generamos datos de ejemplo y entrenamos el autoenconder.\n",
    "data = np.random.rand(1000, 784)\n",
    "autoencoder.fit(data, data, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8805614-7b30-4a48-a487-a497f7a5854d",
   "metadata": {},
   "source": [
    "## GAN: Competencia que genera creatividad\n",
    "\n",
    "Las [Generative Adversarial Networks (GAN)](https://es.wikipedia.org/wiki/Red_generativa_adversativa) han revolucionado la generación de imágenes. Una [GAN](https://es.wikipedia.org/wiki/Red_generativa_adversativa) consta de dos redes: un generador y un discriminador. El generador crea datos falsos mientras que el discriminador intenta distinguir entre datos reales y falsos. A medida que entrenan, ambos modelos mejoran. Las GANs son extremadamente potentes y se utilizan para crear imágenes fotorrealistas de personas, animales y paisajes. Veamos como podemos implementarlas en [Python](https://www.python.org/) utilizando [TensoFlow](https://www.tensorflow.org/?hl=es-419).\n",
    "\n",
    "### Ejemplo simple de GAN en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e36f9ee4-3976-4936-858a-5343802afb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Construcción del generador\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128, input_dim=100))\n",
    "generator.add(LeakyReLU(alpha=0.01))\n",
    "generator.add(Dense(784, activation='sigmoid'))\n",
    "\n",
    "# Construcción del discriminador\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Dense(128, input_dim=784))\n",
    "discriminator.add(LeakyReLU(alpha=0.01))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilamos el discriminador\n",
    "discriminator.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf2826c-0e16-4906-882f-ba2bfa74964f",
   "metadata": {},
   "source": [
    "## Transformers: El motor del texto generativo\n",
    "\n",
    "Los [transformers](https://es.wikipedia.org/wiki/Transformador_(modelo_de_aprendizaje_autom%C3%A1tico)) han dominado el campo del [procesamiento de lenguaje natural (NLP)](https://relopezbriega.github.io/blog/2017/09/23/procesamiento-del-lenguaje-natural-con-python/). Modelos como [GPT (Generative Pre-trained Transformer)](https://es.wikipedia.org/wiki/GPT-4) utilizan una arquitectura basada en [atención (attention)](https://es.wikipedia.org/wiki/Atenci%C3%B3n_(aprendizaje_autom%C3%A1tico)) para generar texto con coherencia y relevancia prácticamente indestinguible de un texto generado por humanos. Es la magia detrás del popular [chatGPT](https://chatgpt.com/). \n",
    "\n",
    "## Atención: Foco en lo importante\n",
    "\n",
    "La [atención (attention)](https://es.wikipedia.org/wiki/Atenci%C3%B3n_(aprendizaje_autom%C3%A1tico)) es el mecanismo clave detrás de [transformers](https://es.wikipedia.org/wiki/Transformador_(modelo_de_aprendizaje_autom%C3%A1tico)). Permite que el modelo se centre en las partes más relevantes de una secuencia, lo que mejora drásticamente no solo la performance en el *entrenamiento* del modelo sino también la capacidad del modelo para entender contextos complejos.\n",
    "\n",
    "Este mecanismo ha permitido a los [transformers](https://es.wikipedia.org/wiki/Transformador_(modelo_de_aprendizaje_autom%C3%A1tico)) sobresalir en tareas de traducción, resúmenes automáticos y generación de texto.\n",
    "\n",
    "Veamos ahora un ejemplo sencillo de un [transformer](https://es.wikipedia.org/wiki/Transformador_(modelo_de_aprendizaje_autom%C3%A1tico))  utilizando el modelo GPT2.\n",
    "\n",
    "### Ejemplo de generación de texto con transformers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574ab1c2-cd86-4454-8b82-abf36c99d9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Device set to use 0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Once upon a time there was a robot that learned that there would be something in the desert, and that was that. On that same time, there came a little bit of an odd side of them. They had an older brother who went somewhere and'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "result = generator('Once upon a time there was a robot that learned', max_length=50)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b6fd13-f197-419f-aaba-8e4f6448ab74",
   "metadata": {},
   "source": [
    "Como vemos, con solo unas pocas líneas de código, puedemos generar texto convincente que continúa una historia. Obviamente, como estamos trabajando con un modelo más simple como GPT2 no vamos a obtener los sorprendentes resultados que muestran los modelos más populares.\n",
    "\n",
    "\n",
    "## LLMs: Grandes modelos para grandes ideas\n",
    "\n",
    "Los [Large Language Models (LLM)](https://es.wikipedia.org/wiki/Modelo_extenso_de_lenguaje) como [GPT-4](https://es.wikipedia.org/wiki/GPT-4) son una evolución de los transformers. Estos modelos se entrenan con enormes cantidades de datos y pueden realizar tareas de generación de texto, programación, y traducción automática.\n",
    "\n",
    "Estos modelos están impulsando innovaciones en multiples aréas como: atención al cliente, creación de contenido y automatización de tareas repetitivas.\n",
    "\n",
    "## Retrieval-Augmented Generation (RAG): Potenciando la generación con datos externos\n",
    "\n",
    "[Retrieval-Augmented Generation (RAG)](https://en.wikipedia.org/wiki/Retrieval-augmented_generation) combina la generación de texto con la recuperación de [información](https://relopezbriega.github.io/blog/2018/03/30/introduccion-a-la-teoria-de-la-informacion-con-python/) de bases de datos o documentos. Esto permite que el modelo acceda a información externa, mejorando la precisión y relevancia del texto generado. [RAG](https://en.wikipedia.org/wiki/Retrieval-augmented_generation) es especialmente útil en aplicaciones donde la información cambia constantemente o es demasiado extensa para almacenarla en el modelo.\n",
    "\n",
    "## Fine-Tuning: Personalizando modelos generativos\n",
    "\n",
    "El [fine-tuning](https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)) consiste en ajustar un modelo preentrenado con datos específicos para mejorar su rendimiento en tareas concretas. Esta técnica es común en [LLMs]((https://es.wikipedia.org/wiki/Modelo_extenso_de_lenguaje)) y [transformers](https://es.wikipedia.org/wiki/Transformador_(modelo_de_aprendizaje_autom%C3%A1tico)) para personalizar sus capacidades a distintos dominios. Al *afinar* el modelo con datos relevantes, se logran resultados más precisos y adaptados a necesidades particulares.\n",
    "\n",
    "## Multimodalidad: Más allá del texto\n",
    "\n",
    "Los modelos generativos también están adoptando enfoques multimodales. Esto significa que pueden manejar múltiples tipos de datos como texto, imagen y audio de manera simultánea; lo que incrementa las posibilidades de las cosas que estos modelos pueden hacer.\n",
    "\n",
    "## Conclusion: Futuro de los modelos generativos\n",
    "\n",
    "A medida que los modelos generativos se vuelven más avanzados, veremos aplicaciones más sorprendentes. La integración de [LLMs]((https://es.wikipedia.org/wiki/Modelo_extenso_de_lenguaje)) y [transformers](https://es.wikipedia.org/wiki/Transformador_(modelo_de_aprendizaje_autom%C3%A1tico)) en dispositivos personales podría revolucionar la forma en que interactuamos con la tecnología. Estos modelos ya están teniendo un gran impacto hoy en día y se espera que su influencia continue creciendo, impacto en cada vez más áreas de nuestra vida cotidiana. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97d16e-d0e1-4f85-b4d3-6adbbc2ca957",
   "metadata": {},
   "source": [
    "Saludos!\n",
    "\n",
    "*Este post fue escrito por [Raúl e. López Briega](https://relopezbriega.github.io/) utilizando [Jupyter notebook](https://jupyter.org/). Pueden descargar este [notebook](https://github.com/relopezbriega/relopezbriega.github.io/blob/master/downloads/generativeAI.ipynb) o ver su version estática en [nbviewer](https://nbviewer.ipython.org/github/relopezbriega/relopezbriega.github.io/blob/master/downloads/generativeAI.ipynb).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
