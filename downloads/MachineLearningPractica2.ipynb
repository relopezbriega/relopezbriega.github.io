{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de Machine Learning con Python - Selección de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Esta notebook fue creada originalmente como un blog post por [Raúl E. López Briega](http://relopezbriega.com.ar/) en [Matemáticas, Analisis de datos y Python](http://relopezbriega.github.io). El contenido esta bajo la licencia BSD.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Machine Learning\" title=\"Machine Learning\" src=\"http://relopezbriega.github.io/images/machine-learning.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Continuando donde nos quedamos en el artículo anterior [Ejemplo de Machine Learning - preprocesamiento y exploración](http://relopezbriega.github.io/blog/2016/04/08/ejemplo-de-machine-learning-con-python-preprocesamiento-y-exploracion/); ahora es tiempo de ingresar en el terreno de la [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection).\n",
    "\n",
    "\n",
    "## ¿En qué consiste la selección de atributos?\n",
    "\n",
    "La [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection) es el proceso por el cual seleccionamos un subconjunto de atributos (representados por cada una de las columnas en un [dataset](https://es.wikipedia.org/wiki/Conjunto_de_datos) de forma tabular) que son más relevantes para la construcción del modelo predictivo sobre el que estamos trabajando. \n",
    "\n",
    "Este proceso, no se debe confundir con el de [reducción de dimensiones](https://en.wikipedia.org/wiki/Dimensionality_reduction); si bien ambos procesos buscan reducir el número de atributos en nuestro [dataset](https://es.wikipedia.org/wiki/Conjunto_de_datos); este último lo hace por medio de la creación de nuevos atributos que son combinaciones de los anteriores; mientras que en el proceso de [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection), intentamos incluir y excluir los atributos prácticamente sin modificarlos.\n",
    "\n",
    "El proceso de [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection) es tanto un arte como una ciencia, en donde el conocimiento sobre el problema y la intuición son sumamente importantes. El objetivo de la [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection) es triple: mejorar la capacidad predictiva de nuestro modelo, proporcionando modelos predictivos más rápidos y eficientes, y proporcionar una mejor comprensión del proceso subyacente que generó los datos. Los métodos de [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection) se pueden utilizar para identificar y eliminar los atributos innecesarios, irrelevantes y redundantes que no contribuyen a la exactitud del modelo predictivo o incluso puedan disminuir su precisión. \n",
    "\n",
    "\n",
    "## Beneficios de la selección de atributos\n",
    "\n",
    "Uno de los principales beneficios de la [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection) esta plasmado por la famosa frase ***\"Menos es más\"*** del arquitecto [Ludwig Mies van der Rohe](https://es.wikipedia.org/wiki/Ludwig_Mies_van_der_Rohe), precursor del [minimalismo](https://es.wikipedia.org/wiki/Minimalismo). Menos atributos son deseables ya que reduce la complejidad del modelo, y un modelo más simple es más fácil de entender y explicar. \n",
    "\n",
    "Otros beneficios adicionales que nos proporciona una buena [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection) antes de comenzar con el armado del modelo, son:\n",
    "\n",
    "* **Reduce el [sobreentrenamiento](https://es.wikipedia.org/wiki/Sobreajuste)**: Menos datos redundantes significan menos oportunidades para tomar decisiones sobre la base de ruido.\n",
    "* **Mejora la precisión**: Menos datos engañosos se convierten en una mejora en la exactitud del modelo.\n",
    "* **Reduce el tiempo de entrenamiento**: Menos datos significa que los algoritmos aprenden más rápidamente.\n",
    "\n",
    "\n",
    "## Selección de atributos univariante o multivariante\n",
    "\n",
    "Una cosa que no debemos pasar por alto en el proceso de [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection), es la relación que puede existir entre ellos. Es decir que debemos considerar seleccionar o eliminar un atributo en forma individual ([univariante](https://en.wikipedia.org/wiki/Univariate_analysis)) o un un grupo de atributos en forma conjunta ([multivariante](https://es.wikipedia.org/wiki/An%C3%A1lisis_multivariante)). Esto también va a depender del problema con el que estemos tratando y del modelo que elijamos. Por ejemplo si elegimos como modelo un [clasificador bayesiano ingenuo](https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo), el modelo asume que cada atributo es independiente del resto, por lo tanto, podríamos utilizar un enfoque [univariante](https://en.wikipedia.org/wiki/Univariate_analysis) sin problemas; en cambio si elegimos como modelo una [red neuronal](https://es.wikipedia.org/wiki/Red_neuronal_artificial), este último no asume la independencia de los atributos, sino que utiliza todas la que dispone; por lo tanto aquí deberíamos seguir un enfoque [multivariante](https://es.wikipedia.org/wiki/An%C3%A1lisis_multivariante) para seleccionar los atributos.\n",
    "\n",
    "\n",
    "## Algoritmos para selección de atributos\n",
    "\n",
    "Podemos encontrar dos clases generales de algoritmos de [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection): los métodos de filtrado, y los métodos empaquetados.\n",
    "\n",
    "### Métodos de filtrado\n",
    "\n",
    "Estos métodos aplican una medida estadística para asignar una puntuación a cada atributo. Los atributos luego son clasificados de acuerdo a su puntuación y son, o bien seleccionados para su conservación o eliminados del conjunto de datos. Los métodos de filtrado son a menudo [univariantes](https://en.wikipedia.org/wiki/Univariate_analysis) y consideran a cada atributo en forma independiente, o con respecto a la variable dependiente.\n",
    "\n",
    "Ejemplos de estos métodos son: [prueba de Chi cuadrado](https://es.wikipedia.org/wiki/Prueba_%CF%87%C2%B2), [prueba F de Fisher](https://es.wikipedia.org/wiki/Prueba_F_de_Fisher), [ratio de ganancia de información](https://en.wikipedia.org/wiki/Information_gain_ratio) y los [coeficientes de correlación](https://es.wikipedia.org/wiki/Correlaci%C3%B3n).\n",
    "\n",
    "### Métodos empaquetados\n",
    "\n",
    "Estos métodos consideran la selección de un conjunto de atributos como un problema de búsqueda, en donde las diferentes combinaciones son evaluadas y comparadas. Para hacer estas evaluaciones se utiliza un modelo predictivo y luego se asigna una puntuación a cada combinación basada en la precisión del modelo.\n",
    "\n",
    "Un ejemplo de este método es el algoritmo de eliminación recursiva de atributos.\n",
    "\n",
    "\n",
    "## Ejemplo\n",
    "\n",
    "Pasamos ahora a ver como podemos aplicar todo esto al caso en el que veníamos trabajando en el el [artículo anterior](http://relopezbriega.github.io/blog/2016/04/08/ejemplo-de-machine-learning-con-python-preprocesamiento-y-exploracion/). Pero antes, terminemos con algunas tareas de preprocesamiento adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <!-- collapse=True -->\n",
    "# Importando las librerías que vamos a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# graficos incrustados\n",
    "%matplotlib inline\n",
    "\n",
    "# parametros esteticos de seaborn\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(rc={\"figure.figsize\": (8, 4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importando el dataset preprocesado.\n",
    "ONG_data = pd.read_csv('LEARNING_procesado.csv', header=0)\n",
    "\n",
    "# Agregando la columna AGE2\n",
    "AGE2 = pd.cut(ONG_data['AGE'], range(0, 100, 10))\n",
    "ONG_data['AGE2'] = AGE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Eliminar columnas con donaciones superiores a 60 (atípicos)\n",
    "ONG_data = ONG_data[ONG_data.DONOR_AMOUNT < 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convertir datos categoricos a numericos\n",
    "tipos = ONG_data.columns.to_series().groupby(ONG_data.dtypes).groups\n",
    "ctext = tipos[np.dtype('object')]\n",
    "\n",
    "for c in ctext:\n",
    "    ONG_data[c], _ = pd.factorize(ONG_data[c])\n",
    "\n",
    "ONG_data['AGE2'], _ = pd.factorize(ONG_data['AGE2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas manipulaciones lo que hicimos es cargar en memoria el [dataset](https://es.wikipedia.org/wiki/Conjunto_de_datos) que prepocesamos anteriormente, le agregamos la nueva columna AGE2, ya que es mejor tener la edad agrupada en rangos en lugar de individualmente, luego eliminamos los [valores atípicos](https://es.wikipedia.org/wiki/Valor_at%C3%ADpico) que habíamos detectado; y por último, reemplazamos con su equivalente numérico a todas las [variables categóricas](http://relopezbriega.github.io/blog/2016/02/29/analisis-de-datos-categoricos-con-python/); ya que para los algoritmos de [Scikit-learn](http://scikit-learn.org/stable/) es mucho más eficiente trabajar con variables numéricas.\n",
    "\n",
    "Ahora sí, ya estamos en condiciones de poder comenzar a aplicar algunos de los algoritmos de [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection), comencemos con un simple algoritmo [univariante](https://en.wikipedia.org/wiki/Univariate_analysis) que aplica el método de filtrado. Para esto vamos a utilizar los objetos `SelectKBest` y `f_classif` del paquete `sklearn.feature_selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separamos las columnas objetivo\n",
    "donor_flag = ONG_data['DONOR_FLAG']\n",
    "donor_amount = ONG_data['DONOR_AMOUNT']\n",
    "indice = ONG_data['IDX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ODATEDW',\n",
       " 'PEPSTRFL',\n",
       " 'HVP3',\n",
       " 'CARDPROM',\n",
       " 'NUMPROM',\n",
       " 'RAMNT_8',\n",
       " 'RAMNT_16',\n",
       " 'NGIFTALL',\n",
       " 'CARDGIFT',\n",
       " 'LASTGIFT',\n",
       " 'LASTDATE',\n",
       " 'FISTDATE',\n",
       " 'AVGGIFT',\n",
       " 'RFA_2F',\n",
       " 'RFA_2A']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando el algoritmo univariante de prueba F.\n",
    "k = 15  # número de atributos a seleccionar\n",
    "entrenar = ONG_data.drop(['DONOR_FLAG', 'DONOR_AMOUNT', 'IDX'], axis=1)\n",
    "columnas = list(entrenar.columns.values)\n",
    "seleccionadas = SelectKBest(f_classif, k=k).fit(entrenar, donor_flag)\n",
    "atrib = seleccionadas.get_support()\n",
    "atributos = [columnas[i] for i in list(atrib.nonzero()[0])]\n",
    "atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Como podemos ver, el algoritmo nos seleccionó la cantidad de atributos que le indicamos; en este ejemplo decidimos seleccionar solo 15; obviamente, cuando armemos nuestro modelo final vamos a tomar un número mayor de atributos.\n",
    "\n",
    "### ¿Cómo funciona?\n",
    "\n",
    "Este algoritmo selecciona a los mejores atributos basándose en una prueba estadística [univariante](https://en.wikipedia.org/wiki/Univariate_analysis). Al objeto `SelectKBest` le pasamos la prueba estadística que vamos a a aplicar, en este caso una [prueba F](https://es.wikipedia.org/wiki/Prueba_F_de_Fisher) definida por el objeto `f_classif`, junto con el número de atributos a seleccionar. El algoritmo va a aplicar la prueba a todos los atributos y va a seleccionar los que mejor resultado obtuvieron.\n",
    "\n",
    "Ahora veamos como funciona el algoritmo de **Eliminación Recursiva de atributos**. Para este caso, vamos a utilizar como nuestro modelo predictivo el algoritmo [ExtraTreesClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Algoritmo de Eliminación Recursiva de atributos con ExtraTrees\n",
    "modelo = ExtraTreesClassifier()\n",
    "era = RFE(modelo, 15)  # número de atributos a seleccionar\n",
    "era = era.fit(entrenar, donor_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OSOURCE',\n",
       " 'ZIP',\n",
       " 'VIETVETS',\n",
       " 'WWIIVETS',\n",
       " 'POP901',\n",
       " 'HV1',\n",
       " 'PEC2',\n",
       " 'TPE13',\n",
       " 'EIC4',\n",
       " 'EIC14',\n",
       " 'VC2',\n",
       " 'CARDPROM',\n",
       " 'MINRDATE',\n",
       " 'MAXRDATE',\n",
       " 'TIMELAG']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imprimir resultados\n",
    "atrib = era.support_\n",
    "atributos = [columnas[i] for i in list(atrib.nonzero()[0])]\n",
    "atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo funciona?\n",
    "\n",
    "En este algoritmo, dado un modelo predictivo que asigna un coeficiente de importancia a cada atributo (como ExtraTreesClassifier), el objetivo de la *Eliminación Recursiva de atributos* es ir seleccionado en forma recursiva un número cada vez más pequeño de atributos. Primero comienza con todos los atributos del [dataset](https://es.wikipedia.org/wiki/Conjunto_de_datos) y luego en cada pasada va eliminando aquellos que tenga el menor coeficiente de importancia hasta alcanzar el número de atributos deseado.\n",
    "\n",
    "Si vemos los 15 atributos seleccionados por este otro algoritmo, existen muchas diferencias con los que selecciono el modelo anterior; en general, la Eliminación Recursiva de atributos suele ser mucho más precisa, pero también consume mucho más tiempo y recursos, ya que requiere que entrenemos a un *modelo predictivo* para poder obtener sus resultados.\n",
    "\n",
    "Por último, también podríamos utilizar ese coeficiente de importancia que nos proporciona el modelo como una guía adicional para refinar nuestra [selección de atributos](https://en.wikipedia.org/wiki/Feature_selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.59616058e-03,   3.03252110e-03,   2.71464477e-03,\n",
       "         2.51952243e-03,   2.34433609e-03,   6.01722535e-04,\n",
       "         4.82782938e-04,   2.24732045e-03,   2.07872966e-03,\n",
       "         1.29249803e-03,   1.17189225e-03,   9.77218420e-06,\n",
       "         6.12421074e-04,   5.79137133e-05,   2.40594405e-03])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importancia de atributos.\n",
    "modelo.fit(entrenar, donor_flag)\n",
    "modelo.feature_importances_[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00369165,  0.00353173,  0.00348298,  0.00336095,  0.00331946,\n",
       "        0.00331828,  0.00331345,  0.00326505,  0.00316758,  0.00316587,\n",
       "        0.00313431,  0.00311334,  0.00310065,  0.00307309,  0.00304518])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15 coeficientes más altos\n",
    "np.sort(modelo.feature_importances_)[::-1][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos algunos de estos atributos en forma individual para tener una idea de cuanto puede ser que aporten a la exactitud del modelo. Podríamos comparar por ejemplo, el promedio de donaciones que podríamos obtener con este atributo contra el promedio de todo el [dataset](https://es.wikipedia.org/wiki/Conjunto_de_datos). Tomemos por ejemplo al atributo LASTGIFT que representa el importe de la última donación que realizó cada persona incluida en el conjunto de datos. En principio parece lógico que este atributo sea significativo para el modelo, ya que si donó en el pasado, hay bastantes posibilidades de que vuelva a donar en esta oportunidad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0377358490566033"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilidad de ser donante de todo el dataset.\n",
    "prob_gral = (ONG_data[ONG_data.DONOR_AMOUNT > 0]['DONOR_AMOUNT'].count()  \\\n",
    "                   / ONG_data['DONOR_AMOUNT'].count()) * 100.0\n",
    "prob_gral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9347104389524157"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilidad de realizar donanción con LASTGIFT <= 10\n",
    "lastgift10 = (ONG_data[(ONG_data.DONOR_AMOUNT > 0) &\n",
    "                            (ONG_data.LASTGIFT <= 10)]['DONOR_AMOUNT'].count()  \\\n",
    "      / ONG_data[ONG_data.LASTGIFT <= 10]['DONOR_AMOUNT'].count()) * 100.0\n",
    "lastgift10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAEKCAYAAABHULzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/R/g6om1pIQt9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ac03a3a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graficando los resultados\n",
    "lastgift = pd.Series({'promedio gral': prob_gral, 'lastgift<=10': lastgift10})\n",
    "plot=lastgift.plot(kind='barh', \n",
    "                   color=['blue', 'green']).set_title('Pobabilidad de donar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este último gráfico nos muestra claramente que con un valor del atributo LASTGIFT menor o igual a 10 las probabilidades de que esa persona realice una donación mejoran, pero veamos que pasa con el importe de la donación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.889109446525177"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importe promedio de donación general\n",
    "donacion_prom = ONG_data[ONG_data.DONOR_AMOUNT > 0]['DONOR_AMOUNT'].mean()\n",
    "donacion_prom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.7553191489361701"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importe promedio de donación lastgift <= 10\n",
    "lastgift10_imp = ONG_data[(ONG_data.DONOR_AMOUNT > 0) & \n",
    "                         (ONG_data.LASTGIFT <= 10)]['DONOR_AMOUNT'].mean()\n",
    "lastgift10_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAEKCAYAAAA4ga4lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFwVJREFUeJzt3XmcXXV5x/HPZAMlEQkMVWpAjPBYCgqCgqxBUYxCaa1U\n3BAQsZXFurNYtS6UqqigtlgRiAta9YXWiBDADYxxi0igwBPRuFWEwIQlCIbA7R/nTLnc3iQz5M6c\n3535vF8vXrlz7u/+zvOcO7nnO79zJgy0Wi0kSZJKMqXpAiRJkjoZUCRJUnEMKJIkqTgGFEmSVBwD\niiRJKo4BRZIkFceAIvWZiNg9Ir7UwH43j4hvjfd+x0pErI6IbSNij409nhHx9Yh4VS/q2Zg5Rrm/\nQyPirI5t8yPixoiYPV51SOsyrekCJI1OZi4FDm9g11sAz2hgv2OlBZCZP2Hjj2dreL6NrWe8ZOZC\nYGHH5unAwZk5NJ61SN0YUKQ+ExHzgI9m5i4RcQFwL7AH8Djgi8BK4ND662Mz89v1OIAdga2By4CT\nMnNtROwHvB94NLAGeHtmLoqIo4BX19vvrF//qIj4ab2/AD4CbAlMBc7OzPO71Psr4CvAvsBjgTMz\n85y6j7OA1fU+9gSOAk4EHgBuAU7IzJ+Pos8ZwL8C+9c1XV33eXfd50eBB4Gl1CvIHcdzc+DjwNOo\nAsMlwKmZ+UBHT9sAC4DHA78Ftmp77i9GeFza6/kJbSvaEXHceo7DncAuwBzgRuCIzLwnIo4BjgNm\nALOBMzLznHq+U4AjgbXAz+vj/CLgbzPz0Ih4AvDvwHbAQEQsyMwPRsQTgW8CF9fvz2zgtMz8Ymc/\nUq95iUfqf08D9qI6eb8BuDsz96E6+Z/cMe65wE71f6+NiC2BL1GdxJ8GvAr4bH1ioh53QGY+Gzga\nuDczn0712fFl4OTM3AOYB7wlIvbsUl8LmJmZzwAOAN4dETvXz/0l1Ql2N6oA8xZgXmbuClwIfHWU\nfZ4M3J+Zu9dz3AycERHT6z7fUNe/CHhUl1rPBlZm5i71fp4GvLnLuI8D38/MnYHXUYU1ImLaSI5L\nHaTa67lsuJ6IePYGjsPTgYOBvwC2AQ6PiM2AY4H59XxHUIVOIuKvqN7Xveq+VgAn8PAVm88B38zM\npwL7AK+IiJfUz20PXJqZewJvG55XGmsGFKm/tYCFmflAZt4C3ANcWj/3S6qfeIfHLcjMezJzDfBp\nqpPcM4GbMvPHAJl5PbCY6sTaApZl5up6joG2/e4IPAk4LyKuBr4DbALsuo46P17P//u6vufV8/82\nM39bj3k+8IXMvL0euwD48zosjbTPQ4DDIuLquq7DqE7kuwBrMvPb9dxfBlZ1qfP5wMfqMWuAc4D5\nXcY9B7igHrcCuHyUx2Vd9QyM4Dhcmpn3Z+Za4FpgdmbeU/d+aES8GzgV2Kze10HAFzPzznq+N2Xm\n6fW+iIhHA3vz0Ht0V93b/Hp/92fmN+q5rm471tKY8hKP1P/WdHx9/zrGtV+mmFp/3e2HlKlUnw33\nU11+6WYqcEe98gFARDwOuGOE+15bP26ff4CHh6DhbdPrxyPpcwrVatCiuqaZwKbAtl3mXsv/N6Vj\n3NS2/bdr8fBjNzzXFEZ2XFrrqWdDx+G+jnmoL9EsoQpUV1Gt4hxSj3nYcYqIx1DdTzS8gjLcc2ff\nw+eH9uPerW5pTLiCIvW3kZ4sBoC/i4gZEbEp1f0IXwN+AEREPIPqwV8C+1H95N/tBDq1fpzAfRHx\n8vp1c4BrgN3o7sh63LZUl5ku6TL/IuAlEbFVPfZo4DbgplH0uQg4se5zCtUJ+33AMqp7K+bXc78A\nGFzH64+vx2xCdU/HZV3GXVo/NxwOnlNvH+lxuXYd9bQewXEYAHYHbs3M92Xm5VT35lAfgyuAF0XE\nrHr8u4E3Dr+4XiH7QVvfmwOvpFoVMoyoMQYUqT+12v5sddne7bnVVD9dLwO+l5nn15cRDgc+GhHL\nqO5FOCozb+ry+t8DP42I66kuHxwGHBsR11CdVP8pM5eso95tI2Ip1Yn99Zn58856M/MK4MPAtyLi\nOqqT5CGZOVzHSPp8D/ArqksR/031Gfem+nLIXwPvqS+9vJjq5tPO+U4Cto6Ia+vjdANVwOl0PLBT\nfSzOowohZOb9Izku9biu9YzyOAzXfhnwu4jIiLgK+BPV/TdzM/MS4Hxgcf0eb011Cai975cDz6mf\n/yHw5frSUvuYzmMljamBVsvvNWmii4jzgRsyc9xvcIyIFcBLMvNH471vSf3LFRRJklQcV1AkSVJx\nXEGRJEnFMaBIkqTi+O+gNGTt2gdaq1b9sekyxswWWzyaidrfRO4N7K/f2V//msi9AQwOzhrVr627\ngtKQadOmbnhQH5vI/U3k3sD++p399a+J3NsjYUCRJEnFMaBIkqTiGFAkSVJxDCiSJKk4BhRJklQc\nA4okSSqOAUWSJBXHgCJJkopjQJEkScUxoEiSpOIYUCRJUnEMKJIkqTgGFEmSVBwDiiRJKo4BRZIk\nFceAIkmSimNAkSRJxTGgSJKk4hhQJElScQwokiSpOAYUSZJUHAOKJEkqjgFFkiQVx4AiSZKKY0CR\nJEnFmdZ0AZPV8uXLGRpa3XQZY2bVqpkTtr+J3BvY3yMxZ852zJgxo6dzSpOdAaUh8Z6AxzZdhaSN\ndgcsOX4pc+fu0HQl0oRiQGnKY4Gtmi5CkqQyeQ+KJEkqjgFFkiQVx4AiSZKKY0CRJEnFMaBIkqTi\nGFAkSVJxDCiSJKk4BhRJklQcA4okSSqOAUWSJBXHgCJJkopjQJEkScUxoEiSpOIYUCRJUnEMKJIk\nqTgGFEmSVBwDiiRJKo4BRZIkFceAIkmSimNAkSRJxTGgSJKk4hhQJElScaY1XUCniDgKiMw8ZYTj\nNwFekZmfWs+YzwOvBLYFvgEsAc4EtsjMqx5hnU8GLsrMp9ZfbwVcCGwK/B44OjPvfSRzS5I02ZW4\ngtIa5fjHA8eub0BmvjQz1wL7Al/PzKOBFwM7dY6NiCdFxMvWN19EvBL4PLBV2+Z3AJ/NzP2Bq4HX\njqoLSZL0f4pbQRkWEacDewBbAtdk5jERsQ/Vysca4I9UIeM0YKeIeDtwDtUqxgwggWdn5g4R8Stg\nP+BU4FERMQS8ClgTEUuBa4DDgKOAPwEfi4i5wLkdZX0uM88FhoADgF+0PbcP8N768SXA6cBHenIw\nJEmaZEoNKDOAP2Tm8yJiCnBdRGxDFSK+AJwF/BWwBVUo2Dkz3xsRH6a67HJORBwEPLeerwXcAvwL\n1eWj0yNiOnBzZv4kIm4Bvgock5m3ttVxYLfiMvNigIho3/wY4M768Wpg8407BJL6xezZMxkcnNV0\nGf+npFrGwkTubyL3NlqlBpQWsHVEXEh1sp9JVevpVCsm3wT+B/gh1T0fw54CnF8//h4w0PbcQNt/\n7dsADgeOAy6IiE8DF1Hdr/LJjrouzMzObcPuogopK4FZwB0jaVRS/xsaWs3KlXc3XQZQneBKqWUs\nTOT+JnJvMPrwVWJAGaBaufh5Zh4REYPA31DdL/MK4ILMfEtEnEIVKs7noXtprgP2BpYBe21gPw8O\nvy4zrwSujIgtqS7zfDAzT2IdKyjrsBh4AbAAmA9cOYrXSpKkNiUGlBbwI2D3iPgW8AeqlZJt6u3n\nRsQ9wANUAeVWYEZE/AtwBvCZiPg7qt+kWdM25/Cfw4+XAh+IiOsz87sAmXk71T0uo6l12HuBBRHx\nGqpVlPXeaCtJktZtoNUa7S/NlCsi5gMr6/tKDgJOzsyDmq6rm4ETB1oP+x0gSf3pNljy8qXMnbtD\n05UAk+MywUTtbyL3BjA4OGtgw6MeUuIKysZYAZwXEWuBqcCJDdcjSZIegQkVUDLzRqp7UCRJUh8r\n8R9qkyRJk5wBRZIkFceAIkmSimNAkSRJxTGgSJKk4hhQJElScQwokiSpOAYUSZJUHAOKJEkqjgFF\nkiQVx4AiSZKKY0CRJEnFMaBIkqTiGFAkSVJxDCiSJKk4BhRJklQcA4okSSqOAUWSJBXHgCJJkopj\nQJEkScWZ1nQBk9YdTRcgqSf8uyyNCQNKQ/KfkqGh1U2XMWZmz545YfubyL2B/T0Sc+Zs19P5JBlQ\nGrPjjjuycuXdTZcxZgYHZ03Y/iZyb2B/ksrgPSiSJKk4BhRJklQcA4okSSqOAUWSJBXHgCJJkopj\nQJEkScUxoEiSpOIYUCRJUnEMKJIkqTgGFEmSVBwDiiRJKo4BRZIkFceAIkmSimNAkSRJxTGgSJKk\n4hhQJElScQwokiSpOAYUSZJUHAOKJEkqjgFFkiQVx4AiSZKKY0CRJEnFMaBIkqTiGFAkSVJxDCiS\nJKk4BhRJklQcA4okSSqOAUWSJBXHgCJJkopjQJEkScUxoEiSpOIYUCRJUnEMKJIkqTgGFEmSVBwD\niiRJKo4BRZIkFceAIkmSimNAkSRJxTGgSJKk4hhQJElScQwokiSpOAYUSZJUHAOKJEkqjgFFkiQV\nx4AiSZKKY0CRJEnFMaBIkqTiGFAkSVJxDCiSJKk4BhRJklQcA4okSSqOAUWSJBXHgCJJkoozrekC\nJqvly5czNLS66TLGzKpVMydsfxO5N7C/fmd//Ws8epszZztmzJgxpvvolYFWq9V0DZPSwMCiFmzf\ndBmSpEljBUuWDDJ37g6N7H1wcNbAaMa7gtKY7YEdmy5CkjSp9M/qk/egSJKk4hhQJElScQwokiSp\nOAYUSZJUHAOKJEkqjgFFkiQVx4AiSZKKY0CRJEnFMaBIkqTiGFAkSVJxDCiSJKk4BhRJklQcA4ok\nSSqOAUWSJBXHgCJJkopjQJEkScUxoEiSpOIYUCRJUnEMKJIkqTgGFEmSVBwDiiRJKo4BRZIkFWfa\n+p6MiIOBbTPzk+NUz5iJiIXACcA8YCgzF47hvuYBr83Ml47VPiRJmsjWG1Ayc9F4FTJOWpm5YDz2\nMw77kCRpwtrQCspRQADnAF8EfgM8EfgCsDOwG3BxZp4WEd8Brq63PQgckZm3ts31rvq1TwBmAydk\n5vcj4tfADcD1wNnAecBUqpP8SZm5LCJuAhYDOwLfBDYHnglkZh4ZEXOATwCPAu4FjsvM30XEPwMv\nBG4G5gADdR03Z+YnIuJMYJ+6xAsz8+yO/g8B/hm4E1gFLAO+A7wf+BPwH8B9wOuA6XXNfwMMrO+4\nSpKk9dvQPSjtKwHbA8cAhwDvAd4A7Am8um3sFZk5D7gIOK3LXCsz8yDgSODf6u1PAF6amW8EPgh8\nODMPAF4PfKoes109337AScDHM3NPYN+I2Lx+3dmZeSBwJnBGROwGHJiZewCHAzPbe6rDxxMzcy9g\nX+BlEbHzcLERMRU4C3h+Zj6bKvgMH49NMnP/zPwssAPwwszcjypkHYwrKJIkbZT1rqB0+GVm3h0R\n9wO3ZOYdABHRfjK+vP5zMdXKRacrADLzuoh4XL3ttsxcVT9+CnBlPeaaemUE4PbM/F29v3sy88Z6\n+53ApsAuwKkR8Taq1Ys19VxL67nui4gfd9TyFOCq+vm1EfEDYCfguvr5QeCuzFxZf30VMFxzts2z\nElgQEavrOZd06VuSpMbNnj2TwcFZTZcxIqMJKCNZFdiT6kS+N3Btl+efCSyqVyp+XW97sO35G4D9\ngYURsSvVpZmR7PsG4IOZuaSee0+q1YwTI2IKVZ+7dXnN0cBHImJ6XfMFbc/fCsyKiK0y8zbgWcCK\n9prr1Zt3UV0+mgJchpd3JEmFGhpazcqVdzey79EGo5H8mnGr48/1PT6+vhflYOB9XebaLyKuoLp3\n47gur38zVaj4LtUloFd3GdMZVlr1695Z7/tTwHWZeQ3wX8CPgK8Ct7W/JjMvBlZExPepVj2+lJk/\nGx6QmQ9S/dbPNyLicqoQcn97DZl5J9Vq0RLgK1QrK49fR52SJGmEBlqt3pxHI+LbwN9m5tA6nn8n\ncG1mXtSTHY6DiDgZ+FBmromIzwCL6vtONtrAwPJWdc+vJEnjYTlLlqxm7twdGtn74OCsUV1hGM0l\nnsnobuAHEfFHqss7/9lwPZIkTQo9W0HR6LiCIkkaX/21guI/dS9JkopjQJEkScUxoEiSpOIYUCRJ\nUnEMKJIkqTgGFEmSVBwDiiRJKo4BRZIkFceAIkmSimNAkSRJxTGgSJKk4hhQJElScQwokiSpOAYU\nSZJUHAOKJEkqjgFFkiQVx4AiSZKKY0CRJEnFMaBIkqTiGFAkSVJxDCiSJKk405ouYPJa0XQBkqRJ\nZQUw2HQRI2ZAaUjm9gwNrW66jDEze/bMCdvfRO4N7K/f2V//GvveBpkzZ7sxnL+3BlqtVtM1TFat\nlSvvbrqGMTM4OIuJ2t9E7g3sr9/ZX/+ayL0BDA7OGhjNeO9BkSRJxTGgSJKk4hhQJElScQwokiSp\nOAYUSZJUHAOKJEkqjgFFkiQVx4AiSZKKY0CRJEnFMaBIkqTiGFAkSVJxDCiSJKk4BhRJklQcA4ok\nSSqOAUWSJBXHgCJJkopjQJEkScUxoEiSpOIYUCRJUnEMKJIkqTgGFEmSVBwDiiRJKo4BRZIkFceA\nIkmSimNAkSRJxTGgSJKk4gy0Wq2ma5AkSXoYV1AkSVJxDCiSJKk4BhRJklQcA4okSSqOAUWSJBXH\ngCJJkoozrekCJpuImAL8G/BU4E/AsZn5i2ar6o2ImA6cB2wHbAK8NzMXNltV70XE1sBS4DmZubzp\nenopIk4BDgWmAx/LzAUNl9Qz9d+9c4EdgQeB12RmNlvVxouIPYEzMvPAiHgycAFVf9cBx2dmX/9b\nEh397QqcDTxA9fl5ZGbe2miBG6m9v7ZtLwNOyMy9m6ts43W8d1sDnwQeCwxQvXe/Wt/rXUEZf38N\nzKi/8U4Gzmy4nl56ObAyM/cHng98rOF6eq4OYZ8A7mm6ll6LiHnAs+rvzXnAkxotqPeeB2yWmfsC\n7wbe13A9Gy0i3kr1ob9JvelDwKn138EB4LCmauuFLv19hOrEfSBwEfC2pmrrhS79ERG7Acc0VlSP\ndOnt/cBnMvMA4B3Azhuaw4Ay/vYBLgXIzB8CezRbTk99ieobD6rvrbUN1jJWPgD8O3Bz04WMgecB\n10bEV4GFwNcarqfX7gU2j4gBYHNgTcP19MJNwIuowgjA0zPzyvrxJcBBjVTVO539HZGZy+rH06ne\n0372sP4iYkuq4PyPPNRzv+p87/YG5kTE5VQ/zH5rQxMYUMbfY4C72r5+oF567nuZeU9mro6IWVRh\n5bSma+qliDiKaoXosnpTv3+AdBoEdgdeDPw98Llmy+m5xcCmwI1Uq2AfbbacjZeZF/HwHwTavydX\nUwWxvtXZX2b+ASAi9gaOBz7cUGk90d5ffR74FPBGqveur3X53nwiMJSZzwV+wwhWvybEibHP3AXM\navt6SmY+2FQxvRYRc6iS8acz8wtN19NjRwPPjYhvA7sCCyLizxquqZduAy7LzLX1vTX3RcRWTRfV\nQ28FFmdm8ND7N6Phmnqt/bNkFnBHU4WMlYh4CdUq5gsy8/am6+mh3YEnU/X2eWCniPhQsyX11O08\ntCq7kBFcPTCgjL/FwAsAImIvYNn6h/eP+mR9GfDWzLyg4XJ6LjMPyMx59fXvn1Hd5HVL03X10Peo\n7h0iIrYBNqP6UJkoNuOh1ctVVJcIpjZXzpi4OiIOqB/PB65c3+B+ExGvoFo5mbehGyz7TWb+ODN3\nrj9fjgCuz8w3Nl1XD30PeGH9+ACqm7jXy9/iGX9fofopfHH99dFNFtNjp1ItKb8jIobvRZmfmfc1\nWJNGKDMvjoj9I+JHVD+8vK7ffwOkwweA8yPiKqpwckpm9vs9DMOG36c3AZ+sV4auB77cXEk91aov\ngZwF/Bq4KCIAvpuZ72qysB7p/Hs20GVbv2r/3jw3Iv6BamXvZRt6of83Y0mSVBwv8UiSpOIYUCRJ\nUnEMKJIkqTgGFEmSVBwDiiRJKo4BRZIkFceAIkmSimNAkSRJxflfEwLk1d5aOacAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ac0de5a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graficando los resultados\n",
    "lastgift = pd.Series({'imp promedio gral': donacion_prom, \n",
    "                      'lastgift<=10': lastgift10_imp})\n",
    "plot=lastgift.plot(kind='barh', \n",
    "                   color=['blue', 'green']\n",
    "                  ).set_title('importe promedio de donación')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí vemos, que si bien las probabilidades de que sea un donador mejoran, el importe que se dona esta por debajo del promedio. En el caso de este atributo podemos ver que existe una [correlación](https://es.wikipedia.org/wiki/Correlaci%C3%B3n) inversa entre el importe de donación y la probabilidad de hacer una donación a la ONG.\n",
    "\n",
    "Hasta aquí llegamos en este artículo, la idea es que luego, cuando tengamos armado el modelo, podamos jugar con distintas combinaciones de atributos y ver como se comporta el modelo hasta alcanzar la combinación ideal de atributos. No se pierdan los próximos artículos!\n",
    "\n",
    "Saludos!\n",
    "\n",
    "*Este post fue escrito utilizando IPython notebook. Pueden descargar este [notebook](https://github.com/relopezbriega/relopezbriega.github.io/blob/master/downloads/MachineLearningPractica2.ipynb) o ver su version estática en [nbviewer](http://nbviewer.ipython.org/github/relopezbriega/relopezbriega.github.io/blob/master/downloads/MachineLearningPractica2.ipynb).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
