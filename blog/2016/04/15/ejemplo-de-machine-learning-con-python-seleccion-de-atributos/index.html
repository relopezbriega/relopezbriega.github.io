<!DOCTYPE html>
<html
  lang="en"
  data-theme="dark"
>
  <head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  


<link
  rel="preload"
  as="font"
  type="font/woff2"
  href="/fonts/roboto-slab-latin-400.woff2"
  crossorigin="anonymous"
/>

<link
  rel="preload"
  as="font"
  type="font/woff2"
  href="/fonts/roboto-slab-latin-700.woff2"
  crossorigin="anonymous"
/>


<link
  rel="preload"
  as="font"
  type="font/woff2"
  href="/fonts/fira-code-latin-300.woff2"
  crossorigin="anonymous"
/>
<link
  rel="preload"
  as="font"
  type="font/woff2"
  href="/fonts/fira-code-latin-400.woff2"
  crossorigin="anonymous"
/>

<link
  rel="preload"
  as="font"
  type="font/woff2"
  href="/fonts/fira-code-latin-700.woff2"
  crossorigin="anonymous"
/>

  
  
    <meta
      name="robots"
      content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"
    />
  




<title>Ejemplo de Machine Learning con Python - Selección de atributos</title>

<meta
  name="description"
  content="Selección de atributos en Machine learning. Qué es la selección de atributos, sus beneficios, univariante o multivariante, algoritmos para seleccionar atributos, ejemplos en python."
/>

<link rel="canonical" href="https://relopezbriega.github.io/blog/2016/04/15/ejemplo-de-machine-learning-con-python-seleccion-de-atributos/" />




  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Ejemplo de Machine Learning con Python - Selección de atributos">
  <meta name="twitter:description" content="Selección de atributos en Machine learning. Qué es la selección de atributos, sus beneficios, univariante o multivariante, algoritmos para seleccionar atributos, ejemplos en python.">

<meta property="og:url" content="https://relopezbriega.github.io/blog/2016/04/15/ejemplo-de-machine-learning-con-python-seleccion-de-atributos/">
  <meta property="og:site_name" content="Raul E. Lopez Briega">
  <meta property="og:title" content="Ejemplo de Machine Learning con Python - Selección de atributos">
  <meta property="og:description" content="Selección de atributos en Machine learning. Qué es la selección de atributos, sus beneficios, univariante o multivariante, algoritmos para seleccionar atributos, ejemplos en python.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2016-04-15T00:00:00+00:00">
    <meta property="article:modified_time" content="2016-04-15T00:00:00+00:00">
    <meta property="article:tag" content="Python">
    <meta property="article:tag" content="Estadistica">
    <meta property="article:tag" content="Programacion">
    <meta property="article:tag" content="Machine Learning">
    <meta property="article:tag" content="Analisis De Datos">


  <meta itemprop="name" content="Ejemplo de Machine Learning con Python - Selección de atributos">
  <meta itemprop="description" content="Selección de atributos en Machine learning. Qué es la selección de atributos, sus beneficios, univariante o multivariante, algoritmos para seleccionar atributos, ejemplos en python.">
  <meta itemprop="datePublished" content="2016-04-15T00:00:00+00:00">
  <meta itemprop="dateModified" content="2016-04-15T00:00:00+00:00">
  <meta itemprop="wordCount" content="1783">
  <meta itemprop="keywords" content="Python,Estadistica,Programacion,Machine Learning,Analisis De Datos">






  
  
    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-6SZHL0BZZJ"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-6SZHL0BZZJ');
        }
      </script>
    
  




  
  
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/pikaday/1.8.0/css/pikaday.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/pikaday/1.8.0/pikaday.min.js"></script>


    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    }
  };
</script>


  








  
  
  
  


<style>
   
  @font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:100;src:local("Roboto Slab Thin "),local("Roboto Slab-Thin"),url(/fonts/roboto-slab-latin-100.woff2) format("woff2"),url(/fonts/roboto-slab-latin-100.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:200;src:local("Roboto Slab Extra Light "),local("Roboto Slab-Extra Light"),url(/fonts/roboto-slab-latin-200.woff2) format("woff2"),url(/fonts/roboto-slab-latin-200.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:300;src:local("Roboto Slab Light "),local("Roboto Slab-Light"),url(/fonts/roboto-slab-latin-300.woff2) format("woff2"),url(/fonts/roboto-slab-latin-300.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:400;src:local("Roboto Slab Regular "),local("Roboto Slab-Regular"),url(/fonts/roboto-slab-latin-400.woff2) format("woff2"),url(/fonts/roboto-slab-latin-400.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:500;src:local("Roboto Slab Medium "),local("Roboto Slab-Medium"),url(/fonts/roboto-slab-latin-500.woff2) format("woff2"),url(/fonts/roboto-slab-latin-500.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:600;src:local("Roboto Slab SemiBold "),local("Roboto Slab-SemiBold"),url(/fonts/roboto-slab-latin-600.woff2) format("woff2"),url(/fonts/roboto-slab-latin-600.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:700;src:local("Roboto Slab Bold "),local("Roboto Slab-Bold"),url(/fonts/roboto-slab-latin-700.woff2) format("woff2"),url(/fonts/roboto-slab-latin-700.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:800;src:local("Roboto Slab ExtraBold "),local("Roboto Slab-ExtraBold"),url(/fonts/roboto-slab-latin-800.woff2) format("woff2"),url(/fonts/roboto-slab-latin-800.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:900;src:local("Roboto Slab Black "),local("Roboto Slab-Black"),url(/fonts/roboto-slab-latin-900.woff2) format("woff2"),url(/fonts/roboto-slab-latin-900.woff) format("woff")}@font-face{font-display:swap;font-family:Fira Code;font-style:normal;font-weight:300;src:local("Fira Code Light "),local("Fira Code-Light"),url(/fonts/fira-code-latin-300.woff2) format("woff2"),url(/fonts/fira-code-latin-300.woff) format("woff")}@font-face{font-display:swap;font-family:Fira Code;font-style:normal;font-weight:400;src:local("Fira Code Regular "),local("Fira Code-Regular"),url(/fonts/fira-code-latin-400.woff2) format("woff2"),url(/fonts/fira-code-latin-400.woff) format("woff")}@font-face{font-display:swap;font-family:Fira Code;font-style:normal;font-weight:500;src:local("Fira Code Medium "),local("Fira Code-Medium"),url(/fonts/fira-code-latin-500.woff2) format("woff2"),url(/fonts/fira-code-latin-500.woff) format("woff")}@font-face{font-display:swap;font-family:Fira Code;font-style:normal;font-weight:600;src:local("Fira Code SemiBold "),local("Fira Code-SemiBold"),url(/fonts/fira-code-latin-600.woff2) format("woff2"),url(/fonts/fira-code-latin-600.woff) format("woff")}@font-face{font-display:swap;font-family:Fira Code;font-style:normal;font-weight:700;src:local("Fira Code Bold "),local("Fira Code-Bold"),url(/fonts/fira-code-latin-700.woff2) format("woff2"),url(/fonts/fira-code-latin-700.woff) format("woff")}

/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden],template{display:none}

/*! CC BY-SA 3.0 License | https://stackoverflow.com/a/36118384/1154965 */@keyframes blink{50%{opacity:0}to{opacity:1}}

/*! MIT License | github.com/schnerring/hugo-theme-gruvbox */:root[data-theme=light]{--bg:var(--bg0);--bg0:#fbf1c7;--bg0_h:#f9f5d7;--bg0_s:#f2e5bc;--bg1:#ebdbb2;--bg2:#d5c4a1;--bg3:#bdae93;--bg4:#a89984;--fg:var(--fg1);--fg0:#282828;--fg1:#3c3836;--fg2:#504945;--fg3:#665c54;--fg4:#7c6f64;--gray1:var(--fg4);--gray2:#928374;--red1:#cc241d;--red2:#9d0006;--green1:#98971a;--green2:#797403;--yellow1:#d79921;--yellow2:#b57614;--blue1:#458588;--blue2:#076678;--purple1:#b16286;--purple2:#8f3f71;--aqua1:#689d6a;--aqua2:#427b58;--orange1:#d65d0e;--orange2:#af3a03}[data-theme=light]:root .light--hidden{display:none}:root[data-theme=dark]{--bg:var(--bg0);--bg0:#282828;--bg0_h:#1d2021;--bg0_s:#32302f;--bg1:#3c3836;--bg2:#504945;--bg3:#665c54;--bg4:#7c6f64;--fg:var(--fg1);--fg0:#fbf1c7;--fg1:#ebdbb2;--fg2:#d5c4a1;--fg3:#bdae93;--fg4:#a89984;--gray1:var(--fg4);--gray2:#928374;--red1:#cc241d;--red2:#fb4934;--green1:#98971a;--green2:#b8bb26;--yellow1:#d79921;--yellow2:#fabd2f;--blue1:#458588;--blue2:#83a598;--purple1:#b16286;--purple2:#d3869b;--aqua1:#689d6a;--aqua2:#8ec07c;--orange1:#d65d0e;--orange2:#fe8019}[data-theme=dark]:root .dark--hidden{display:none}:root{--primary:var(--blue1);--primary-alt:var(--blue2);--font-monospace:"Fira Code","Lucida Console",Monaco,monospace;--font-sans-serif:Verdana,Helvetica,sans-serif;--font-serif:"Roboto Slab",Georgia,serif}html{font-family:Roboto Slab,Georgia,serif;font-family:var(--font-serif);font-size:1rem;scroll-behavior:smooth}body{background:var(--bg);color:var(--fg);line-height:1.675;word-wrap:break-word}strong{letter-spacing:.35px}a{color:inherit;-webkit-text-decoration:none;text-decoration:none}a.link--external:after{content:"\2009↗"}img{border:2px solid var(--bg1);height:auto;max-width:100%}::-moz-selection{background:var(--bg4);color:var(--fg0)}::selection{background:var(--bg4);color:var(--fg0)}h1,h2,h3,h4{color:var(--fg0);font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace);font-weight:300;line-height:1.4}h1 code,h2 code,h3 code,h4 code{font-size:1em}h2,h3,h4{border-bottom:1px solid var(--bg1)}h1,h2{font-weight:400}h1{font-size:1.875rem}h2{font-size:1.75rem}h3{font-size:1.625rem}@media (min-width:768px){h1{font-size:2.375rem}h2{font-size:2rem}h3{font-size:1.75rem}}h4{font-size:1.5rem}table{border-collapse:collapse;margin:2rem 0;table-layout:fixed;width:100%}table,td,th{border:1px solid var(--bg1);padding:.5rem}hr{background:var(--bg1);border:none;height:1px;margin:3rem auto;width:80%}blockquote,code,pre{border-radius:.2rem;padding:0 .2em}pre code{padding:0}blockquote,code,pre,th{background:var(--bg1)}code,pre,th{font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace)}code code{background:var(--bg2)}blockquote,pre{padding:1rem}pre{background:var(--bg1)!important;overflow:auto}pre code{background:none}blockquote{border-left:5px solid var(--primary-alt);margin:.5rem 0}blockquote:not(.does-not-exist) code{background:var(--bg2)}blockquote:not(.does-not-exist) p:first-of-type{margin-top:0}blockquote:not(.does-not-exist) p:last-of-type{margin-bottom:0}pre::-webkit-scrollbar{height:.5rem;scrollbar-width:auto}pre::-webkit-scrollbar-track{background:var(--bg2);border-radius:.2rem}pre::-webkit-scrollbar-thumb{background:var(--bg4);border-radius:.2rem}.layout{display:grid;grid-template-areas:"header" "main" "footer";grid-template-rows:auto 1fr auto;height:100vh}main{align-items:start;display:grid;grid-area:main;grid-template-areas:"empty content sidebar";grid-template-columns:1fr minmax(0,650px) 4fr}header{background:var(--bg1);grid-area:header}footer{grid-area:footer}footer,main{margin:.5em 1.1em}.content{grid-area:content}.sidebar{display:none;flex-direction:column;grid-area:sidebar;margin-top:3rem;position:sticky;top:2rem}@media (min-width:992px){.sidebar{display:flex}}header{display:grid;font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace);font-size:1.125rem;grid-template-areas:"heading search nav theme-toggle";grid-template-columns:auto auto 1fr auto;padding:.75rem}.logo{color:var(--fg0);display:flex;font-weight:700;grid-area:heading}.logo:hover .logo__cursor{animation:blink 1s infinite;opacity:1}.logo__chevron,.logo__cursor{margin-left:.5rem}.logo__cursor{opacity:0}.logo__text{display:none}@media (min-width:768px){.logo__text{display:block}}.search{display:flex;grid-area:search;margin:0 1rem}#search__text{background:var(--bg2);border:1px solid var(--bg2);border-radius:.2rem;caret-color:var(--fg);color:var(--fg);outline:none;padding:0 .5rem;width:100%}#search__text:hover{border-color:var(--bg3)}#search__text:focus{border-color:var(--bg4)}#search__text::-moz-placeholder{color:var(--fg3)}#search__text::placeholder{color:var(--fg3)}#search__text[type=search]::-webkit-search-cancel-button{-webkit-appearance:none;appearance:none}#search__suggestions{background:var(--bg);border-radius:.2rem;box-shadow:0 .5rem 1rem var(--bg1);font-family:Roboto Slab,Georgia,serif;font-family:var(--font-serif);left:0;margin-top:2rem;position:absolute;width:95vw;z-index:1000}@media (min-width:768px){.search{position:relative}#search__suggestions{width:60vw}}.search__suggestions--hidden{display:none}.search__suggestion-item{border-bottom:1px dashed var(--bg2);display:grid;grid-template-columns:1fr 2fr}.search__suggestion-item:focus,.search__suggestion-item:focus-visible,.search__suggestion-item:hover{background:var(--bg1);cursor:pointer;outline:none}.search__suggestion-item:last-child{border:none}.search__suggestion-description,.search__suggestion-title{margin:1rem 0;padding:0 1rem}.search__suggestion-title{font-weight:700}.search__suggestion-description{border-left:1px solid var(--bg2)}.search__no-results{padding:.75rem}.theme__toggle{align-items:center;background:none;border:none;color:var(--yellow1);cursor:pointer;display:flex;grid-area:theme-toggle;margin:0 1rem}.theme__toggle:hover{color:var(--yellow2)}.theme__toggle svg{height:28px;width:28px}nav#menu{align-items:center;display:flex;grid-area:nav;justify-content:flex-end}nav#menu .menu__item{color:var(--fg)}nav#menu .menu__item:hover{color:var(--fg3);cursor:pointer}nav#menu ul{list-style:none;margin:0;padding:0}nav#menu ul.menu--horizontal{align-items:center;display:none}nav#menu ul.menu--horizontal li{display:inline-block;margin:0 .75rem}@media (min-width:768px){nav#menu ul.menu--horizontal{display:flex}}nav#menu ul.menu--vertical{background:var(--fg0);bottom:0;margin:0;padding:3rem;position:fixed;right:0;top:0;transform:translate(100%);transition:transform .5s cubic-bezier(.9,0,.1,1);width:50%;z-index:10}nav#menu ul.menu--vertical .menu__item{color:var(--bg1)}nav#menu ul.menu--vertical .menu__item:hover{color:var(--bg4)}nav#menu .menu__burger{display:flex;height:24px;width:24px}nav#menu .menu__burger>*{position:absolute}nav#menu .menu__burger svg{height:inherit;width:inherit;z-index:20}nav#menu .menu__burger input{height:inherit;opacity:0;width:inherit;z-index:30}nav#menu .menu__burger input:checked~ul.menu--vertical{transform:none}nav#menu .menu__burger input:checked~svg{stroke:var(--bg1)}@media (min-width:768px){nav#menu .menu__burger{display:none}}.sidebar{font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace);margin-left:auto;margin-right:auto;max-width:350px;padding-left:2.5rem}.sidebar hr{margin:1.5rem auto}.sidebar svg{fill:var(--fg)}.sidebar__heading{font-size:1.3rem}aside.toc a{color:var(--primary-alt)}aside.toc a:hover{color:var(--primary)}aside.toc ul{list-style:none;margin:0;padding:0}aside.toc ul ul{font-size:.9rem;margin-left:.5rem}aside.toc ul li{line-height:1.1}aside.toc ul li a{display:block;padding:.2rem 0}.jr-basics__image{background:var(--bg1);border:2px solid var(--bg2)}.jr-basics__summary{color:var(--fg3);font-family:Roboto Slab,Georgia,serif;font-family:var(--font-serif);margin:.75rem 0}.jr-basics__profile a:hover{color:var(--fg3)}.jr-basics__profile a:hover svg{fill:var(--fg3)}.tag-cloud{line-height:1.1;text-align:justify}.tag-cloud__tag:hover{color:var(--fg3)}.content-section,.post{border-bottom:2px dotted var(--bg1);padding:2rem 0}.post img:not(figure img){box-sizing:border-box;margin:.5rem 0}.post-header{font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace)}.post-meta__author{font-weight:700}.post-content{margin:1.3rem 0}.post-content a,.post-header a{color:var(--primary-alt)}.post-content a:hover,.post-header a:hover{color:var(--primary)}.post-tags{align-items:center;display:flex;flex-wrap:wrap;gap:.9rem;margin:1rem 0}.post-tag{font-size:.9rem;line-height:1}.post-tag:before{content:"#"}.post-heading__anchor{display:none}h1:hover .post-heading__anchor,h2:hover .post-heading__anchor,h3:hover .post-heading__anchor,h4:hover .post-heading__anchor{display:inline-block}.jr__item-meta{flex-direction:column}.jr-basics__image,.jr-basics__item,.jr-basics__profile-icon,.jr-basics__profile-item,.jr__item-meta{align-items:center;display:flex}.jr-basics__name,.jr-education__area,.jr-publications__name{font-size:1.125rem;font-weight:700}.jr-basics__item{flex-direction:column;text-align:center}.jr-basics__item hr{margin:1.5rem auto}.jr-basics__image{border-radius:50%;height:250px;justify-content:center;overflow:hidden;width:250px}.jr-basics__label,.jr-basics__name,.jr-basics__summary{margin-top:.75rem}.jr-basics__profile svg{height:24px;width:24px}.jr-basics__profile,.jr-basics__profile-item{display:flex}.jr-basics__profile-item{display:flex;padding:.2rem}.jr-basics__profile--col{flex-direction:column}.jr-basics__profile--row{flex-wrap:wrap;justify-content:space-evenly}.jr-basics__profile-icon{padding:0 .75rem}.jr__item-meta{align-items:start;flex-flow:column;font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace)}@media (min-width:768px){.jr__item-meta{align-items:center;flex-flow:row wrap}.jr__date,.jr__date-range{flex-grow:1;text-align:right}.jr-education__institution,.jr-publications__publisher{flex-basis:100%}}.social-share{align-items:center;border-top:2px dotted var(--bg1);display:flex;flex-wrap:wrap;gap:.9rem;margin:3rem 0;padding-top:3rem}.social-share svg{fill:var(--fg);height:24px;width:24px}.social-share svg.icon-tabler{fill:none;stroke:var(--fg)}.social-share__item{background:var(--bg1);display:flex;padding:.5rem}
   
</style>

<link
  rel="preload"
  href="/css/non-critical.d3593a72484a28e4736252e5c81ef7c44e765681722d4ed0f4e854530adca85a3fe3dc4d11828100566e8fb31736d16948fc8071cf1285343211314dc3c7c3fd.css"
  as="style"
  onload="this.onload=null;this.rel='stylesheet'"
  
    integrity="sha512-01k6ckhKKORzYlLlyB73xE52VoFyLU7Q9OhUUwrcqFo/49xNEYKBAFZuj7MXNtFpSPyAcc8ShTQyETFNw8fD/Q=="
  
/>


<link
  id="prism-dark"
  rel="preload"
  href="/prism-themes/prism-gruvbox-dark.min.54aecc64074623a4f9898544dcbdab9e804f1560ef0b38f4cf8e10fcaaf72264e798cb407c601aca6ecd833ec4eb93d66535581f18d45ba202cf848b70dbc332.css"
  as="style"
  onload="this.onload=null;this.rel='stylesheet'"
  integrity="sha512-VK7MZAdGI6T5iYVE3L2rnoBPFWDvCzj0z44Q/Kr3ImTnmMtAfGAaym7Ngz7E65PWZTVYHxjUW6ICz4SLcNvDMg=="
  
/>


<link
  id="prism-light"
  rel="preload"
  href="/prism-themes/prism-gruvbox-light.min.42a221741efe997fcc94187c39d63c555560678789ac9ca856c74a5f0ddb2aa6c50d38b2ffbecc7a99038cbbd2efa99746e862267f781c559e0cfec10b88a5fc.css"
  as="style"
  onload="this.onload=null;this.rel='stylesheet'"
  
    integrity="sha512-QqIhdB7&#43;mX/MlBh8OdY8VVVgZ4eJrJyoVsdKXw3bKqbFDTiy/77MepkDjLvS76mXRuhiJn94HFWeDP7BC4il/A=="
  
  disabled
/>

<noscript>
  
    <link
      rel="stylesheet"
      href="/prism-themes/prism-gruvbox-dark.min.54aecc64074623a4f9898544dcbdab9e804f1560ef0b38f4cf8e10fcaaf72264e798cb407c601aca6ecd833ec4eb93d66535581f18d45ba202cf848b70dbc332.css"
      
        integrity="sha512-VK7MZAdGI6T5iYVE3L2rnoBPFWDvCzj0z44Q/Kr3ImTnmMtAfGAaym7Ngz7E65PWZTVYHxjUW6ICz4SLcNvDMg=="
      
    />
  


  <link
    rel="stylesheet"
    href="/css/non-critical.d3593a72484a28e4736252e5c81ef7c44e765681722d4ed0f4e854530adca85a3fe3dc4d11828100566e8fb31736d16948fc8071cf1285343211314dc3c7c3fd.css"
    
      integrity="sha512-01k6ckhKKORzYlLlyB73xE52VoFyLU7Q9OhUUwrcqFo/49xNEYKBAFZuj7MXNtFpSPyAcc8ShTQyETFNw8fD/Q=="
    
  />
</noscript>


  

  




<script>
  (()=>{function c(){if(localStorage&&localStorage.getItem("theme"))return localStorage.getItem("theme");if(window.matchMedia)return window.matchMedia("(prefers-color-scheme: light)").matches?"light":"dark"}function n(t){document.documentElement.setAttribute("data-theme",t);let e=document.getElementById("prism-dark"),i=document.getElementById("prism-light");e.toggleAttribute("disabled",t==="light"),i.toggleAttribute("disabled",t==="dark"),localStorage.setItem("theme",t)}var o=c();o&&n(o);function l(t){let e=t.currentTarget.classList.contains("light--hidden")?"light":"dark";n(e)}document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".theme__toggle").forEach(e=>{e.addEventListener("click",l)})});})();

</script>


  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
<link rel="manifest" href="/site.webmanifest" />
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#282828" />
<meta name="msapplication-TileColor" content="#282828" />
<meta name="theme-color" content="#282828" />



  
  

</head>

  <body>
    <div class="layout">
      <header>
  <a
    class="logo"
    href="/"
  >
    
      <div class="logo__text">relopezbriega</div>
    
    <div class="logo__chevron">></div>
    <div class="logo__cursor">█</div>
  </a>

  <div class="search">
    <input
      id="search__text"
      type="search"
      placeholder="Buscar..."
      aria-label="Search"
      autocomplete="off"
    />
    <div id="search__suggestions" class="search__suggestions--hidden"></div>
  </div>

  <nav id="menu">
    <ul class="menu--horizontal">
      
        <li class="menu__item">
          <a href="/blog">Articulos</a>
        </li>
      
        <li class="menu__item">
          <a href="/conversor-fecha-juliana">Conversor-Juliana</a>
        </li>
      
        <li class="menu__item">
          <a href="https://iaarbook.github.io/">Libro</a>
        </li>
      
        <li class="menu__item">
          <a href="/cv">CV</a>
        </li>
      
        <li class="menu__item">
          <a href="/contacto">Contacto</a>
        </li>
      
        <li class="menu__item">
          <a href="/acerca">Acerca</a>
        </li>
      
    </ul>

    <div class="menu__burger">
      
      <input class="menu__item" type="checkbox" aria-label="Open main menu" />

      
<svg
  xmlns="http://www.w3.org/2000/svg"
  width="24"
  height="24"
  viewBox="0 0 24 24"
  fill="none"
  stroke="currentColor"
  stroke-width="2"
  stroke-linecap="round"
  stroke-linejoin="round"
  class="icon icon-tabler icons-tabler-outline icon-tabler-menu-2"
>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 6l16 0" />
  <path d="M4 12l16 0" />
  <path d="M4 18l16 0" />
</svg>




      <ul class="menu--vertical">
        
          <li>
            <a class="menu__item" href="/blog">Articulos</a>
          </li>
        
          <li>
            <a class="menu__item" href="/conversor-fecha-juliana">Conversor-Juliana</a>
          </li>
        
          <li>
            <a class="menu__item" href="https://iaarbook.github.io/">Libro</a>
          </li>
        
          <li>
            <a class="menu__item" href="/cv">CV</a>
          </li>
        
          <li>
            <a class="menu__item" href="/contacto">Contacto</a>
          </li>
        
          <li>
            <a class="menu__item" href="/acerca">Acerca</a>
          </li>
        
      </ul>
    </div>
  </nav>

  <button class="theme__toggle light--hidden" aria-label="Toggle light mode">
    
<svg
  xmlns="http://www.w3.org/2000/svg"
  width="24"
  height="24"
  viewBox="0 0 24 24"
  fill="none"
  stroke="currentColor"
  stroke-width="2"
  stroke-linecap="round"
  stroke-linejoin="round"
  class="icon icon-tabler icons-tabler-outline icon-tabler-sun"
>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M12 12m-4 0a4 4 0 1 0 8 0a4 4 0 1 0 -8 0" />
  <path d="M3 12h1m8 -9v1m8 8h1m-9 8v1m-6.4 -15.4l.7 .7m12.1 -.7l-.7 .7m0 11.4l.7 .7m-12.1 -.7l-.7 .7" />
</svg>


  </button>

  <button class="theme__toggle dark--hidden" aria-label="Toggle dark mode">
    
<svg
  xmlns="http://www.w3.org/2000/svg"
  width="24"
  height="24"
  viewBox="0 0 24 24"
  fill="none"
  stroke="currentColor"
  stroke-width="2"
  stroke-linecap="round"
  stroke-linejoin="round"
  class="icon icon-tabler icons-tabler-outline icon-tabler-moon"
>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
</svg>


  </button>
</header>

      <main>
        <div class="content">
          
  <article class="post">
    <div class="post-header">
      <h1>Ejemplo de Machine Learning con Python - Selección de atributos</h1>
      <div class="post-meta"><span>2016-04-15</span><span> by </span><span class="post-meta__author">Raul E Lopez Briega</span>
    <div class="post-tags">
      <a class="post-tag" href="https://relopezbriega.github.io/tags/python">python</a><a class="post-tag" href="https://relopezbriega.github.io/tags/estadistica">estadistica</a><a class="post-tag" href="https://relopezbriega.github.io/tags/programacion">programacion</a><a class="post-tag" href="https://relopezbriega.github.io/tags/machine-learning">machine&#8209;learning</a><a class="post-tag" href="https://relopezbriega.github.io/tags/analisis-de-datos">analisis&#8209;de&#8209;datos</a>
    </div>
  

  
</div>

    </div>

    <div class="post-content">
      <p><em>Esta notebook fue creada originalmente como un blog post por <a
  href="/cv/"
  
  
>Raúl E. López Briega</a> en <a
  href="https://relopezbriega.github.io"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Matemáticas, Analisis de datos y Python</a>. El contenido esta bajo la licencia BSD.</em></p>
<img alt="Machine Learning" title="Machine Learning" src="https://relopezbriega.github.io/images/machine-learning.jpg">
<h2 id="introducción">Introducción<a href="#introducci%c3%b3n" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>Continuando donde nos quedamos en el artículo anterior <a
  href="https://relopezbriega.github.io/blog/2016/04/08/ejemplo-de-machine-learning-con-python-preprocesamiento-y-exploracion/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Ejemplo de Machine Learning - preprocesamiento y exploración</a>; ahora es tiempo de ingresar en el terreno de la <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a>.</p>
<h2 id="en-qué-consiste-la-selección-de-atributos">¿En qué consiste la selección de atributos?<a href="#en-qu%c3%a9-consiste-la-selecci%c3%b3n-de-atributos" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>La <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a> es el proceso por el cual seleccionamos un subconjunto de atributos (representados por cada una de las columnas en un <a
  href="https://es.wikipedia.org/wiki/Conjunto_de_datos"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>dataset</a> de forma tabular) que son más relevantes para la construcción del modelo predictivo sobre el que estamos trabajando.</p>
<p>Este proceso, no se debe confundir con el de <a
  href="https://en.wikipedia.org/wiki/Dimensionality_reduction"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>reducción de dimensiones</a>; si bien ambos procesos buscan reducir el número de atributos en nuestro <a
  href="https://es.wikipedia.org/wiki/Conjunto_de_datos"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>dataset</a>; este último lo hace por medio de la creación de nuevos atributos que son combinaciones de los anteriores; mientras que en el proceso de <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a>, intentamos incluir y excluir los atributos prácticamente sin modificarlos.</p>
<p>El proceso de <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a> es tanto un arte como una ciencia, en donde el conocimiento sobre el problema y la intuición son sumamente importantes. El objetivo de la <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a> es triple: mejorar la capacidad predictiva de nuestro modelo, proporcionando modelos predictivos más rápidos y eficientes, y proporcionar una mejor comprensión del proceso subyacente que generó los datos. Los métodos de <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a> se pueden utilizar para identificar y eliminar los atributos innecesarios, irrelevantes y redundantes que no contribuyen a la exactitud del modelo predictivo o incluso puedan disminuir su precisión.</p>
<h2 id="beneficios-de-la-selección-de-atributos">Beneficios de la selección de atributos<a href="#beneficios-de-la-selecci%c3%b3n-de-atributos" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>Uno de los principales beneficios de la <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a> esta plasmado por la famosa frase <em><strong>&ldquo;Menos es más&rdquo;</strong></em> del arquitecto <a
  href="https://es.wikipedia.org/wiki/Ludwig_Mies_van_der_Rohe"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Ludwig Mies van der Rohe</a>, precursor del <a
  href="https://es.wikipedia.org/wiki/Minimalismo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>minimalismo</a>. Menos atributos son deseables ya que reduce la complejidad del modelo, y un modelo más simple es más fácil de entender y explicar.</p>
<p>Otros beneficios adicionales que nos proporciona una buena <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a> antes de comenzar con el armado del modelo, son:</p>
<ul>
<li><strong>Reduce el <a
  href="https://es.wikipedia.org/wiki/Sobreajuste"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>sobreentrenamiento</a></strong>: Menos datos redundantes significan menos oportunidades para tomar decisiones sobre la base de ruido.</li>
<li><strong>Mejora la precisión</strong>: Menos datos engañosos se convierten en una mejora en la exactitud del modelo.</li>
<li><strong>Reduce el tiempo de entrenamiento</strong>: Menos datos significa que los algoritmos aprenden más rápidamente.</li>
</ul>
<h2 id="selección-de-atributos-univariante-o-multivariante">Selección de atributos univariante o multivariante<a href="#selecci%c3%b3n-de-atributos-univariante-o-multivariante" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>Una cosa que no debemos pasar por alto en el proceso de <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a>, es la relación que puede existir entre ellos. Es decir que debemos considerar seleccionar o eliminar un atributo en forma individual (<a
  href="https://en.wikipedia.org/wiki/Univariate_analysis"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>univariante</a>) o un un grupo de atributos en forma conjunta (<a
  href="https://es.wikipedia.org/wiki/An%C3%A1lisis_multivariante"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>multivariante</a>). Esto también va a depender del problema con el que estemos tratando y del modelo que elijamos. Por ejemplo si elegimos como modelo un <a
  href="https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>clasificador bayesiano ingenuo</a>, el modelo asume que cada atributo es independiente del resto, por lo tanto, podríamos utilizar un enfoque <a
  href="https://en.wikipedia.org/wiki/Univariate_analysis"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>univariante</a> sin problemas; en cambio si elegimos como modelo una <a
  href="https://es.wikipedia.org/wiki/Red_neuronal_artificial"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>red neuronal</a>, este último no asume la independencia de los atributos, sino que utiliza todas la que dispone; por lo tanto aquí deberíamos seguir un enfoque <a
  href="https://es.wikipedia.org/wiki/An%C3%A1lisis_multivariante"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>multivariante</a> para seleccionar los atributos.</p>
<h2 id="algoritmos-para-selección-de-atributos">Algoritmos para selección de atributos<a href="#algoritmos-para-selecci%c3%b3n-de-atributos" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>Podemos encontrar dos clases generales de algoritmos de <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a>: los métodos de filtrado, y los métodos empaquetados.</p>
<h3 id="métodos-de-filtrado">Métodos de filtrado<a href="#m%c3%a9todos-de-filtrado" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>Estos métodos aplican una medida estadística para asignar una puntuación a cada atributo. Los atributos luego son clasificados de acuerdo a su puntuación y son, o bien seleccionados para su conservación o eliminados del conjunto de datos. Los métodos de filtrado son a menudo <a
  href="https://en.wikipedia.org/wiki/Univariate_analysis"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>univariantes</a> y consideran a cada atributo en forma independiente, o con respecto a la variable dependiente.</p>
<p>Ejemplos de estos métodos son: <a
  href="https://es.wikipedia.org/wiki/Prueba_%CF%87%C2%B2"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>prueba de Chi cuadrado</a>, <a
  href="https://es.wikipedia.org/wiki/Prueba_F_de_Fisher"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>prueba F de Fisher</a>, <a
  href="https://en.wikipedia.org/wiki/Information_gain_ratio"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>ratio de ganancia de información</a> y los <a
  href="https://es.wikipedia.org/wiki/Correlaci%C3%B3n"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>coeficientes de correlación</a>.</p>
<h3 id="métodos-empaquetados">Métodos empaquetados<a href="#m%c3%a9todos-empaquetados" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>Estos métodos consideran la selección de un conjunto de atributos como un problema de búsqueda, en donde las diferentes combinaciones son evaluadas y comparadas. Para hacer estas evaluaciones se utiliza un modelo predictivo y luego se asigna una puntuación a cada combinación basada en la precisión del modelo.</p>
<p>Un ejemplo de este método es el algoritmo de eliminación recursiva de atributos.</p>
<h2 id="ejemplo">Ejemplo<a href="#ejemplo" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>Pasamos ahora a ver como podemos aplicar todo esto al caso en el que veníamos trabajando en el el <a
  href="https://relopezbriega.github.io/blog/2016/04/08/ejemplo-de-machine-learning-con-python-preprocesamiento-y-exploracion/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>artículo anterior</a>. Pero antes, terminemos con algunas tareas de preprocesamiento adicionales.</p>
<details>
  <summary>Ver Código</summary>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># &lt;!-- collapse=True --&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Importando las librerías que vamos a utilizar</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np 
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt 
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> seaborn <span style="color:#66d9ef">as</span> sns 
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.cross_validation <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_selection <span style="color:#f92672">import</span> SelectKBest
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_selection <span style="color:#f92672">import</span> f_classif
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_selection <span style="color:#f92672">import</span> RFE
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> ExtraTreesClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># graficos incrustados</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">%</span>matplotlib inline
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># parametros esteticos de seaborn</span>
</span></span><span style="display:flex;"><span>sns<span style="color:#f92672">.</span>set_palette(<span style="color:#e6db74">&#34;deep&#34;</span>, desat<span style="color:#f92672">=</span><span style="color:#ae81ff">.6</span>)
</span></span><span style="display:flex;"><span>sns<span style="color:#f92672">.</span>set_context(rc<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#34;figure.figsize&#34;</span>: (<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">4</span>)})
</span></span></code></pre></div></details>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># importando el dataset preprocesado.</span>
</span></span><span style="display:flex;"><span>ONG_data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;LEARNING_procesado.csv&#39;</span>, header<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Agregando la columna AGE2</span>
</span></span><span style="display:flex;"><span>AGE2 <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>cut(ONG_data[<span style="color:#e6db74">&#39;AGE&#39;</span>], range(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">10</span>))
</span></span><span style="display:flex;"><span>ONG_data[<span style="color:#e6db74">&#39;AGE2&#39;</span>] <span style="color:#f92672">=</span> AGE2
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Eliminar columnas con donaciones superiores a 60 (atípicos)</span>
</span></span><span style="display:flex;"><span>ONG_data <span style="color:#f92672">=</span> ONG_data[ONG_data<span style="color:#f92672">.</span>DONOR_AMOUNT <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">60</span>]
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Convertir datos categoricos a numericos</span>
</span></span><span style="display:flex;"><span>tipos <span style="color:#f92672">=</span> ONG_data<span style="color:#f92672">.</span>columns<span style="color:#f92672">.</span>to_series()<span style="color:#f92672">.</span>groupby(ONG_data<span style="color:#f92672">.</span>dtypes)<span style="color:#f92672">.</span>groups
</span></span><span style="display:flex;"><span>ctext <span style="color:#f92672">=</span> tipos[np<span style="color:#f92672">.</span>dtype(<span style="color:#e6db74">&#39;object&#39;</span>)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> ctext:
</span></span><span style="display:flex;"><span>    ONG_data[c], _ <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>factorize(ONG_data[c])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ONG_data[<span style="color:#e6db74">&#39;AGE2&#39;</span>], _ <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>factorize(ONG_data[<span style="color:#e6db74">&#39;AGE2&#39;</span>])
</span></span></code></pre></div><p>Con estas manipulaciones lo que hicimos es cargar en memoria el <a
  href="https://es.wikipedia.org/wiki/Conjunto_de_datos"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>dataset</a> que prepocesamos anteriormente, le agregamos la nueva columna AGE2, ya que es mejor tener la edad agrupada en rangos en lugar de individualmente, luego eliminamos los <a
  href="https://es.wikipedia.org/wiki/Valor_at%C3%ADpico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>valores atípicos</a> que habíamos detectado; y por último, reemplazamos con su equivalente numérico a todas las <a
  href="https://relopezbriega.github.io/blog/2016/02/29/analisis-de-datos-categoricos-con-python/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>variables categóricas</a>; ya que para los algoritmos de <a
  href="https://scikit-learn.org/stable/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Scikit-learn</a> es mucho más eficiente trabajar con variables numéricas.</p>
<p>Ahora sí, ya estamos en condiciones de poder comenzar a aplicar algunos de los algoritmos de <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a>, comencemos con un simple algoritmo <a
  href="https://en.wikipedia.org/wiki/Univariate_analysis"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>univariante</a> que aplica el método de filtrado. Para esto vamos a utilizar los objetos <code>SelectKBest</code> y <code>f_classif</code> del paquete <code>sklearn.feature_selection</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Separamos las columnas objetivo</span>
</span></span><span style="display:flex;"><span>donor_flag <span style="color:#f92672">=</span> ONG_data[<span style="color:#e6db74">&#39;DONOR_FLAG&#39;</span>]
</span></span><span style="display:flex;"><span>donor_amount <span style="color:#f92672">=</span> ONG_data[<span style="color:#e6db74">&#39;DONOR_AMOUNT&#39;</span>]
</span></span><span style="display:flex;"><span>indice <span style="color:#f92672">=</span> ONG_data[<span style="color:#e6db74">&#39;IDX&#39;</span>]
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Aplicando el algoritmo univariante de prueba F.</span>
</span></span><span style="display:flex;"><span>k <span style="color:#f92672">=</span> <span style="color:#ae81ff">15</span>  <span style="color:#75715e"># número de atributos a seleccionar</span>
</span></span><span style="display:flex;"><span>entrenar <span style="color:#f92672">=</span> ONG_data<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;DONOR_FLAG&#39;</span>, <span style="color:#e6db74">&#39;DONOR_AMOUNT&#39;</span>, <span style="color:#e6db74">&#39;IDX&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>columnas <span style="color:#f92672">=</span> list(entrenar<span style="color:#f92672">.</span>columns<span style="color:#f92672">.</span>values)
</span></span><span style="display:flex;"><span>seleccionadas <span style="color:#f92672">=</span> SelectKBest(f_classif, k<span style="color:#f92672">=</span>k)<span style="color:#f92672">.</span>fit(entrenar, donor_flag)
</span></span><span style="display:flex;"><span>atrib <span style="color:#f92672">=</span> seleccionadas<span style="color:#f92672">.</span>get_support()
</span></span><span style="display:flex;"><span>atributos <span style="color:#f92672">=</span> [columnas[i] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> list(atrib<span style="color:#f92672">.</span>nonzero()[<span style="color:#ae81ff">0</span>])]
</span></span><span style="display:flex;"><span>atributos
</span></span></code></pre></div><pre><code>['ODATEDW',
 'PEPSTRFL',
 'HVP3',
 'CARDPROM',
 'NUMPROM',
 'RAMNT_8',
 'RAMNT_16',
 'NGIFTALL',
 'CARDGIFT',
 'LASTGIFT',
 'LASTDATE',
 'FISTDATE',
 'AVGGIFT',
 'RFA_2F',
 'RFA_2A']
</code></pre>
<p>Como podemos ver, el algoritmo nos seleccionó la cantidad de atributos que le indicamos; en este ejemplo decidimos seleccionar solo 15; obviamente, cuando armemos nuestro modelo final vamos a tomar un número mayor de atributos.</p>
<h3 id="cómo-funciona">¿Cómo funciona?<a href="#c%c3%b3mo-funciona" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>Este algoritmo selecciona a los mejores atributos basándose en una prueba estadística <a
  href="https://en.wikipedia.org/wiki/Univariate_analysis"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>univariante</a>. Al objeto <code>SelectKBest</code> le pasamos la prueba estadística que vamos a a aplicar, en este caso una <a
  href="https://es.wikipedia.org/wiki/Prueba_F_de_Fisher"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>prueba F</a> definida por el objeto <code>f_classif</code>, junto con el número de atributos a seleccionar. El algoritmo va a aplicar la prueba a todos los atributos y va a seleccionar los que mejor resultado obtuvieron.</p>
<p>Ahora veamos como funciona el algoritmo de <strong>Eliminación Recursiva de atributos</strong>. Para este caso, vamos a utilizar como nuestro modelo predictivo el algoritmo <a
  href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>ExtraTreesClassifier</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Algoritmo de Eliminación Recursiva de atributos con ExtraTrees</span>
</span></span><span style="display:flex;"><span>modelo <span style="color:#f92672">=</span> ExtraTreesClassifier()
</span></span><span style="display:flex;"><span>era <span style="color:#f92672">=</span> RFE(modelo, <span style="color:#ae81ff">15</span>)  <span style="color:#75715e"># número de atributos a seleccionar</span>
</span></span><span style="display:flex;"><span>era <span style="color:#f92672">=</span> era<span style="color:#f92672">.</span>fit(entrenar, donor_flag)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># imprimir resultados</span>
</span></span><span style="display:flex;"><span>atrib <span style="color:#f92672">=</span> era<span style="color:#f92672">.</span>support_
</span></span><span style="display:flex;"><span>atributos <span style="color:#f92672">=</span> [columnas[i] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> list(atrib<span style="color:#f92672">.</span>nonzero()[<span style="color:#ae81ff">0</span>])]
</span></span><span style="display:flex;"><span>atributos
</span></span></code></pre></div><pre><code>['OSOURCE',
 'ZIP',
 'VIETVETS',
 'WWIIVETS',
 'POP901',
 'HV1',
 'PEC2',
 'TPE13',
 'EIC4',
 'EIC14',
 'VC2',
 'CARDPROM',
 'MINRDATE',
 'MAXRDATE',
 'TIMELAG']
</code></pre>
<h3 id="cómo-funciona-1">¿Cómo funciona?<a href="#c%c3%b3mo-funciona-1" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>En este algoritmo, dado un modelo predictivo que asigna un coeficiente de importancia a cada atributo (como ExtraTreesClassifier), el objetivo de la <em>Eliminación Recursiva de atributos</em> es ir seleccionado en forma recursiva un número cada vez más pequeño de atributos. Primero comienza con todos los atributos del <a
  href="https://es.wikipedia.org/wiki/Conjunto_de_datos"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>dataset</a> y luego en cada pasada va eliminando aquellos que tenga el menor coeficiente de importancia hasta alcanzar el número de atributos deseado.</p>
<p>Si vemos los 15 atributos seleccionados por este otro algoritmo, existen muchas diferencias con los que selecciono el modelo anterior; en general, la Eliminación Recursiva de atributos suele ser mucho más precisa, pero también consume mucho más tiempo y recursos, ya que requiere que entrenemos a un <em>modelo predictivo</em> para poder obtener sus resultados.</p>
<p>Por último, también podríamos utilizar ese coeficiente de importancia que nos proporciona el modelo como una guía adicional para refinar nuestra <a
  href="https://en.wikipedia.org/wiki/Feature_selection"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>selección de atributos</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Importancia de atributos.</span>
</span></span><span style="display:flex;"><span>modelo<span style="color:#f92672">.</span>fit(entrenar, donor_flag)
</span></span><span style="display:flex;"><span>modelo<span style="color:#f92672">.</span>feature_importances_[:<span style="color:#ae81ff">15</span>]
</span></span></code></pre></div><pre><code>array([  2.59616058e-03,   3.03252110e-03,   2.71464477e-03,
         2.51952243e-03,   2.34433609e-03,   6.01722535e-04,
         4.82782938e-04,   2.24732045e-03,   2.07872966e-03,
         1.29249803e-03,   1.17189225e-03,   9.77218420e-06,
         6.12421074e-04,   5.79137133e-05,   2.40594405e-03])
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 15 coeficientes más altos</span>
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>sort(modelo<span style="color:#f92672">.</span>feature_importances_)[::<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>][:<span style="color:#ae81ff">15</span>]
</span></span></code></pre></div><pre><code>array([ 0.00369165,  0.00353173,  0.00348298,  0.00336095,  0.00331946,
        0.00331828,  0.00331345,  0.00326505,  0.00316758,  0.00316587,
        0.00313431,  0.00311334,  0.00310065,  0.00307309,  0.00304518])
</code></pre>
<p>Analicemos algunos de estos atributos en forma individual para tener una idea de cuanto puede ser que aporten a la exactitud del modelo. Podríamos comparar por ejemplo, el promedio de donaciones que podríamos obtener con este atributo contra el promedio de todo el <a
  href="https://es.wikipedia.org/wiki/Conjunto_de_datos"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>dataset</a>. Tomemos por ejemplo al atributo LASTGIFT que representa el importe de la última donación que realizó cada persona incluida en el conjunto de datos. En principio parece lógico que este atributo sea significativo para el modelo, ya que si donó en el pasado, hay bastantes posibilidades de que vuelva a donar en esta oportunidad.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Probabilidad de ser donante de todo el dataset.</span>
</span></span><span style="display:flex;"><span>prob_gral <span style="color:#f92672">=</span> (ONG_data[ONG_data<span style="color:#f92672">.</span>DONOR_AMOUNT <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>][<span style="color:#e6db74">&#39;DONOR_AMOUNT&#39;</span>]<span style="color:#f92672">.</span>count()  \
</span></span><span style="display:flex;"><span>                   <span style="color:#f92672">/</span> ONG_data[<span style="color:#e6db74">&#39;DONOR_AMOUNT&#39;</span>]<span style="color:#f92672">.</span>count()) <span style="color:#f92672">*</span> <span style="color:#ae81ff">100.0</span>
</span></span><span style="display:flex;"><span>prob_gral 
</span></span></code></pre></div><pre><code>5.0377358490566033
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Probabilidad de realizar donanción con LASTGIFT &lt;= 10</span>
</span></span><span style="display:flex;"><span>lastgift10 <span style="color:#f92672">=</span> (ONG_data[(ONG_data<span style="color:#f92672">.</span>DONOR_AMOUNT <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>) <span style="color:#f92672">&amp;</span>
</span></span><span style="display:flex;"><span>                            (ONG_data<span style="color:#f92672">.</span>LASTGIFT <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">10</span>)][<span style="color:#e6db74">&#39;DONOR_AMOUNT&#39;</span>]<span style="color:#f92672">.</span>count()  \
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">/</span> ONG_data[ONG_data<span style="color:#f92672">.</span>LASTGIFT <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">10</span>][<span style="color:#e6db74">&#39;DONOR_AMOUNT&#39;</span>]<span style="color:#f92672">.</span>count()) <span style="color:#f92672">*</span> <span style="color:#ae81ff">100.0</span>
</span></span><span style="display:flex;"><span>lastgift10
</span></span></code></pre></div><pre><code>6.9347104389524157
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># graficando los resultados</span>
</span></span><span style="display:flex;"><span>lastgift <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>Series({<span style="color:#e6db74">&#39;promedio gral&#39;</span>: prob_gral, <span style="color:#e6db74">&#39;lastgift&lt;=10&#39;</span>: lastgift10})
</span></span><span style="display:flex;"><span>plot<span style="color:#f92672">=</span>lastgift<span style="color:#f92672">.</span>plot(kind<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;barh&#39;</span>, 
</span></span><span style="display:flex;"><span>                   color<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;blue&#39;</span>, <span style="color:#e6db74">&#39;green&#39;</span>])<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;Pobabilidad de donar&#39;</span>)
</span></span></code></pre></div><p>



  
  
  <img
    src="/MachineLearningPractica2_files/MachineLearningPractica2_20_0.png"
    alt="png"
    
    loading="lazy"
    width="530"
    height="266"
  />






</p>
<p>Este último gráfico nos muestra claramente que con un valor del atributo LASTGIFT menor o igual a 10 las probabilidades de que esa persona realice una donación mejoran, pero veamos que pasa con el importe de la donación.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># importe promedio de donación general</span>
</span></span><span style="display:flex;"><span>donacion_prom <span style="color:#f92672">=</span> ONG_data[ONG_data<span style="color:#f92672">.</span>DONOR_AMOUNT <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>][<span style="color:#e6db74">&#39;DONOR_AMOUNT&#39;</span>]<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>donacion_prom
</span></span></code></pre></div><pre><code>14.889109446525177
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># importe promedio de donación lastgift &lt;= 10</span>
</span></span><span style="display:flex;"><span>lastgift10_imp <span style="color:#f92672">=</span> ONG_data[(ONG_data<span style="color:#f92672">.</span>DONOR_AMOUNT <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>) <span style="color:#f92672">&amp;</span> 
</span></span><span style="display:flex;"><span>                         (ONG_data<span style="color:#f92672">.</span>LASTGIFT <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">10</span>)][<span style="color:#e6db74">&#39;DONOR_AMOUNT&#39;</span>]<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>lastgift10_imp
</span></span></code></pre></div><pre><code>8.7553191489361701
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># graficando los resultados</span>
</span></span><span style="display:flex;"><span>lastgift <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>Series({<span style="color:#e6db74">&#39;imp promedio gral&#39;</span>: donacion_prom, 
</span></span><span style="display:flex;"><span>                      <span style="color:#e6db74">&#39;lastgift&lt;=10&#39;</span>: lastgift10_imp})
</span></span><span style="display:flex;"><span>plot<span style="color:#f92672">=</span>lastgift<span style="color:#f92672">.</span>plot(kind<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;barh&#39;</span>, 
</span></span><span style="display:flex;"><span>                   color<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;blue&#39;</span>, <span style="color:#e6db74">&#39;green&#39;</span>]
</span></span><span style="display:flex;"><span>                  )<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;importe promedio de donación&#39;</span>)
</span></span></code></pre></div><p>



  
  
  <img
    src="/MachineLearningPractica2_files/MachineLearningPractica2_24_0.png"
    alt="png"
    
    loading="lazy"
    width="552"
    height="266"
  />






</p>
<p>Aquí vemos, que si bien las probabilidades de que sea un donador mejoran, el importe que se dona esta por debajo del promedio. En el caso de este atributo podemos ver que existe una <a
  href="https://es.wikipedia.org/wiki/Correlaci%C3%B3n"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>correlación</a> inversa entre el importe de donación y la probabilidad de hacer una donación a la ONG.</p>
<p>Hasta aquí llegamos en este artículo, la idea es que luego, cuando tengamos armado el modelo, podamos jugar con distintas combinaciones de atributos y ver como se comporta el modelo hasta alcanzar la combinación ideal de atributos. No se pierdan los próximos artículos!</p>
<p>Saludos!</p>
<p><em>Este post fue escrito utilizando IPython notebook. Pueden descargar este <a
  href="https://github.com/relopezbriega/relopezbriega.github.io/blob/master/downloads/MachineLearningPractica2.ipynb"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>notebook</a> o ver su version estática en <a
  href="https://nbviewer.ipython.org/github/relopezbriega/relopezbriega.github.io/blob/master/downloads/MachineLearningPractica2.ipynb"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>nbviewer</a>.</em></p>

    </div>

    
      


  <div class="social-share">
    <strong class="social-share__heading">Share this post: </strong>
    
      
      
      
      <a
        class="social-share__item"
        href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Frelopezbriega.github.io%2Fblog%2F2016%2F04%2F15%2Fejemplo-de-machine-learning-con-python-seleccion-de-atributos%2F"
        target="_blank"
        rel="noreferrer"
      >
        
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Facebook</title><path d="M9.101 23.691v-7.98H6.627v-3.667h2.474v-1.58c0-4.085 1.848-5.978 5.858-5.978.401 0 .955.042 1.468.103a8.68 8.68 0 0 1 1.141.195v3.325a8.623 8.623 0 0 0-.653-.036 26.805 26.805 0 0 0-.733-.009c-.707 0-1.259.096-1.675.309a1.686 1.686 0 0 0-.679.622c-.258.42-.374.995-.374 1.752v1.297h3.919l-.386 2.103-.287 1.564h-3.246v8.245C19.396 23.238 24 18.179 24 12.044c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.628 3.874 10.35 9.101 11.647Z"/></svg>


      </a>
    
      
      
      
      <a
        class="social-share__item"
        href="https://reddit.com/submit?url=https%3A%2F%2Frelopezbriega.github.io%2Fblog%2F2016%2F04%2F15%2Fejemplo-de-machine-learning-con-python-seleccion-de-atributos%2F&amp;title=Ejemplo&#43;de&#43;Machine&#43;Learning&#43;con&#43;Python&#43;-&#43;Selecci%C3%B3n&#43;de&#43;atributos"
        target="_blank"
        rel="noreferrer"
      >
        
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Reddit</title><path d="M12 0C5.373 0 0 5.373 0 12c0 3.314 1.343 6.314 3.515 8.485l-2.286 2.286C.775 23.225 1.097 24 1.738 24H12c6.627 0 12-5.373 12-12S18.627 0 12 0Zm4.388 3.199c1.104 0 1.999.895 1.999 1.999 0 1.105-.895 2-1.999 2-.946 0-1.739-.657-1.947-1.539v.002c-1.147.162-2.032 1.15-2.032 2.341v.007c1.776.067 3.4.567 4.686 1.363.473-.363 1.064-.58 1.707-.58 1.547 0 2.802 1.254 2.802 2.802 0 1.117-.655 2.081-1.601 2.531-.088 3.256-3.637 5.876-7.997 5.876-4.361 0-7.905-2.617-7.998-5.87-.954-.447-1.614-1.415-1.614-2.538 0-1.548 1.255-2.802 2.803-2.802.645 0 1.239.218 1.712.585 1.275-.79 2.881-1.291 4.64-1.365v-.01c0-1.663 1.263-3.034 2.88-3.207.188-.911.993-1.595 1.959-1.595Zm-8.085 8.376c-.784 0-1.459.78-1.506 1.797-.047 1.016.64 1.429 1.426 1.429.786 0 1.371-.369 1.418-1.385.047-1.017-.553-1.841-1.338-1.841Zm7.406 0c-.786 0-1.385.824-1.338 1.841.047 1.017.634 1.385 1.418 1.385.785 0 1.473-.413 1.426-1.429-.046-1.017-.721-1.797-1.506-1.797Zm-3.703 4.013c-.974 0-1.907.048-2.77.135-.147.015-.241.168-.183.305.483 1.154 1.622 1.964 2.953 1.964 1.33 0 2.47-.81 2.953-1.964.057-.137-.037-.29-.184-.305-.863-.087-1.795-.135-2.769-.135Z"/></svg>


      </a>
    
      
      
      
      <a
        class="social-share__item"
        href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Frelopezbriega.github.io%2Fblog%2F2016%2F04%2F15%2Fejemplo-de-machine-learning-con-python-seleccion-de-atributos%2F"
        target="_blank"
        rel="noreferrer"
      >
        
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>


      </a>
    
      
      
      
      <a
        class="social-share__item"
        href="https://x.com/intent/tweet?url=https%3A%2F%2Frelopezbriega.github.io%2Fblog%2F2016%2F04%2F15%2Fejemplo-de-machine-learning-con-python-seleccion-de-atributos%2F&amp;text=Ejemplo&#43;de&#43;Machine&#43;Learning&#43;con&#43;Python&#43;-&#43;Selecci%C3%B3n&#43;de&#43;atributos&amp;via=%7buser_id%7d&amp;hashtags=%7bhash_tags%7d"
        target="_blank"
        rel="noreferrer"
      >
        
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>X</title><path d="M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"/></svg>


      </a>
    
  </div>


    

    
  </article>

        </div>
        <div class="sidebar">
  
    
      <aside class="toc">
        <nav>
          <p class="sidebar__heading">Indice</p>
          <nav id="TableOfContents">
  <ul>
    <li><a href="#introducción">Introducción</a></li>
    <li><a href="#en-qué-consiste-la-selección-de-atributos">¿En qué consiste la selección de atributos?</a></li>
    <li><a href="#beneficios-de-la-selección-de-atributos">Beneficios de la selección de atributos</a></li>
    <li><a href="#selección-de-atributos-univariante-o-multivariante">Selección de atributos univariante o multivariante</a></li>
    <li><a href="#algoritmos-para-selección-de-atributos">Algoritmos para selección de atributos</a>
      <ul>
        <li><a href="#métodos-de-filtrado">Métodos de filtrado</a></li>
        <li><a href="#métodos-empaquetados">Métodos empaquetados</a></li>
      </ul>
    </li>
    <li><a href="#ejemplo">Ejemplo</a>
      <ul>
        <li><a href="#cómo-funciona">¿Cómo funciona?</a></li>
        <li><a href="#cómo-funciona-1">¿Cómo funciona?</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </nav>
      </aside>
      <hr />
    
  

  
  
    <aside class="bio">
      

  <div class="jr__item jr-basics__item">
    
  <div class="jr-basics__image">
    <img
      src="https://0.gravatar.com/avatar/45973a2c27d1bafade36a201a13d784ad93ec68fbeb70d7c44c02b4ba6eaeb40?size=256"
      alt="Picture of Raul E. Lopez Briega"
      width="250"
      height="250"
    />
  </div>



    
      <div class="jr-basics__name">Raul E. Lopez Briega</div>
    

    
      <div class="jr-basics__label">Business Analyst</div>
    

    

    

    

    
      <div class="jr-basics__summary">Profesional en Contabilidad y Administración con amplia experiencia en tecnologías de la información. Especializado en integración de procesos contables y financieros con herramientas IT, y manejo de sistemas ERP como JD Edwards y SAP. Reconocido por mi enfoque en la mejora continua, liderazgo en proyectos y compromiso con la excelencia en resultados. Puedo combinar perfectamente el conocimiento contable y financiero con el conocimiento técnico funcional propio de las herramientas informáticas.</div>
    

    
      

      

      
        <div class="jr-basics__location-city">Buenos Aires, ARG</div>
      

      

      
    

    
      <hr />
      <div class="jr-basics__profile jr-basics__profile--col">
        
          

<a href="https://github.com/relopezbriega" target="_blank" rel="noreferrer me">

<div class="jr-basics__profile-item">
  <div class="jr-basics__profile-icon">
    
    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
  </div>

  
    <div class="jr-basics__profile-username">relopezbriega</div>
  
</div>


</a>

        
      </div>
    

    
      <hr />
      <div class="jr-basics__profile jr-basics__profile--row">
        
          

<a href="https://x.com/relopezbriega" target="_blank" rel="noreferrer me">

<div class="jr-basics__profile-item">
  <div class="jr-basics__profile-icon">
    
    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>X</title><path d="M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"/></svg>
  </div>

  
</div>


</a>

        
          

<a href="https://www.linkedin.com/in/relopezbriega" target="_blank" rel="noreferrer me">

<div class="jr-basics__profile-item">
  <div class="jr-basics__profile-icon">
    
    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
  </div>

  
</div>


</a>

        
          

<a href="https://gravatar.com/raulezequiellopezbriega" target="_blank" rel="noreferrer me">

<div class="jr-basics__profile-item">
  <div class="jr-basics__profile-icon">
    
    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Gravatar</title><path d="M12 0c-1.326 0-2.4 1.074-2.4 2.4v8.4c0 1.324 1.074 2.398 2.4 2.398s2.4-1.074 2.4-2.398V5.21c2.795.99 4.799 3.654 4.799 6.789 0 3.975-3.225 7.199-7.199 7.199S4.801 15.975 4.801 12c0-1.989.805-3.789 2.108-5.091.938-.938.938-2.458 0-3.396s-2.458-.938-3.396 0C1.344 5.686 0 8.686 0 12c0 6.627 5.373 12 12 12s12-5.373 12-12S18.627 0 12 0"/></svg>
  </div>

  
</div>


</a>

        
      </div>
    
  </div>



      
        <hr />
      
    </aside>
  

  
    <aside>
      


  
  
  
  
  
  


  <div class="tag-cloud">
    
      
      
      
      <a
        href="/tags/algebra"
        style="font-size:1.0148626781012497rem"
        class="tag-cloud__tag"
        >algebra</a
      >
    
      
      
      
      <a
        href="/tags/analisis-de-datos"
        style="font-size:1.8099490660932782rem"
        class="tag-cloud__tag"
        >analisis de datos</a
      >
    
      
      
      
      <a
        href="/tags/batman"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >batman</a
      >
    
      
      
      
      <a
        href="/tags/bayes"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >bayes</a
      >
    
      
      
      
      <a
        href="/tags/binario"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >binario</a
      >
    
      
      
      
      <a
        href="/tags/bit"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >bit</a
      >
    
      
      
      
      <a
        href="/tags/boosting"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >boosting</a
      >
    
      
      
      
      <a
        href="/tags/calculo"
        style="font-size:1.4031957969340216rem"
        class="tag-cloud__tag"
        >calculo</a
      >
    
      
      
      
      <a
        href="/tags/caos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >caos</a
      >
    
      
      
      
      <a
        href="/tags/ciencia-de-datos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >ciencia de datos</a
      >
    
      
      
      
      <a
        href="/tags/complejidad"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >complejidad</a
      >
    
      
      
      
      <a
        href="/tags/complejos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >complejos</a
      >
    
      
      
      
      <a
        href="/tags/conjuntos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >conjuntos</a
      >
    
      
      
      
      <a
        href="/tags/decimales"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >decimales</a
      >
    
      
      
      
      <a
        href="/tags/deep-learning"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >deep learning</a
      >
    
      
      
      
      <a
        href="/tags/derivada"
        style="font-size:1.1405492875950014rem"
        class="tag-cloud__tag"
        >derivada</a
      >
    
      
      
      
      <a
        href="/tags/derivadas-parciales"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >derivadas parciales</a
      >
    
      
      
      
      <a
        href="/tags/distribuciones"
        style="font-size:1.355411965696251rem"
        class="tag-cloud__tag"
        >distribuciones</a
      >
    
      
      
      
      <a
        href="/tags/ecuaciones-diferenciales"
        style="font-size:1.1405492875950014rem"
        class="tag-cloud__tag"
        >ecuaciones diferenciales</a
      >
    
      
      
      
      <a
        href="/tags/entropia"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >entropia</a
      >
    
      
      
      
      <a
        href="/tags/estadistica"
        style="font-size:1.6594507124049986rem"
        class="tag-cloud__tag"
        >estadistica</a
      >
    
      
      
      
      <a
        href="/tags/falacias"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >falacias</a
      >
    
      
      
      
      <a
        href="/tags/finanazas"
        style="font-size:1.2297253562024992rem"
        class="tag-cloud__tag"
        >finanazas</a
      >
    
      
      
      
      <a
        href="/tags/fractales"
        style="font-size:1.0148626781012497rem"
        class="tag-cloud__tag"
        >fractales</a
      >
    
      
      
      
      <a
        href="/tags/funcional"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >funcional</a
      >
    
      
      
      
      <a
        href="/tags/futbol"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >futbol</a
      >
    
      
      
      
      <a
        href="/tags/incertidumbre"
        style="font-size:1.2297253562024992rem"
        class="tag-cloud__tag"
        >incertidumbre</a
      >
    
      
      
      
      <a
        href="/tags/inferencia"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >inferencia</a
      >
    
      
      
      
      <a
        href="/tags/infinito"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >infinito</a
      >
    
      
      
      
      <a
        href="/tags/informacion"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >informacion</a
      >
    
      
      
      
      <a
        href="/tags/integral"
        style="font-size:1.1405492875950014rem"
        class="tag-cloud__tag"
        >integral</a
      >
    
      
      
      
      <a
        href="/tags/inteligencia"
        style="font-size:1.0148626781012497rem"
        class="tag-cloud__tag"
        >inteligencia</a
      >
    
      
      
      
      <a
        href="/tags/inteligencia-artificial"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >inteligencia artificial</a
      >
    
      
      
      
      <a
        href="/tags/lenguaje-natural"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >lenguaje natural</a
      >
    
      
      
      
      <a
        href="/tags/limite"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >limite</a
      >
    
      
      
      
      <a
        href="/tags/limites"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >limites</a
      >
    
      
      
      
      <a
        href="/tags/logaritmo"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >logaritmo</a
      >
    
      
      
      
      <a
        href="/tags/logica"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >logica</a
      >
    
      
      
      
      <a
        href="/tags/machine-learning"
        style="font-size:1.7286210450285304rem"
        class="tag-cloud__tag"
        >machine learning</a
      >
    
      
      
      
      <a
        href="/tags/map-reduce"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >map-reduce</a
      >
    
      
      
      
      <a
        href="/tags/matematica"
        style="font-size:1.7719446364353373rem"
        class="tag-cloud__tag"
        >matematica</a
      >
    
      
      
      
      <a
        href="/tags/matplotlib"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >matplotlib</a
      >
    
      
      
      
      <a
        href="/tags/matrices"
        style="font-size:1.0148626781012497rem"
        class="tag-cloud__tag"
        >matrices</a
      >
    
      
      
      
      <a
        href="/tags/mcmc"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >mcmc</a
      >
    
      
      
      
      <a
        href="/tags/metropolis"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >metropolis</a
      >
    
      
      
      
      <a
        href="/tags/modelos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >modelos</a
      >
    
      
      
      
      <a
        href="/tags/monte-carlo"
        style="font-size:1.0148626781012497rem"
        class="tag-cloud__tag"
        >monte carlo</a
      >
    
      
      
      
      <a
        href="/tags/numeros"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >numeros</a
      >
    
      
      
      
      <a
        href="/tags/optimizacion"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >optimizacion</a
      >
    
      
      
      
      <a
        href="/tags/overfitting"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >overfitting</a
      >
    
      
      
      
      <a
        href="/tags/pensamiento"
        style="font-size:1.0148626781012497rem"
        class="tag-cloud__tag"
        >pensamiento</a
      >
    
      
      
      
      <a
        href="/tags/pi"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >pi</a
      >
    
      
      
      
      <a
        href="/tags/probabilidad"
        style="font-size:1.4445880343037487rem"
        class="tag-cloud__tag"
        >probabilidad</a
      >
    
      
      
      
      <a
        href="/tags/programacion"
        style="font-size:1.8216478627850043rem"
        class="tag-cloud__tag"
        >programacion</a
      >
    
      
      
      
      <a
        href="/tags/programacion-lineal"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >programacion lineal</a
      >
    
      
      
      
      <a
        href="/tags/python"
        style="font-size:1.9934738364228022rem"
        class="tag-cloud__tag"
        >python</a
      >
    
      
      
      
      <a
        href="/tags/redes-neuronales"
        style="font-size:1.4031957969340216rem"
        class="tag-cloud__tag"
        >redes neuronales</a
      >
    
      
      
      
      <a
        href="/tags/redundancia"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >redundancia</a
      >
    
      
      
      
      <a
        href="/tags/regex"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >regex</a
      >
    
      
      
      
      <a
        href="/tags/seaborn"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >seaborn</a
      >
    
      
      
      
      <a
        href="/tags/series-de-tiempo"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >series de tiempo</a
      >
    
      
      
      
      <a
        href="/tags/sistemas-dinamicos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >sistemas dinamicos</a
      >
    
      
      
      
      <a
        href="/tags/sobreajuste"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >sobreajuste</a
      >
    
      
      
      
      <a
        href="/tags/tensores"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >tensores</a
      >
    
      
      
      
      <a
        href="/tags/tensorflow"
        style="font-size:1.1405492875950014rem"
        class="tag-cloud__tag"
        >tensorflow</a
      >
    
      
      
      
      <a
        href="/tags/vectores"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >vectores</a
      >
    
      
      
      
      <a
        href="/tags/visualizaciones"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >visualizaciones</a
      >
    
      
      
      
      <a
        href="/tags/xgboost"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >xgboost</a
      >
    
  </div>


    </aside>
  
</div>

      </main>
      <footer>
  <div class="copyright">
    
  </div>
</footer>



  







  
  



<script src="/js/main.cd7795d28b80ce821160de11b7556c4da5149179a3ec7f243e3a53d453b1e1fb7f7d82a21dccd3723d92e160b4a7197e900c7ed135ae3ae33bafcec5c05a05bb.js" integrity="sha512-zXeV0ouAzoIRYN4Rt1VsTaUUkXmj7H8kPjpT1FOx4ft/fYKiHczTcj2S4WC0pxl&#43;kAx&#43;0TWuOuM7r87FwFoFuw=="></script>
<script src="/js/flexsearch.1ab5b109bf2ed66903ae10907394415caa12f5c0ee66bc80088ba135ec4a751f62e4961d6a7303b562e4db724392da85945b763b8e1858ea3fd05cc36f9b8156.js" integrity="sha512-GrWxCb8u1mkDrhCQc5RBXKoS9cDuZryACIuhNexKdR9i5JYdanMDtWLk23JDktqFlFt2O44YWOo/0FzDb5uBVg=="></script>






    </div>
  </body>
</html>
