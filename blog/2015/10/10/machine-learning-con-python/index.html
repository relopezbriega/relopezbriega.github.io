<!DOCTYPE html>
<html
  lang="en"
  data-theme="dark"
>
  <head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  


<link
  rel="preload"
  as="font"
  type="font/woff2"
  href="/fonts/roboto-slab-latin-400.woff2"
  crossorigin="anonymous"
/>

<link
  rel="preload"
  as="font"
  type="font/woff2"
  href="/fonts/roboto-slab-latin-700.woff2"
  crossorigin="anonymous"
/>


<link
  rel="preload"
  as="font"
  type="font/woff2"
  href="/fonts/fira-code-latin-300.woff2"
  crossorigin="anonymous"
/>
<link
  rel="preload"
  as="font"
  type="font/woff2"
  href="/fonts/fira-code-latin-400.woff2"
  crossorigin="anonymous"
/>

<link
  rel="preload"
  as="font"
  type="font/woff2"
  href="/fonts/fira-code-latin-700.woff2"
  crossorigin="anonymous"
/>

  
  
    <meta
      name="robots"
      content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"
    />
  




<title>Machine Learning con Python</title>

<meta
  name="description"
  content=" Machine Learning con Python. Qué es el machine learning, tipos de Machine Learning, sobreajuste, algoritmos más utilizados, librerías de python."
/>

<link rel="canonical" href="https://relopezbriega.github.io/blog/2015/10/10/machine-learning-con-python/" />




  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Machine Learning con Python">
  <meta name="twitter:description" content=" Machine Learning con Python. Qué es el machine learning, tipos de Machine Learning, sobreajuste, algoritmos más utilizados, librerías de python.">

<meta property="og:url" content="https://relopezbriega.github.io/blog/2015/10/10/machine-learning-con-python/">
  <meta property="og:site_name" content="Raul E. Lopez Briega">
  <meta property="og:title" content="Machine Learning con Python">
  <meta property="og:description" content=" Machine Learning con Python. Qué es el machine learning, tipos de Machine Learning, sobreajuste, algoritmos más utilizados, librerías de python.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2015-10-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2015-10-10T00:00:00+00:00">
    <meta property="article:tag" content="Python">
    <meta property="article:tag" content="Estadistica">
    <meta property="article:tag" content="Programacion">
    <meta property="article:tag" content="Machine Learning">
    <meta property="article:tag" content="Analisis De Datos">


  <meta itemprop="name" content="Machine Learning con Python">
  <meta itemprop="description" content=" Machine Learning con Python. Qué es el machine learning, tipos de Machine Learning, sobreajuste, algoritmos más utilizados, librerías de python.">
  <meta itemprop="datePublished" content="2015-10-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2015-10-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="3665">
  <meta itemprop="keywords" content="Python,Estadistica,Programacion,Machine Learning,Analisis De Datos">






  
  
    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-6SZHL0BZZJ"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-6SZHL0BZZJ');
        }
      </script>
    
  




  
  
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/pikaday/1.8.0/css/pikaday.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/pikaday/1.8.0/pikaday.min.js"></script>


    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    }
  };
</script>


  








  
  
  
  


<style>
   
  @font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:100;src:local("Roboto Slab Thin "),local("Roboto Slab-Thin"),url(/fonts/roboto-slab-latin-100.woff2) format("woff2"),url(/fonts/roboto-slab-latin-100.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:200;src:local("Roboto Slab Extra Light "),local("Roboto Slab-Extra Light"),url(/fonts/roboto-slab-latin-200.woff2) format("woff2"),url(/fonts/roboto-slab-latin-200.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:300;src:local("Roboto Slab Light "),local("Roboto Slab-Light"),url(/fonts/roboto-slab-latin-300.woff2) format("woff2"),url(/fonts/roboto-slab-latin-300.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:400;src:local("Roboto Slab Regular "),local("Roboto Slab-Regular"),url(/fonts/roboto-slab-latin-400.woff2) format("woff2"),url(/fonts/roboto-slab-latin-400.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:500;src:local("Roboto Slab Medium "),local("Roboto Slab-Medium"),url(/fonts/roboto-slab-latin-500.woff2) format("woff2"),url(/fonts/roboto-slab-latin-500.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:600;src:local("Roboto Slab SemiBold "),local("Roboto Slab-SemiBold"),url(/fonts/roboto-slab-latin-600.woff2) format("woff2"),url(/fonts/roboto-slab-latin-600.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:700;src:local("Roboto Slab Bold "),local("Roboto Slab-Bold"),url(/fonts/roboto-slab-latin-700.woff2) format("woff2"),url(/fonts/roboto-slab-latin-700.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:800;src:local("Roboto Slab ExtraBold "),local("Roboto Slab-ExtraBold"),url(/fonts/roboto-slab-latin-800.woff2) format("woff2"),url(/fonts/roboto-slab-latin-800.woff) format("woff")}@font-face{font-display:swap;font-family:Roboto Slab;font-style:normal;font-weight:900;src:local("Roboto Slab Black "),local("Roboto Slab-Black"),url(/fonts/roboto-slab-latin-900.woff2) format("woff2"),url(/fonts/roboto-slab-latin-900.woff) format("woff")}@font-face{font-display:swap;font-family:Fira Code;font-style:normal;font-weight:300;src:local("Fira Code Light "),local("Fira Code-Light"),url(/fonts/fira-code-latin-300.woff2) format("woff2"),url(/fonts/fira-code-latin-300.woff) format("woff")}@font-face{font-display:swap;font-family:Fira Code;font-style:normal;font-weight:400;src:local("Fira Code Regular "),local("Fira Code-Regular"),url(/fonts/fira-code-latin-400.woff2) format("woff2"),url(/fonts/fira-code-latin-400.woff) format("woff")}@font-face{font-display:swap;font-family:Fira Code;font-style:normal;font-weight:500;src:local("Fira Code Medium "),local("Fira Code-Medium"),url(/fonts/fira-code-latin-500.woff2) format("woff2"),url(/fonts/fira-code-latin-500.woff) format("woff")}@font-face{font-display:swap;font-family:Fira Code;font-style:normal;font-weight:600;src:local("Fira Code SemiBold "),local("Fira Code-SemiBold"),url(/fonts/fira-code-latin-600.woff2) format("woff2"),url(/fonts/fira-code-latin-600.woff) format("woff")}@font-face{font-display:swap;font-family:Fira Code;font-style:normal;font-weight:700;src:local("Fira Code Bold "),local("Fira Code-Bold"),url(/fonts/fira-code-latin-700.woff2) format("woff2"),url(/fonts/fira-code-latin-700.woff) format("woff")}

/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden],template{display:none}

/*! CC BY-SA 3.0 License | https://stackoverflow.com/a/36118384/1154965 */@keyframes blink{50%{opacity:0}to{opacity:1}}

/*! MIT License | github.com/schnerring/hugo-theme-gruvbox */:root[data-theme=light]{--bg:var(--bg0);--bg0:#fbf1c7;--bg0_h:#f9f5d7;--bg0_s:#f2e5bc;--bg1:#ebdbb2;--bg2:#d5c4a1;--bg3:#bdae93;--bg4:#a89984;--fg:var(--fg1);--fg0:#282828;--fg1:#3c3836;--fg2:#504945;--fg3:#665c54;--fg4:#7c6f64;--gray1:var(--fg4);--gray2:#928374;--red1:#cc241d;--red2:#9d0006;--green1:#98971a;--green2:#797403;--yellow1:#d79921;--yellow2:#b57614;--blue1:#458588;--blue2:#076678;--purple1:#b16286;--purple2:#8f3f71;--aqua1:#689d6a;--aqua2:#427b58;--orange1:#d65d0e;--orange2:#af3a03}[data-theme=light]:root .light--hidden{display:none}:root[data-theme=dark]{--bg:var(--bg0);--bg0:#282828;--bg0_h:#1d2021;--bg0_s:#32302f;--bg1:#3c3836;--bg2:#504945;--bg3:#665c54;--bg4:#7c6f64;--fg:var(--fg1);--fg0:#fbf1c7;--fg1:#ebdbb2;--fg2:#d5c4a1;--fg3:#bdae93;--fg4:#a89984;--gray1:var(--fg4);--gray2:#928374;--red1:#cc241d;--red2:#fb4934;--green1:#98971a;--green2:#b8bb26;--yellow1:#d79921;--yellow2:#fabd2f;--blue1:#458588;--blue2:#83a598;--purple1:#b16286;--purple2:#d3869b;--aqua1:#689d6a;--aqua2:#8ec07c;--orange1:#d65d0e;--orange2:#fe8019}[data-theme=dark]:root .dark--hidden{display:none}:root{--primary:var(--blue1);--primary-alt:var(--blue2);--font-monospace:"Fira Code","Lucida Console",Monaco,monospace;--font-sans-serif:Verdana,Helvetica,sans-serif;--font-serif:"Roboto Slab",Georgia,serif}html{font-family:Roboto Slab,Georgia,serif;font-family:var(--font-serif);font-size:1rem;scroll-behavior:smooth}body{background:var(--bg);color:var(--fg);line-height:1.675;word-wrap:break-word}strong{letter-spacing:.35px}a{color:inherit;-webkit-text-decoration:none;text-decoration:none}a.link--external:after{content:"\2009↗"}img{border:2px solid var(--bg1);height:auto;max-width:100%}::-moz-selection{background:var(--bg4);color:var(--fg0)}::selection{background:var(--bg4);color:var(--fg0)}h1,h2,h3,h4{color:var(--fg0);font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace);font-weight:300;line-height:1.4}h1 code,h2 code,h3 code,h4 code{font-size:1em}h2,h3,h4{border-bottom:1px solid var(--bg1)}h1,h2{font-weight:400}h1{font-size:1.875rem}h2{font-size:1.75rem}h3{font-size:1.625rem}@media (min-width:768px){h1{font-size:2.375rem}h2{font-size:2rem}h3{font-size:1.75rem}}h4{font-size:1.5rem}table{border-collapse:collapse;margin:2rem 0;table-layout:fixed;width:100%}table,td,th{border:1px solid var(--bg1);padding:.5rem}hr{background:var(--bg1);border:none;height:1px;margin:3rem auto;width:80%}blockquote,code,pre{border-radius:.2rem;padding:0 .2em}pre code{padding:0}blockquote,code,pre,th{background:var(--bg1)}code,pre,th{font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace)}code code{background:var(--bg2)}blockquote,pre{padding:1rem}pre{background:var(--bg1)!important;overflow:auto}pre code{background:none}blockquote{border-left:5px solid var(--primary-alt);margin:.5rem 0}blockquote:not(.does-not-exist) code{background:var(--bg2)}blockquote:not(.does-not-exist) p:first-of-type{margin-top:0}blockquote:not(.does-not-exist) p:last-of-type{margin-bottom:0}pre::-webkit-scrollbar{height:.5rem;scrollbar-width:auto}pre::-webkit-scrollbar-track{background:var(--bg2);border-radius:.2rem}pre::-webkit-scrollbar-thumb{background:var(--bg4);border-radius:.2rem}.layout{display:grid;grid-template-areas:"header" "main" "footer";grid-template-rows:auto 1fr auto;height:100vh}main{align-items:start;display:grid;grid-area:main;grid-template-areas:"empty content sidebar";grid-template-columns:1fr minmax(0,650px) 4fr}header{background:var(--bg1);grid-area:header}footer{grid-area:footer}footer,main{margin:.5em 1.1em}.content{grid-area:content}.sidebar{display:none;flex-direction:column;grid-area:sidebar;margin-top:3rem;position:sticky;top:2rem}@media (min-width:992px){.sidebar{display:flex}}header{display:grid;font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace);font-size:1.125rem;grid-template-areas:"heading search nav theme-toggle";grid-template-columns:auto auto 1fr auto;padding:.75rem}.logo{color:var(--fg0);display:flex;font-weight:700;grid-area:heading}.logo:hover .logo__cursor{animation:blink 1s infinite;opacity:1}.logo__chevron,.logo__cursor{margin-left:.5rem}.logo__cursor{opacity:0}.logo__text{display:none}@media (min-width:768px){.logo__text{display:block}}.search{display:flex;grid-area:search;margin:0 1rem}#search__text{background:var(--bg2);border:1px solid var(--bg2);border-radius:.2rem;caret-color:var(--fg);color:var(--fg);outline:none;padding:0 .5rem;width:100%}#search__text:hover{border-color:var(--bg3)}#search__text:focus{border-color:var(--bg4)}#search__text::-moz-placeholder{color:var(--fg3)}#search__text::placeholder{color:var(--fg3)}#search__text[type=search]::-webkit-search-cancel-button{-webkit-appearance:none;appearance:none}#search__suggestions{background:var(--bg);border-radius:.2rem;box-shadow:0 .5rem 1rem var(--bg1);font-family:Roboto Slab,Georgia,serif;font-family:var(--font-serif);left:0;margin-top:2rem;position:absolute;width:95vw;z-index:1000}@media (min-width:768px){.search{position:relative}#search__suggestions{width:60vw}}.search__suggestions--hidden{display:none}.search__suggestion-item{border-bottom:1px dashed var(--bg2);display:grid;grid-template-columns:1fr 2fr}.search__suggestion-item:focus,.search__suggestion-item:focus-visible,.search__suggestion-item:hover{background:var(--bg1);cursor:pointer;outline:none}.search__suggestion-item:last-child{border:none}.search__suggestion-description,.search__suggestion-title{margin:1rem 0;padding:0 1rem}.search__suggestion-title{font-weight:700}.search__suggestion-description{border-left:1px solid var(--bg2)}.search__no-results{padding:.75rem}.theme__toggle{align-items:center;background:none;border:none;color:var(--yellow1);cursor:pointer;display:flex;grid-area:theme-toggle;margin:0 1rem}.theme__toggle:hover{color:var(--yellow2)}.theme__toggle svg{height:28px;width:28px}nav#menu{align-items:center;display:flex;grid-area:nav;justify-content:flex-end}nav#menu .menu__item{color:var(--fg)}nav#menu .menu__item:hover{color:var(--fg3);cursor:pointer}nav#menu ul{list-style:none;margin:0;padding:0}nav#menu ul.menu--horizontal{align-items:center;display:none}nav#menu ul.menu--horizontal li{display:inline-block;margin:0 .75rem}@media (min-width:768px){nav#menu ul.menu--horizontal{display:flex}}nav#menu ul.menu--vertical{background:var(--fg0);bottom:0;margin:0;padding:3rem;position:fixed;right:0;top:0;transform:translate(100%);transition:transform .5s cubic-bezier(.9,0,.1,1);width:50%;z-index:10}nav#menu ul.menu--vertical .menu__item{color:var(--bg1)}nav#menu ul.menu--vertical .menu__item:hover{color:var(--bg4)}nav#menu .menu__burger{display:flex;height:24px;width:24px}nav#menu .menu__burger>*{position:absolute}nav#menu .menu__burger svg{height:inherit;width:inherit;z-index:20}nav#menu .menu__burger input{height:inherit;opacity:0;width:inherit;z-index:30}nav#menu .menu__burger input:checked~ul.menu--vertical{transform:none}nav#menu .menu__burger input:checked~svg{stroke:var(--bg1)}@media (min-width:768px){nav#menu .menu__burger{display:none}}.sidebar{font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace);margin-left:auto;margin-right:auto;max-width:350px;padding-left:2.5rem}.sidebar hr{margin:1.5rem auto}.sidebar svg{fill:var(--fg)}.sidebar__heading{font-size:1.3rem}aside.toc a{color:var(--primary-alt)}aside.toc a:hover{color:var(--primary)}aside.toc ul{list-style:none;margin:0;padding:0}aside.toc ul ul{font-size:.9rem;margin-left:.5rem}aside.toc ul li{line-height:1.1}aside.toc ul li a{display:block;padding:.2rem 0}.jr-basics__image{background:var(--bg1);border:2px solid var(--bg2)}.jr-basics__summary{color:var(--fg3);font-family:Roboto Slab,Georgia,serif;font-family:var(--font-serif);margin:.75rem 0}.jr-basics__profile a:hover{color:var(--fg3)}.jr-basics__profile a:hover svg{fill:var(--fg3)}.tag-cloud{line-height:1.1;text-align:justify}.tag-cloud__tag:hover{color:var(--fg3)}.content-section,.post{border-bottom:2px dotted var(--bg1);padding:2rem 0}.post img:not(figure img){box-sizing:border-box;margin:.5rem 0}.post-header{font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace)}.post-meta__author{font-weight:700}.post-content{margin:1.3rem 0}.post-content a,.post-header a{color:var(--primary-alt)}.post-content a:hover,.post-header a:hover{color:var(--primary)}.post-tags{align-items:center;display:flex;flex-wrap:wrap;gap:.9rem;margin:1rem 0}.post-tag{font-size:.9rem;line-height:1}.post-tag:before{content:"#"}.post-heading__anchor{display:none}h1:hover .post-heading__anchor,h2:hover .post-heading__anchor,h3:hover .post-heading__anchor,h4:hover .post-heading__anchor{display:inline-block}.jr__item-meta{flex-direction:column}.jr-basics__image,.jr-basics__item,.jr-basics__profile-icon,.jr-basics__profile-item,.jr__item-meta{align-items:center;display:flex}.jr-basics__name,.jr-education__area,.jr-publications__name{font-size:1.125rem;font-weight:700}.jr-basics__item{flex-direction:column;text-align:center}.jr-basics__item hr{margin:1.5rem auto}.jr-basics__image{border-radius:50%;height:250px;justify-content:center;overflow:hidden;width:250px}.jr-basics__label,.jr-basics__name,.jr-basics__summary{margin-top:.75rem}.jr-basics__profile svg{height:24px;width:24px}.jr-basics__profile,.jr-basics__profile-item{display:flex}.jr-basics__profile-item{display:flex;padding:.2rem}.jr-basics__profile--col{flex-direction:column}.jr-basics__profile--row{flex-wrap:wrap;justify-content:space-evenly}.jr-basics__profile-icon{padding:0 .75rem}.jr__item-meta{align-items:start;flex-flow:column;font-family:Fira Code,Lucida Console,Monaco,monospace;font-family:var(--font-monospace)}@media (min-width:768px){.jr__item-meta{align-items:center;flex-flow:row wrap}.jr__date,.jr__date-range{flex-grow:1;text-align:right}.jr-education__institution,.jr-publications__publisher{flex-basis:100%}}.social-share{align-items:center;border-top:2px dotted var(--bg1);display:flex;flex-wrap:wrap;gap:.9rem;margin:3rem 0;padding-top:3rem}.social-share svg{fill:var(--fg);height:24px;width:24px}.social-share svg.icon-tabler{fill:none;stroke:var(--fg)}.social-share__item{background:var(--bg1);display:flex;padding:.5rem}
   
</style>

<link
  rel="preload"
  href="/css/non-critical.d3593a72484a28e4736252e5c81ef7c44e765681722d4ed0f4e854530adca85a3fe3dc4d11828100566e8fb31736d16948fc8071cf1285343211314dc3c7c3fd.css"
  as="style"
  onload="this.onload=null;this.rel='stylesheet'"
  
    integrity="sha512-01k6ckhKKORzYlLlyB73xE52VoFyLU7Q9OhUUwrcqFo/49xNEYKBAFZuj7MXNtFpSPyAcc8ShTQyETFNw8fD/Q=="
  
/>


<link
  id="prism-dark"
  rel="preload"
  href="/prism-themes/prism-gruvbox-dark.min.54aecc64074623a4f9898544dcbdab9e804f1560ef0b38f4cf8e10fcaaf72264e798cb407c601aca6ecd833ec4eb93d66535581f18d45ba202cf848b70dbc332.css"
  as="style"
  onload="this.onload=null;this.rel='stylesheet'"
  integrity="sha512-VK7MZAdGI6T5iYVE3L2rnoBPFWDvCzj0z44Q/Kr3ImTnmMtAfGAaym7Ngz7E65PWZTVYHxjUW6ICz4SLcNvDMg=="
  
/>


<link
  id="prism-light"
  rel="preload"
  href="/prism-themes/prism-gruvbox-light.min.42a221741efe997fcc94187c39d63c555560678789ac9ca856c74a5f0ddb2aa6c50d38b2ffbecc7a99038cbbd2efa99746e862267f781c559e0cfec10b88a5fc.css"
  as="style"
  onload="this.onload=null;this.rel='stylesheet'"
  
    integrity="sha512-QqIhdB7&#43;mX/MlBh8OdY8VVVgZ4eJrJyoVsdKXw3bKqbFDTiy/77MepkDjLvS76mXRuhiJn94HFWeDP7BC4il/A=="
  
  disabled
/>

<noscript>
  
    <link
      rel="stylesheet"
      href="/prism-themes/prism-gruvbox-dark.min.54aecc64074623a4f9898544dcbdab9e804f1560ef0b38f4cf8e10fcaaf72264e798cb407c601aca6ecd833ec4eb93d66535581f18d45ba202cf848b70dbc332.css"
      
        integrity="sha512-VK7MZAdGI6T5iYVE3L2rnoBPFWDvCzj0z44Q/Kr3ImTnmMtAfGAaym7Ngz7E65PWZTVYHxjUW6ICz4SLcNvDMg=="
      
    />
  


  <link
    rel="stylesheet"
    href="/css/non-critical.d3593a72484a28e4736252e5c81ef7c44e765681722d4ed0f4e854530adca85a3fe3dc4d11828100566e8fb31736d16948fc8071cf1285343211314dc3c7c3fd.css"
    
      integrity="sha512-01k6ckhKKORzYlLlyB73xE52VoFyLU7Q9OhUUwrcqFo/49xNEYKBAFZuj7MXNtFpSPyAcc8ShTQyETFNw8fD/Q=="
    
  />
</noscript>


  

  




<script>
  (()=>{function c(){if(localStorage&&localStorage.getItem("theme"))return localStorage.getItem("theme");if(window.matchMedia)return window.matchMedia("(prefers-color-scheme: light)").matches?"light":"dark"}function n(t){document.documentElement.setAttribute("data-theme",t);let e=document.getElementById("prism-dark"),i=document.getElementById("prism-light");e.toggleAttribute("disabled",t==="light"),i.toggleAttribute("disabled",t==="dark"),localStorage.setItem("theme",t)}var o=c();o&&n(o);function l(t){let e=t.currentTarget.classList.contains("light--hidden")?"light":"dark";n(e)}document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".theme__toggle").forEach(e=>{e.addEventListener("click",l)})});})();

</script>


  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
<link rel="manifest" href="/site.webmanifest" />
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#282828" />
<meta name="msapplication-TileColor" content="#282828" />
<meta name="theme-color" content="#282828" />



  
  
<script type="text/javascript">
    (function(c,l,a,r,i,t,y){
        c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
        t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
        y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
    })(window, document, "clarity", "script", "poo3nr5a8n");
</script>

</head>

  <body>
    <div class="layout">
      <header>
  <a
    class="logo"
    href="/"
  >
    
      <div class="logo__text">relopezbriega</div>
    
    <div class="logo__chevron">></div>
    <div class="logo__cursor">█</div>
  </a>

  <div class="search">
    <input
      id="search__text"
      type="search"
      placeholder="Buscar..."
      aria-label="Search"
      autocomplete="off"
    />
    <div id="search__suggestions" class="search__suggestions--hidden"></div>
  </div>

  <nav id="menu">
    <ul class="menu--horizontal">
      
        <li class="menu__item">
          <a href="/blog">Articulos</a>
        </li>
      
        <li class="menu__item">
          <a href="/conversor-fecha-juliana">Conversor-Juliana</a>
        </li>
      
        <li class="menu__item">
          <a href="https://iaarbook.github.io/">Libro</a>
        </li>
      
        <li class="menu__item">
          <a href="/cv">CV</a>
        </li>
      
        <li class="menu__item">
          <a href="/contacto">Contacto</a>
        </li>
      
        <li class="menu__item">
          <a href="/acerca">Acerca</a>
        </li>
      
    </ul>

    <div class="menu__burger">
      
      <input class="menu__item" type="checkbox" aria-label="Open main menu" />

      
<svg
  xmlns="http://www.w3.org/2000/svg"
  width="24"
  height="24"
  viewBox="0 0 24 24"
  fill="none"
  stroke="currentColor"
  stroke-width="2"
  stroke-linecap="round"
  stroke-linejoin="round"
  class="icon icon-tabler icons-tabler-outline icon-tabler-menu-2"
>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 6l16 0" />
  <path d="M4 12l16 0" />
  <path d="M4 18l16 0" />
</svg>




      <ul class="menu--vertical">
        
          <li>
            <a class="menu__item" href="/blog">Articulos</a>
          </li>
        
          <li>
            <a class="menu__item" href="/conversor-fecha-juliana">Conversor-Juliana</a>
          </li>
        
          <li>
            <a class="menu__item" href="https://iaarbook.github.io/">Libro</a>
          </li>
        
          <li>
            <a class="menu__item" href="/cv">CV</a>
          </li>
        
          <li>
            <a class="menu__item" href="/contacto">Contacto</a>
          </li>
        
          <li>
            <a class="menu__item" href="/acerca">Acerca</a>
          </li>
        
      </ul>
    </div>
  </nav>

  <button class="theme__toggle light--hidden" aria-label="Toggle light mode">
    
<svg
  xmlns="http://www.w3.org/2000/svg"
  width="24"
  height="24"
  viewBox="0 0 24 24"
  fill="none"
  stroke="currentColor"
  stroke-width="2"
  stroke-linecap="round"
  stroke-linejoin="round"
  class="icon icon-tabler icons-tabler-outline icon-tabler-sun"
>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M12 12m-4 0a4 4 0 1 0 8 0a4 4 0 1 0 -8 0" />
  <path d="M3 12h1m8 -9v1m8 8h1m-9 8v1m-6.4 -15.4l.7 .7m12.1 -.7l-.7 .7m0 11.4l.7 .7m-12.1 -.7l-.7 .7" />
</svg>


  </button>

  <button class="theme__toggle dark--hidden" aria-label="Toggle dark mode">
    
<svg
  xmlns="http://www.w3.org/2000/svg"
  width="24"
  height="24"
  viewBox="0 0 24 24"
  fill="none"
  stroke="currentColor"
  stroke-width="2"
  stroke-linecap="round"
  stroke-linejoin="round"
  class="icon icon-tabler icons-tabler-outline icon-tabler-moon"
>
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
</svg>


  </button>
</header>

      <main>
        <div class="content">
          
  <article class="post">
    <div class="post-header">
      <h1>Machine Learning con Python</h1>
      <div class="post-meta"><span>2015-10-10</span><span> by </span><span class="post-meta__author">Raul E Lopez Briega</span>
    <div class="post-tags">
      <a class="post-tag" href="https://relopezbriega.github.io/tags/python">python</a><a class="post-tag" href="https://relopezbriega.github.io/tags/estadistica">estadistica</a><a class="post-tag" href="https://relopezbriega.github.io/tags/programacion">programacion</a><a class="post-tag" href="https://relopezbriega.github.io/tags/machine-learning">machine&#8209;learning</a><a class="post-tag" href="https://relopezbriega.github.io/tags/analisis-de-datos">analisis&#8209;de&#8209;datos</a>
    </div>
  

  
</div>

    </div>

    <div class="post-content">
      <p><em>Esta notebook fue creada originalmente como un blog post por <a
  href="/cv/"
  
  
>Raúl E. López Briega</a> en <a
  href="https://relopezbriega.github.io"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Mi blog sobre Python</a>. El contenido esta bajo la licencia BSD.</em></p>
<img alt="Machine Learning" title="Machine Learning" src="https://relopezbriega.github.io/images/machine-learning.jpg">
<p>Una de las ramas de estudio que cada vez esta ganando más popularidad dentro de las <a
  href="https://es.wikipedia.org/wiki/Ciencias_de_la_computaci%C3%B3n"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>ciencias de la computación</a> es el <em><strong>aprendizaje automático</strong></em> o <em><strong><a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a></strong></em>. Muchos de los servicios que utilizamos en nuestro día a día como google, gmail, netflix, spotify o amazon se valen de las herramientas que les brinda el <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> para alcanzar un servicio cada vez más personalizado y lograr así ventajas competitivas sobre sus rivales.</p>
<h2 id="qué-es-machine-learning">Qué es Machine Learning?<a href="#qu%c3%a9-es-machine-learning" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>Pero, ¿qué es exactamente <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a>?. El <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> es el diseño y estudio de las herramientas informáticas que utilizan la experiencia pasada para tomar decisiones futuras; es el estudio de programas que pueden aprenden de los datos. El objetivo fundamental del <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> es <em><strong>generalizar, o inducir una regla desconocida a partir de ejemplos donde esa regla es aplicada</strong></em>. El ejemplo más típico donde podemos ver el uso del <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> es en el filtrado de los correo basura o spam. Mediante la observación de miles de correos electrónicos que han sido marcados previamente como basura, los filtros de spam aprenden a clasificar los mensajes nuevos. El <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> combina conceptos y técnicas de diferentes áreas del conocimiento, como las <a
  href="https://es.wikipedia.org/wiki/Matem%C3%A1ticas"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>matemáticas</a>, <a
  href="https://es.wikipedia.org/wiki/Estad%C3%ADstica"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>estadísticas</a> y las <a
  href="https://es.wikipedia.org/wiki/Ciencias_de_la_computaci%C3%B3n"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>ciencias de la computación</a>; por tal motivo, hay muchas maneras de aprender la disciplina.</p>
<h2 id="tipos-de-machine-learning">Tipos de Machine Learning<a href="#tipos-de-machine-learning" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>El <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> tiene una amplia gama de aplicaciones, incluyendo motores de búsqueda, diagnósticos médicos, detección de fraude en el uso de tarjetas de crédito, análisis del mercado de valores, clasificación de secuencias de ADN, reconocimiento del habla y del lenguaje escrito, juegos y robótica. Pero para poder abordar cada uno de estos temas es crucial en primer lugar distingir los distintos tipos de problemas de <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> con los que nos podemos encontrar.</p>
<h3 id="aprendizaje-supervisado">Aprendizaje supervisado<a href="#aprendizaje-supervisado" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>En los problemas de <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_supervisado"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>aprendizaje supervisado</a> se enseña o entrena al <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> a partir de datos que ya vienen etiquetados con la respuesta correcta. Cuanto mayor es el conjunto de datos más el <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> puede aprender sobre el tema. Una vez concluído el entrenamiento, se le brindan nuevos datos, ya sin las etiquetas de las respuestas correctas, y el <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> de aprendizaje utiliza la experiencia pasada que adquirió durante la etapa de entrenamiento para predecir un resultado. Esto es similar al método de aprendizaje que se utiliza en las escuelas, donde se nos enseñan problemas y las formas de resolverlos, para que luego podamos aplicar los mismos métodos en situaciones similares.</p>
<h3 id="aprendizaje-no-supervisado">Aprendizaje no supervisado<a href="#aprendizaje-no-supervisado" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>En los problemas de <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_no_supervisado"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>aprendizaje no supervisado</a> el <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> es entrenado usando un conjunto de datos que no tiene ninguna etiqueta; en este caso, nunca se le dice al <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> lo que representan los datos. La idea es que el <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> pueda encontrar por si solo patrones que ayuden a entender el conjunto de datos. El <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_no_supervisado"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>aprendizaje no supervisado</a> es similar al método que utilizamos para aprender a hablar cuando somos bebes, en un principio escuchamos hablar a nuestros padres y no entendemos nada; pero a medida que vamos escuchando miles de conversaciones, nuestro cerebro comenzará a formar un modelo sobre cómo funciona el lenguaje y comenzaremos a reconocer patrones y a esperar ciertos sonidos.</p>
<h3 id="aprendizaje-por-refuerzo">Aprendizaje por refuerzo<a href="#aprendizaje-por-refuerzo" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>En los problemas de aprendizaje por refuerzo, el <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> aprende observando el mundo que le rodea. Su información de entrada es el feedback o retroalimentación que obtiene del mundo exterior como respuesta a sus acciones. Por lo tanto, el sistema aprende a base de ensayo-error. Un buen ejemplo de este tipo de aprendizaje lo podemos encontrar en los juegos, donde vamos probando nuevas estrategias y vamos seleccionando y perfeccionando aquellas que nos ayudan a ganar el juego. A medida que vamos adquiriendo más practica, el efecto acumulativo del refuerzo a nuestras acciones victoriosas terminará creando una estrategia ganadora.</p>
<h2 id="sobreentrenamiento">Sobreentrenamiento<a href="#sobreentrenamiento" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>Como mencionamos cuando definimos al <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a>, la idea fundamental es encontrar patrones que podamos generalizar para luego poder aplicar esta generalización sobre los casos que todavía no hemos observado y realizar predicciones. Pero también puede ocurrir que durante el entrenamiento solo descubramos casualidades en los datos que se parecen a patrones interesantes, pero que no generalicen. Esto es lo que se conoce con el nombre de <em><a
  href="https://es.wikipedia.org/wiki/Sobreajuste"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>sobreentrenamiento</a> o sobreajuste</em>.</p>
<p>El <em><a
  href="https://es.wikipedia.org/wiki/Sobreajuste"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>sobreentrenamiento</a></em> es la tendencia que tienen la mayoría de los <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmos</a> de <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> a ajustarse a unas características muy específicas de los datos de entrenamiento que no tienen relación causal con la <em>función objetivo</em> que estamos buscando para generalizar. El ejemplo más extremo de un modelo <em>sobreentrenado</em> es un modelo que solo memoriza las respuestas correctas; este modelo al ser utilizado con datos que nunca antes ha visto va a tener un rendimiento azaroso, ya que nunca logró generalizar un patrón para predecir.</p>
<h3 id="como-evitar-el-sobreentrenamiento">Como evitar el sobreentrenamiento<a href="#como-evitar-el-sobreentrenamiento" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>Como mencionamos anteriormente, todos los modelos de <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> tienen tendencia al <em><a
  href="https://es.wikipedia.org/wiki/Sobreajuste"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>sobreentrenamiento</a></em>; es por esto que debemos aprender a convivir con el mismo y tratar de tomar medidas preventivas para reducirlo lo más posible. Las dos principales estrategias para lidiar son el <em><a
  href="https://es.wikipedia.org/wiki/Sobreajuste"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>sobreentrenamiento</a></em> son: la <em><strong>retención de datos</strong></em> y la <em><strong><a
  href="https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>validación cruzada</a></strong></em>.</p>
<p>En el primer caso, la idea es dividir nuestro <a
  href="https://es.wikipedia.org/wiki/Conjunto_de_datos"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>conjunto de datos</a>, en uno o varios conjuntos de entrenamiento y otro/s conjuntos de evaluación. Es decir, que no le vamos a pasar todos nuestros datos al <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> durante el entrenamiento, sino que vamos a <em>retener</em> una parte de los datos de entrenamiento para realizar una evaluación de la efectividad del modelo. Con esto lo que buscamos es evitar que los mismos datos que usamos para entrenar sean los mismos que utilizamos para evaluar. De esta forma vamos a poder analizar con más precisión como el modelo se va comportando a medida que más lo vamos entrenando y poder detectar el punto crítico en el que el modelo deja de generalizar y comienza a <em>sobreajustarse</em> a los datos de entrenamiento.</p>
<p>La <em><a
  href="https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>validación cruzada</a></em> es un procedimiento más sofisticado que el anterior. En lugar de solo obtener una simple estimación de la efectividad de la <em>generalización</em>; la idea es realizar un análisis estadístico para obtener otras medidas del rendimiento estimado, como la media y la varianza, y así poder entender cómo se espera que el rendimiento varíe a través de los distintos conjuntos de datos. Esta variación es fundamental para la evaluación de la confianza en la estimación del rendimiento.
La <em><a
  href="https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>validación cruzada</a></em> también hace un mejor uso de un conjunto de datos limitado; ya que a diferencia de la simple división de los datos en uno el entrenamiento y otro de evaluación; la <em><a
  href="https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>validación cruzada</a></em> calcula sus estimaciones sobre todo el <a
  href="https://es.wikipedia.org/wiki/Conjunto_de_datos"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>conjunto de datos</a> mediante la realización de múltiples divisiones e intercambios sistemáticos entre datos de entrenamiento y datos de evaluación.</p>
<h2 id="pasos-para-construir-un-modelo-de-machine-learning">Pasos para construir un modelo de machine learning<a href="#pasos-para-construir-un-modelo-de-machine-learning" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>Construir un modelo de <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a>, no se reduce solo a utilizar un <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> de aprendizaje o utilizar una librería de <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a>; sino que es todo un proceso que suele involucrar los siguientes pasos:</p>
<ol>
<li>
<p><strong>Recolectar los datos</strong>. Podemos recolectar los datos desde muchas fuentes, podemos por ejemplo extraer los datos de un sitio web o obtener los datos utilizando una <a
  href="https://es.wikipedia.org/wiki/Interfaz_de_programaci%C3%B3n_de_aplicaciones"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>API</a> o desde una base de datos. Podemos también utilizar otros dispositivos que recolectan los datos por nosotros; o utilizar datos que son de dominio público. El número de opciones que tenemos para recolectar datos no tiene fin!. Este paso parece obvio, pero es uno de los que más complicaciones trae y más tiempo consume.</p>
</li>
<li>
<p><strong>Preprocesar los datos</strong>. Una vez que tenemos los datos, tenemos que asegurarnos que tiene el formato correcto para nutrir nuestro <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> de aprendizaje. Es prácticamente inevitable tener que realizar varias tareas de preprocesamiento antes de poder utilizar los datos. Igualmente este punto suele ser mucho más sencillo que el paso anterior.</p>
</li>
<li>
<p><strong>Explorar los datos</strong>. Una vez que ya tenemos los datos y están con el formato correcto, podemos realizar un pre análisis para corregir los casos de valores faltantes o intentar encontrar a simple vista algún patrón en los mismos que nos facilite la construcción del modelo. En esta etapa suelen ser de mucha utilidad las medidas estadísticas y los gráficos en 2 y 3 dimensiones para tener una idea visual de como se comportan nuestros datos. En este punto podemos detectar <a
  href="https://es.wikipedia.org/wiki/Valor_at%C3%ADpico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>valores atípicos</a> que debamos descartar; o encontrar las características que más influencia tienen para realizar una predicción.</p>
</li>
<li>
<p><strong>Entrenar el <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a></strong>. Aquí es donde comenzamos a utilizar las técnicas de <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> realmente. En esta etapa nutrimos al o los <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmos</a> de aprendizaje con los datos que venimos procesando en las etapas anteriores. La idea es que los <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmos</a> puedan extraer información útil de los datos que le pasamos para luego poder hacer predicciones.</p>
</li>
<li>
<p><strong>Evaluar el <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a></strong>. En esta etapa ponemos a prueba la información o conocimiento que el <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> obtuvo del entrenamiento del paso anterior. Evaluamos que tan preciso es el algoritmo en sus predicciones y si no estamos muy conforme con su rendimiento, podemos volver a la etapa anterior y continuar entrenando el <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> cambiando algunos parámetros hasta lograr un rendimiento aceptable.</p>
</li>
<li>
<p><strong>Utilizar el modelo</strong>. En esta ultima etapa, ya ponemos a nuestro modelo a enfrentarse al problema real. Aquí también podemos medir su rendimiento, lo que tal vez nos obligue a revisar todos los pasos anteriores.</p>
</li>
</ol>
<h2 id="librerías-de-python-para-machine-learning">Librerías de Python para machine learning<a href="#librer%c3%adas-de-python-para-machine-learning" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>Como siempre me gusta comentar, una de las grandes ventajas que ofrece <a
  href="https://python.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Python</a> sobre otros lenguajes de programación; es lo grande y prolifera que es la comunidad de desarrolladores que lo rodean; comunidad que ha contribuido con una gran variedad de librerías de primer nivel que extienden la funcionalidades del lenguaje. Para el caso de <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a>, las principales librerías que podemos utilizar son:</p>
<h3 id="scikit-learn">Scikit-Learn<a href="#scikit-learn" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p><a
  href="https://scikit-learn.org/stable/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Scikit-learn</a> es la principal librería que existe para trabajar con <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a>, incluye la implementación de un gran número de <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmos</a> de aprendizaje. La podemos utilizar para <a href='https://scikit-learn.org/stable/supervised_learning.html#supervised-learning' target='_blank'>clasificaciones</a>, <a href='https://scikit-learn.org/stable/modules/feature_extraction.html#feature-extractionfeature' target='_blank'>extraccion de características</a>, <a href='https://scikit-learn.org/stable/supervised_learning.html#supervised-learning' target='_blank'>regresiones</a>, <a href='https://scikit-learn.org/stable/modules/clustering.html#clustering' target='_blank'>agrupaciones</a>, <a href='https://scikit-learn.org/stable/modules/decomposition.html#decompositions' target='_blank'>reducción de dimensiones</a>, <a href='https://scikit-learn.org/stable/model_selection.html#model-selection' target='_blank'>selección de modelos</a>, o <a href='https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing' target='_blank'>preprocesamiento</a>. Posee una <a
  href="https://es.wikipedia.org/wiki/Interfaz_de_programaci%C3%B3n_de_aplicaciones"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>API</a> que es consistente en todos los modelos y se integra muy bien con el resto de los paquetes científicos que ofrece <a
  href="https://python.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Python</a>. Esta librería también nos facilita las tareas de evaluación, diagnostico y <a
  href="https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>validaciones cruzadas</a> ya que nos proporciona varios métodos de fábrica para poder realizar estas tareas en forma muy simple.</p>
<h3 id="statsmodels">Statsmodels<a href="#statsmodels" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p><a
  href="https://statsmodels.sourceforge.net/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Statsmodels</a> es otra gran librería que hace foco en modelos estadísticos y se utiliza principalmente para análisis predictivos y exploratorios. Al igual que <a
  href="https://scikit-learn.org/stable/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Scikit-learn</a>, también se integra muy bien con el resto de los paquetes cientificos de <a
  href="https://python.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Python</a>. Si deseamos ajustar modelos lineales, hacer una análisis estadístico, o tal vez un poco de modelado predictivo, entonces <a
  href="https://statsmodels.sourceforge.net/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Statsmodels</a> es la librería ideal. Las pruebas estadísticas que ofrece son bastante amplias y abarcan tareas de validación para la mayoría de los casos.</p>
<h3 id="pymc">PyMC<a href="#pymc" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p><a
  href="https://pymc-devs.github.io/pymc/index.html"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>pyMC</a> es un módulo de <a
  href="https://python.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Python</a> que implementa modelos estadísticos bayesianos, incluyendo la <a
  href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>cadena de Markov Monte Carlo(MCMC)</a>. <a
  href="https://pymc-devs.github.io/pymc/index.html"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>pyMC</a>  ofrece funcionalidades para hacer el análisis bayesiano lo mas simple posible. Incluye los modelos <a
  href="https://es.wikipedia.org/wiki/Inferencia_bayesiana"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>bayesianos</a>,  distribuciones estadísticas y herramientas de diagnostico  para la covarianza de los modelos. Si queremos realizar un análisis <a
  href="https://es.wikipedia.org/wiki/Inferencia_bayesiana"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>bayesiano</a> esta es sin duda la librería a utilizar.</p>
<h3 id="ntlk">NTLK<a href="#ntlk" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p><a
  href="https://www.nltk.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>NLTK</a> es la librería líder para el procesamiento del lenguaje natural o <a
  href="https://es.wikipedia.org/wiki/Procesamiento_de_lenguajes_naturales"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>NLP</a> por sus siglas en inglés. Proporciona interfaces fáciles de usar a más de 50 cuerpos y recursos léxicos, como <a
  href="https://wordnet.princeton.edu/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>WordNet</a>, junto con un conjunto de bibliotecas de procesamiento de texto para la clasificación, tokenización, el etiquetado, el análisis y el razonamiento semántico.</p>
<p>Obviamente, aquí solo estoy listando unas pocas de las muchas librerías que existen en <a
  href="https://python.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Python</a> para trabajar con problemas de <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a>, los invito a realizar su propia investigación sobre el tema.</p>
<h2 id="algoritmos-más-utilizados">Algoritmos más utilizados<a href="#algoritmos-m%c3%a1s-utilizados" class="post-heading__anchor" aria-hidden="true">#</a>
</h2>
<p>Los <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmos</a>  que más se suelen utilizar en los problemas de <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> son los siguientes:</p>
<ol>
<li><a
  href="https://es.wikipedia.org/wiki/Regresi%C3%B3n_lineal"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Regresión Lineal</a></li>
<li><a
  href="https://es.wikipedia.org/wiki/Regresi%C3%B3n_log%C3%ADstica"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Regresión Logística</a></li>
<li><a
  href="https://es.wikipedia.org/wiki/%C3%81rbol_de_decisi%C3%B3n"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Arboles de Decision</a></li>
<li><a
  href="https://es.wikipedia.org/wiki/Random_forest"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Random Forest</a></li>
<li><a
  href="https://es.wikipedia.org/wiki/M%C3%A1quinas_de_vectores_de_soporte"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>SVM</a> o Máquinas de vectores de soporte.</li>
<li><a
  href="https://es.wikipedia.org/wiki/K-vecinos_m%C3%A1s_cercanos"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>KNN</a> o K vecinos más cercanos.</li>
<li><a
  href="https://es.wikipedia.org/wiki/K-means"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>K-means</a></li>
</ol>
<p>Todos ellos se pueden aplicar a casi cualquier problema de datos y obviamente estan todos implementados por la excelente librería de <a
  href="https://python.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Python</a>, <a
  href="https://scikit-learn.org/stable/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Scikit-learn</a>. Veamos algunos ejemplos de ellos.</p>
<h3 id="regresión-lineal">Regresión Lineal<a href="#regresi%c3%b3n-lineal" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>Se utiliza para estimar los valores reales (costo de las viviendas, el número de llamadas, ventas totales, etc.) basados en variables continuas. La idea es tratar de establecer la relación entre las variables independientes y dependientes por medio de ajustar una mejor línea recta con respecto a los puntos. Esta línea de mejor ajuste se conoce como línea de regresión y esta representada por la siguiente ecuación lineal:</p>
$$Y = \beta_{0} + \beta_{1}X_{1} + \beta_{2}X_{2} + ... + \beta_{n}X_{n}$$
<p>Veamos un pequeño ejemplo de como se implementa en <a
  href="https://python.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Python</a>. En este ejemplo voy a utilizar el dataset Boston que ya viene junto con <a
  href="https://scikit-learn.org/stable/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Scikit-learn</a> y es ideal para practicar con <a
  href="https://es.wikipedia.org/wiki/Regresi%C3%B3n_lineal"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Regresiones Lineales</a>; el mismo contiene precios de casas de varias áreas de la ciudad de Boston.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># graficos embebidos</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">%</span>matplotlib inline
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># importando pandas, numpy y matplotlib</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># importando los datasets de sklearn</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> datasets
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>boston <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_boston()
</span></span><span style="display:flex;"><span>boston_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(boston<span style="color:#f92672">.</span>data, columns<span style="color:#f92672">=</span>boston<span style="color:#f92672">.</span>feature_names)
</span></span><span style="display:flex;"><span>boston_df[<span style="color:#e6db74">&#39;TARGET&#39;</span>] <span style="color:#f92672">=</span> boston<span style="color:#f92672">.</span>target
</span></span><span style="display:flex;"><span>boston_df<span style="color:#f92672">.</span>head() <span style="color:#75715e"># estructura de nuestro dataset.</span>
</span></span></code></pre></div><div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }
<pre><code>.dataframe thead th {
    text-align: left;
}

.dataframe tbody tr th {
    vertical-align: top;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>TARGET</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
  </tbody>
</table>
</div>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># importando el modelo de regresión lineal</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LinearRegression
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>rl <span style="color:#f92672">=</span> LinearRegression() <span style="color:#75715e"># Creando el modelo.</span>
</span></span><span style="display:flex;"><span>rl<span style="color:#f92672">.</span>fit(boston<span style="color:#f92672">.</span>data, boston<span style="color:#f92672">.</span>target) <span style="color:#75715e"># ajustando el modelo</span>
</span></span></code></pre></div><pre><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Lista de coeficientes B para cada X</span>
</span></span><span style="display:flex;"><span>list(zip(boston<span style="color:#f92672">.</span>feature_names, rl<span style="color:#f92672">.</span>coef_))
</span></span></code></pre></div><pre><code>[('CRIM', -0.10717055656035711),
 ('ZN', 0.046395219529796805),
 ('INDUS', 0.020860239532172288),
 ('CHAS', 2.6885613993179822),
 ('NOX', -17.795758660308522),
 ('RM', 3.8047524602580101),
 ('AGE', 0.00075106170332574131),
 ('DIS', -1.4757587965198171),
 ('RAD', 0.30565503833910218),
 ('TAX', -0.012329346305270897),
 ('PTRATIO', -0.95346355469055977),
 ('B', 0.0093925127221893244),
 ('LSTAT', -0.5254666329007841)]
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># haciendo las predicciones</span>
</span></span><span style="display:flex;"><span>predicciones <span style="color:#f92672">=</span> rl<span style="color:#f92672">.</span>predict(boston<span style="color:#f92672">.</span>data)
</span></span><span style="display:flex;"><span>predicciones_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(predicciones, columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;Pred&#39;</span>])
</span></span><span style="display:flex;"><span>predicciones_df<span style="color:#f92672">.</span>head() <span style="color:#75715e"># predicciones de las primeras 5 lineas</span>
</span></span></code></pre></div><div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }
<pre><code>.dataframe thead th {
    text-align: left;
}

.dataframe tbody tr th {
    vertical-align: top;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>30.008213</td>
    </tr>
    <tr>
      <th>1</th>
      <td>25.029861</td>
    </tr>
    <tr>
      <th>2</th>
      <td>30.570232</td>
    </tr>
    <tr>
      <th>3</th>
      <td>28.608141</td>
    </tr>
    <tr>
      <th>4</th>
      <td>27.942882</td>
    </tr>
  </tbody>
</table>
</div>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Calculando el desvio</span>
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>mean(boston<span style="color:#f92672">.</span>target <span style="color:#f92672">-</span> predicciones)
</span></span></code></pre></div><pre><code>5.6871503553921065e-15
</code></pre>
<p>Como podemos ver, el desvío del modelo es pequeño, por lo que sus resultados para este ejemplo son bastante confiables.</p>
<h3 id="regresión-logística">Regresión Logística<a href="#regresi%c3%b3n-log%c3%adstica" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>Los modelos lineales, también pueden ser utilizados para clasificaciones; es decir, que primero ajustamos el modelo lineal a la probabilidad de que una cierta clase o categoría ocurra y, a luego, utilizamos una función para crear un umbral en el cual especificamos el resultado de una de estas clases o categorías. La función que utiliza este modelo, no es ni más ni menos que la función logística.</p>
$$f(x) = \frac{1}{1 + e^{-1}}$$
<p>Veamos, aquí también un pequeño ejemplo en <a
  href="https://python.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Python</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Creando un dataset de ejemplo </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> make_classification
</span></span><span style="display:flex;"><span>X, y <span style="color:#f92672">=</span> make_classification(n_samples<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>, n_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Importando el modelo</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>rlog <span style="color:#f92672">=</span> LogisticRegression() <span style="color:#75715e"># Creando el modelo</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Dividiendo el dataset en entrenamiento y evaluacion</span>
</span></span><span style="display:flex;"><span>X_entrenamiento <span style="color:#f92672">=</span> X[:<span style="color:#f92672">-</span><span style="color:#ae81ff">200</span>]
</span></span><span style="display:flex;"><span>X_evaluacion <span style="color:#f92672">=</span> X[<span style="color:#f92672">-</span><span style="color:#ae81ff">200</span>:]
</span></span><span style="display:flex;"><span>y_entrenamiento <span style="color:#f92672">=</span> y[:<span style="color:#f92672">-</span><span style="color:#ae81ff">200</span>]
</span></span><span style="display:flex;"><span>y_evaluacion <span style="color:#f92672">=</span> y[<span style="color:#f92672">-</span><span style="color:#ae81ff">200</span>:]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>rlog<span style="color:#f92672">.</span>fit(X_entrenamiento, y_entrenamiento) <span style="color:#75715e">#ajustando el modelo</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Realizando las predicciones</span>
</span></span><span style="display:flex;"><span>y_predic_entrenamiento <span style="color:#f92672">=</span> rlog<span style="color:#f92672">.</span>predict(X_entrenamiento) 
</span></span><span style="display:flex;"><span>y_predic_evaluacion <span style="color:#f92672">=</span> rlog<span style="color:#f92672">.</span>predict(X_evaluacion)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Verificando la exactitud del modelo</span>
</span></span><span style="display:flex;"><span>entrenamiento <span style="color:#f92672">=</span> (y_predic_entrenamiento <span style="color:#f92672">==</span> y_entrenamiento)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>astype(float) <span style="color:#f92672">/</span> y_entrenamiento<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;sobre datos de entrenamiento: </span><span style="color:#e6db74">{0:.2f}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(entrenamiento))
</span></span><span style="display:flex;"><span>evaluacion <span style="color:#f92672">=</span> (y_predic_evaluacion <span style="color:#f92672">==</span> y_evaluacion)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>astype(float) <span style="color:#f92672">/</span> y_evaluacion<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;sobre datos de evaluación: </span><span style="color:#e6db74">{0:.2f}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(evaluacion))
</span></span></code></pre></div><pre><code>sobre datos de entrenamiento: 0.92
sobre datos de evaluación: 0.91
</code></pre>
<p>Como podemos ver en este ejemplo también nuestro modelo tiene bastante precisión clasificando las categorías de nuestro dataset.</p>
<h3 id="arboles-de-decisión">Arboles de decisión<a href="#arboles-de-decisi%c3%b3n" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>Los <a
  href="https://es.wikipedia.org/wiki/%C3%81rbol_de_decisi%C3%B3n"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Arboles de Decision</a> son diagramas con construcciones lógicas, muy similares a los sistemas de predicción basados en reglas, que sirven para representar y categorizar una serie de condiciones que ocurren de forma sucesiva, para la resolución de un problema.
Los <a
  href="https://es.wikipedia.org/wiki/%C3%81rbol_de_decisi%C3%B3n"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Arboles de Decision</a> están compuestos por nodos interiores, nodos terminales y ramas que emanan de los nodos interiores. Cada nodo interior en el árbol contiene una prueba de un atributo, y cada rama representa un valor distinto del atributo. Siguiendo las ramas desde el nodo raíz hacia abajo, cada ruta finalmente termina en un nodo terminal creando una segmentación de los datos. Veamos aquí también un pequeño ejemplo en <a
  href="https://python.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Python</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Creando un dataset de ejemplo</span>
</span></span><span style="display:flex;"><span>X, y <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>make_classification(<span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">20</span>, n_informative<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Importando el arbol de decisión</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.tree <span style="color:#f92672">import</span> DecisionTreeClassifier
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> tree
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ad <span style="color:#f92672">=</span> DecisionTreeClassifier(criterion<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;entropy&#39;</span>, max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>) <span style="color:#75715e"># Creando el modelo</span>
</span></span><span style="display:flex;"><span>ad<span style="color:#f92672">.</span>fit(X, y) <span style="color:#75715e"># Ajustando el modelo</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#generando archivo para graficar el arbol</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;mi_arbol.dot&#34;</span>, <span style="color:#e6db74">&#39;w&#39;</span>) <span style="color:#66d9ef">as</span> archivo_dot:
</span></span><span style="display:flex;"><span>    tree<span style="color:#f92672">.</span>export_graphviz(ad, out_file <span style="color:#f92672">=</span> archivo_dot)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># utilizando el lenguaje dot para graficar el arbol.</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">!</span>dot <span style="color:#f92672">-</span>Tjpeg mi_arbol<span style="color:#f92672">.</span>dot <span style="color:#f92672">-</span>o arbol_decision<span style="color:#f92672">.</span>jpeg
</span></span></code></pre></div><p>Luego de usar el lenguaje <a
  href="https://www.graphviz.org/content/dot-language"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>dot</a> para convertir nuestro arbol a formato jpeg, ya podemos ver la imagen del mismo.</p>
<img alt="arbol de decision" title="arbol de decision" src="https://relopezbriega.github.io/images/arbol_decision.jpeg">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># verificando la precisión</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;precisión del modelo: </span><span style="color:#e6db74">{0: .2f}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format((y <span style="color:#f92672">==</span> ad<span style="color:#f92672">.</span>predict(X))<span style="color:#f92672">.</span>mean()))
</span></span></code></pre></div><pre><code>precisión del modelo:  0.96
</code></pre>
<p>En este ejemplo, nuestro árbol tiene una precisión del 89%. Tener en cuenta que los <a
  href="https://es.wikipedia.org/wiki/%C3%81rbol_de_decisi%C3%B3n"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Arboles de Decision</a> tienen tendencia a <em>sobreentrenar</em> los datos.</p>
<h3 id="random-forest">Random Forest<a href="#random-forest" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>En lugar de utilizar solo un arbol para decidir, ¿por qué no utilizar todo un bosque?!!. Esta es la idea central detrás del <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> de <a
  href="https://es.wikipedia.org/wiki/Random_forest"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Random Forest</a>. Tarbaja construyendo una gran cantidad de <a
  href="https://es.wikipedia.org/wiki/%C3%81rbol_de_decisi%C3%B3n"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>arboles de decision</a> muy poco profundos, y luego toma la clase que
cada árbol eligió. Esta idea es muy poderosa en <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a>. Si tenemos en cuenta que un sencillo clasificador entrenado podría tener sólo el 60 por ciento de precisión, podemos entrenar un montón de clasificadores que sean por lo general acertados y luego podemos utilizar la sabiduría de todos los aprendices juntos.
Con <a
  href="https://python.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Python</a> los podemos utilizar de la siguiente manera:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Creando un dataset de ejemplo</span>
</span></span><span style="display:flex;"><span>X, y <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>make_classification(<span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Importando el random forest</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>rf <span style="color:#f92672">=</span> RandomForestClassifier() <span style="color:#75715e"># Creando el modelo</span>
</span></span><span style="display:flex;"><span>rf<span style="color:#f92672">.</span>fit(X, y) <span style="color:#75715e"># Ajustando el modelo</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># verificando la precisión</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;precisión del modelo: </span><span style="color:#e6db74">{0: .2f}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format((y <span style="color:#f92672">==</span> rf<span style="color:#f92672">.</span>predict(X))<span style="color:#f92672">.</span>mean()))
</span></span></code></pre></div><pre><code>precisión del modelo:  0.99
</code></pre>
<h3 id="svm-o-máquinas-de-vectores-de-soporte">SVM o Máquinas de vectores de soporte<a href="#svm-o-m%c3%a1quinas-de-vectores-de-soporte" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>La idea detrás de <a
  href="https://es.wikipedia.org/wiki/M%C3%A1quinas_de_vectores_de_soporte"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>SVM</a> es encontrar un plano que separe los grupos dentro de los datos de la mejor forma posible. Aquí, la separación significa que la elección
del plano maximiza el margen entre los puntos más cercanos en el plano; éstos puntos se denominan vectores de soporte. Pasemos al ejemplo.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># importanto SVM</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> svm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># importando el dataset iris</span>
</span></span><span style="display:flex;"><span>iris <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_iris()
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> iris<span style="color:#f92672">.</span>data[:, :<span style="color:#ae81ff">2</span>]  <span style="color:#75715e"># solo tomamos las primeras 2 características</span>
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> iris<span style="color:#f92672">.</span>target
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>h <span style="color:#f92672">=</span> <span style="color:#ae81ff">.02</span>  <span style="color:#75715e"># tamaño de la malla del grafico</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Creando el SVM con sus diferentes métodos</span>
</span></span><span style="display:flex;"><span>C <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span>  <span style="color:#75715e"># parametro de regulacion SVM </span>
</span></span><span style="display:flex;"><span>svc <span style="color:#f92672">=</span> svm<span style="color:#f92672">.</span>SVC(kernel<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;linear&#39;</span>, C<span style="color:#f92672">=</span>C)<span style="color:#f92672">.</span>fit(X, y)
</span></span><span style="display:flex;"><span>rbf_svc <span style="color:#f92672">=</span> svm<span style="color:#f92672">.</span>SVC(kernel<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;rbf&#39;</span>, gamma<span style="color:#f92672">=</span><span style="color:#ae81ff">0.7</span>, C<span style="color:#f92672">=</span>C)<span style="color:#f92672">.</span>fit(X, y)
</span></span><span style="display:flex;"><span>poly_svc <span style="color:#f92672">=</span> svm<span style="color:#f92672">.</span>SVC(kernel<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;poly&#39;</span>, degree<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, C<span style="color:#f92672">=</span>C)<span style="color:#f92672">.</span>fit(X, y)
</span></span><span style="display:flex;"><span>lin_svc <span style="color:#f92672">=</span> svm<span style="color:#f92672">.</span>LinearSVC(C<span style="color:#f92672">=</span>C)<span style="color:#f92672">.</span>fit(X, y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># crear el area para graficar</span>
</span></span><span style="display:flex;"><span>x_min, x_max <span style="color:#f92672">=</span> X[:, <span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>min() <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>, X[:, <span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>max() <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>y_min, y_max <span style="color:#f92672">=</span> X[:, <span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>min() <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>, X[:, <span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>max() <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>xx, yy <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>meshgrid(np<span style="color:#f92672">.</span>arange(x_min, x_max, h),
</span></span><span style="display:flex;"><span>                     np<span style="color:#f92672">.</span>arange(y_min, y_max, h))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># titulos de los graficos</span>
</span></span><span style="display:flex;"><span>titles <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;SVC con el motor lineal&#39;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#39;LinearSVC&#39;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#39;SVC con el motor RBF&#39;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">&#39;SVC con el motor polinomial&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i, clf <span style="color:#f92672">in</span> enumerate((svc, lin_svc, rbf_svc, poly_svc)):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Realizando el gráfico, se le asigna un color a cada punto</span>
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>subplots_adjust(wspace<span style="color:#f92672">=</span><span style="color:#ae81ff">0.4</span>, hspace<span style="color:#f92672">=</span><span style="color:#ae81ff">0.4</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    Z <span style="color:#f92672">=</span> clf<span style="color:#f92672">.</span>predict(np<span style="color:#f92672">.</span>c_[xx<span style="color:#f92672">.</span>ravel(), yy<span style="color:#f92672">.</span>ravel()])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    Z <span style="color:#f92672">=</span> Z<span style="color:#f92672">.</span>reshape(xx<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>contourf(xx, yy, Z, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>Paired, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Graficando tambien los puntos de datos</span>
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>scatter(X[:, <span style="color:#ae81ff">0</span>], X[:, <span style="color:#ae81ff">1</span>], c<span style="color:#f92672">=</span>y, cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>Paired)
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;largo del petalo&#39;</span>)
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;ancho del petalo&#39;</span>)
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>xlim(xx<span style="color:#f92672">.</span>min(), xx<span style="color:#f92672">.</span>max())
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>ylim(yy<span style="color:#f92672">.</span>min(), yy<span style="color:#f92672">.</span>max())
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>xticks(())
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>yticks(())
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>title(titles[i])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p>



  
  
  <img
    src="/MachineLearningPython_files/MachineLearningPython_33_0.png"
    alt="png"
    
    loading="lazy"
    width="378"
    height="261"
  />






</p>
<h3 id="knn-o-k-vecinos-más-cercanos">KNN o k vecinos más cercanos<a href="#knn-o-k-vecinos-m%c3%a1s-cercanos" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p>Este es un método de clasificación no paramétrico, que estima el valor de la probabilidad a posteriori de que un elemento \(x\) pertenezca a una clase en particular a partir de la información proporcionada por el conjunto de prototipos.
La regresión <a
  href="https://es.wikipedia.org/wiki/K-vecinos_m%C3%A1s_cercanos"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>KNN</a> se calcula simplemente tomando el promedio del punto k más cercano al punto que se está probando.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Creando el dataset iris</span>
</span></span><span style="display:flex;"><span>iris <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_iris()
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> iris<span style="color:#f92672">.</span>data
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> iris<span style="color:#f92672">.</span>target
</span></span><span style="display:flex;"><span>iris<span style="color:#f92672">.</span>feature_names
</span></span></code></pre></div><pre><code>['sepal length (cm)',
 'sepal width (cm)',
 'petal length (cm)',
 'petal width (cm)']
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># importando KNN </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.neighbors <span style="color:#f92672">import</span> KNeighborsRegressor
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>knnr <span style="color:#f92672">=</span> KNeighborsRegressor(n_neighbors<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>) <span style="color:#75715e"># Creando el modelo con 10 vecinos</span>
</span></span><span style="display:flex;"><span>knnr<span style="color:#f92672">.</span>fit(X, y) <span style="color:#75715e"># Ajustando el modelo</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Verificando el error medio del modelo</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;El error medio del modelo es: </span><span style="color:#e6db74">{:.2f}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(np<span style="color:#f92672">.</span>power(y <span style="color:#f92672">-</span> knnr<span style="color:#f92672">.</span>predict(X),
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>mean()))
</span></span></code></pre></div><pre><code>El error medio del modelo es: 0.02
</code></pre>
<h3 id="k-means">K-means<a href="#k-means" class="post-heading__anchor" aria-hidden="true">#</a>
</h3>
<p><a
  href="https://es.wikipedia.org/wiki/K-means"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>K-means</a> es probablemente uno de los algoritmos de agrupamiento más conocidos y, en un sentido más amplio, una de las técnicas de aprendizaje no supervisado más conocidas.
<a
  href="https://es.wikipedia.org/wiki/K-means"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>K-means</a> es en realidad un <a
  href="https://es.wikipedia.org/wiki/Algoritmo"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>algoritmo</a> muy simple que funciona para reducir al mínimo la suma de las distancias cuadradas desde la media dentro del agrupamiento. Para hacer esto establece primero un número previamente especificado de conglomerados, K, y luego va asignando cada observación a la agrupación más cercana de acuerdo a su media. Veamos el ejemplo</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Creando el dataset</span>
</span></span><span style="display:flex;"><span>grupos, pos_correcta <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>make_blobs(<span style="color:#ae81ff">1000</span>, centers<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,
</span></span><span style="display:flex;"><span>cluster_std<span style="color:#f92672">=</span><span style="color:#ae81ff">1.75</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Graficando los grupos de datos</span>
</span></span><span style="display:flex;"><span>f, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>colores <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;r&#39;</span>, <span style="color:#e6db74">&#39;g&#39;</span>, <span style="color:#e6db74">&#39;b&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">3</span>):
</span></span><span style="display:flex;"><span>    p <span style="color:#f92672">=</span> grupos[pos_correcta <span style="color:#f92672">==</span> i]
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>scatter(p[:,<span style="color:#ae81ff">0</span>], p[:,<span style="color:#ae81ff">1</span>], c<span style="color:#f92672">=</span>colores[i],
</span></span><span style="display:flex;"><span>               label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Grupo </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(i))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Agrupamiento perfecto&#34;</span>)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p>



  
  
  <img
    src="/MachineLearningPython_files/MachineLearningPython_38_0.png"
    alt="png"
    
    loading="lazy"
    width="436"
    height="319"
  />






</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># importando KMeans</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.cluster <span style="color:#f92672">import</span> KMeans
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Creando el modelo</span>
</span></span><span style="display:flex;"><span>kmeans <span style="color:#f92672">=</span> KMeans(n_clusters<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>kmeans<span style="color:#f92672">.</span>fit(grupos) <span style="color:#75715e"># Ajustando el modelo</span>
</span></span></code></pre></div><pre><code>KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,
    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',
    random_state=None, tol=0.0001, verbose=0)
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># verificando los centros de los grupos</span>
</span></span><span style="display:flex;"><span>kmeans<span style="color:#f92672">.</span>cluster_centers_
</span></span></code></pre></div><pre><code>array([[-9.90500465, -4.48254047],
       [-8.1907267 ,  7.77491011],
       [ 1.9875472 ,  4.07789958]])
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Graficando segun modelo</span>
</span></span><span style="display:flex;"><span>f, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>colores <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;r&#39;</span>, <span style="color:#e6db74">&#39;g&#39;</span>, <span style="color:#e6db74">&#39;b&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">3</span>):
</span></span><span style="display:flex;"><span>    p <span style="color:#f92672">=</span> grupos[pos_correcta <span style="color:#f92672">==</span> i]
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>scatter(p[:,<span style="color:#ae81ff">0</span>], p[:,<span style="color:#ae81ff">1</span>], c<span style="color:#f92672">=</span>colores[i],
</span></span><span style="display:flex;"><span>               label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Grupo </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(i))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>scatter(kmeans<span style="color:#f92672">.</span>cluster_centers_[:, <span style="color:#ae81ff">0</span>], kmeans<span style="color:#f92672">.</span>cluster_centers_[:, <span style="color:#ae81ff">1</span>], 
</span></span><span style="display:flex;"><span>           s<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;black&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Centros&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Agrupamiento s/modelo&#34;</span>)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()    
</span></span></code></pre></div><p>



  
  
  <img
    src="/MachineLearningPython_files/MachineLearningPython_41_0.png"
    alt="png"
    
    loading="lazy"
    width="436"
    height="319"
  />






</p>
<p>Con esto doy por concluída esta introducción al <a
  href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Machine Learning</a> con <a
  href="https://python.org/"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>Python</a>, espero les sea útil.</p>
<p>Saludos!</p>
<p><em>Este post fue escrito utilizando IPython notebook. Pueden descargar este <a
  href="https://github.com/relopezbriega/relopezbriega.github.io/blob/master/downloads/MachineLearningPython.ipynb"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>notebook</a> o ver su version estática en <a
  href="https://nbviewer.ipython.org/github/relopezbriega/relopezbriega.github.io/blob/master/downloads/MachineLearningPython.ipynb"
  
  
    class="link--external" target="_blank" rel="noreferrer"
  
>nbviewer</a>.</em></p>

    </div>

    
      


  <div class="social-share">
    <strong class="social-share__heading">Share this post: </strong>
    
      
      
      
      <a
        class="social-share__item"
        href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Frelopezbriega.github.io%2Fblog%2F2015%2F10%2F10%2Fmachine-learning-con-python%2F"
        target="_blank"
        rel="noreferrer"
      >
        
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Facebook</title><path d="M9.101 23.691v-7.98H6.627v-3.667h2.474v-1.58c0-4.085 1.848-5.978 5.858-5.978.401 0 .955.042 1.468.103a8.68 8.68 0 0 1 1.141.195v3.325a8.623 8.623 0 0 0-.653-.036 26.805 26.805 0 0 0-.733-.009c-.707 0-1.259.096-1.675.309a1.686 1.686 0 0 0-.679.622c-.258.42-.374.995-.374 1.752v1.297h3.919l-.386 2.103-.287 1.564h-3.246v8.245C19.396 23.238 24 18.179 24 12.044c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.628 3.874 10.35 9.101 11.647Z"/></svg>


      </a>
    
      
      
      
      <a
        class="social-share__item"
        href="https://reddit.com/submit?url=https%3A%2F%2Frelopezbriega.github.io%2Fblog%2F2015%2F10%2F10%2Fmachine-learning-con-python%2F&amp;title=Machine&#43;Learning&#43;con&#43;Python"
        target="_blank"
        rel="noreferrer"
      >
        
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Reddit</title><path d="M12 0C5.373 0 0 5.373 0 12c0 3.314 1.343 6.314 3.515 8.485l-2.286 2.286C.775 23.225 1.097 24 1.738 24H12c6.627 0 12-5.373 12-12S18.627 0 12 0Zm4.388 3.199c1.104 0 1.999.895 1.999 1.999 0 1.105-.895 2-1.999 2-.946 0-1.739-.657-1.947-1.539v.002c-1.147.162-2.032 1.15-2.032 2.341v.007c1.776.067 3.4.567 4.686 1.363.473-.363 1.064-.58 1.707-.58 1.547 0 2.802 1.254 2.802 2.802 0 1.117-.655 2.081-1.601 2.531-.088 3.256-3.637 5.876-7.997 5.876-4.361 0-7.905-2.617-7.998-5.87-.954-.447-1.614-1.415-1.614-2.538 0-1.548 1.255-2.802 2.803-2.802.645 0 1.239.218 1.712.585 1.275-.79 2.881-1.291 4.64-1.365v-.01c0-1.663 1.263-3.034 2.88-3.207.188-.911.993-1.595 1.959-1.595Zm-8.085 8.376c-.784 0-1.459.78-1.506 1.797-.047 1.016.64 1.429 1.426 1.429.786 0 1.371-.369 1.418-1.385.047-1.017-.553-1.841-1.338-1.841Zm7.406 0c-.786 0-1.385.824-1.338 1.841.047 1.017.634 1.385 1.418 1.385.785 0 1.473-.413 1.426-1.429-.046-1.017-.721-1.797-1.506-1.797Zm-3.703 4.013c-.974 0-1.907.048-2.77.135-.147.015-.241.168-.183.305.483 1.154 1.622 1.964 2.953 1.964 1.33 0 2.47-.81 2.953-1.964.057-.137-.037-.29-.184-.305-.863-.087-1.795-.135-2.769-.135Z"/></svg>


      </a>
    
      
      
      
      <a
        class="social-share__item"
        href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Frelopezbriega.github.io%2Fblog%2F2015%2F10%2F10%2Fmachine-learning-con-python%2F"
        target="_blank"
        rel="noreferrer"
      >
        
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>


      </a>
    
      
      
      
      <a
        class="social-share__item"
        href="https://x.com/intent/tweet?url=https%3A%2F%2Frelopezbriega.github.io%2Fblog%2F2015%2F10%2F10%2Fmachine-learning-con-python%2F&amp;text=Machine&#43;Learning&#43;con&#43;Python&amp;via=%7buser_id%7d&amp;hashtags=%7bhash_tags%7d"
        target="_blank"
        rel="noreferrer"
      >
        
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>X</title><path d="M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"/></svg>


      </a>
    
  </div>


    

    
  </article>

        </div>
        <div class="sidebar">
  
    
      <aside class="toc">
        <nav>
          <p class="sidebar__heading">Indice</p>
          <nav id="TableOfContents">
  <ul>
    <li><a href="#qué-es-machine-learning">Qué es Machine Learning?</a></li>
    <li><a href="#tipos-de-machine-learning">Tipos de Machine Learning</a>
      <ul>
        <li><a href="#aprendizaje-supervisado">Aprendizaje supervisado</a></li>
        <li><a href="#aprendizaje-no-supervisado">Aprendizaje no supervisado</a></li>
        <li><a href="#aprendizaje-por-refuerzo">Aprendizaje por refuerzo</a></li>
      </ul>
    </li>
    <li><a href="#sobreentrenamiento">Sobreentrenamiento</a>
      <ul>
        <li><a href="#como-evitar-el-sobreentrenamiento">Como evitar el sobreentrenamiento</a></li>
      </ul>
    </li>
    <li><a href="#pasos-para-construir-un-modelo-de-machine-learning">Pasos para construir un modelo de machine learning</a></li>
    <li><a href="#librerías-de-python-para-machine-learning">Librerías de Python para machine learning</a>
      <ul>
        <li><a href="#scikit-learn">Scikit-Learn</a></li>
        <li><a href="#statsmodels">Statsmodels</a></li>
        <li><a href="#pymc">PyMC</a></li>
        <li><a href="#ntlk">NTLK</a></li>
      </ul>
    </li>
    <li><a href="#algoritmos-más-utilizados">Algoritmos más utilizados</a>
      <ul>
        <li><a href="#regresión-lineal">Regresión Lineal</a></li>
        <li><a href="#regresión-logística">Regresión Logística</a></li>
        <li><a href="#arboles-de-decisión">Arboles de decisión</a></li>
        <li><a href="#random-forest">Random Forest</a></li>
        <li><a href="#svm-o-máquinas-de-vectores-de-soporte">SVM o Máquinas de vectores de soporte</a></li>
        <li><a href="#knn-o-k-vecinos-más-cercanos">KNN o k vecinos más cercanos</a></li>
        <li><a href="#k-means">K-means</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </nav>
      </aside>
      <hr />
    
  

  
  
    <aside class="bio">
      

  <div class="jr__item jr-basics__item">
    
  <div class="jr-basics__image">
    <img
      src="https://0.gravatar.com/avatar/45973a2c27d1bafade36a201a13d784ad93ec68fbeb70d7c44c02b4ba6eaeb40?size=256"
      alt="Picture of Raul E. Lopez Briega"
      width="250"
      height="250"
    />
  </div>



    
      <div class="jr-basics__name">Raul E. Lopez Briega</div>
    

    
      <div class="jr-basics__label">Business Analyst</div>
    

    

    

    

    
      <div class="jr-basics__summary">Profesional en Contabilidad y Administración con amplia experiencia en tecnologías de la información. Especializado en integración de procesos contables y financieros con herramientas IT, y manejo de sistemas ERP como JD Edwards y SAP. Reconocido por mi enfoque en la mejora continua, liderazgo en proyectos y compromiso con la excelencia en resultados. Puedo combinar perfectamente el conocimiento contable y financiero con el conocimiento técnico funcional propio de las herramientas informáticas.</div>
    

    
      

      

      
        <div class="jr-basics__location-city">Buenos Aires, ARG</div>
      

      

      
    

    
      <hr />
      <div class="jr-basics__profile jr-basics__profile--col">
        
          

<a href="https://github.com/relopezbriega" target="_blank" rel="noreferrer me">

<div class="jr-basics__profile-item">
  <div class="jr-basics__profile-icon">
    
    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
  </div>

  
    <div class="jr-basics__profile-username">relopezbriega</div>
  
</div>


</a>

        
      </div>
    

    
      <hr />
      <div class="jr-basics__profile jr-basics__profile--row">
        
          

<a href="https://x.com/relopezbriega" target="_blank" rel="noreferrer me">

<div class="jr-basics__profile-item">
  <div class="jr-basics__profile-icon">
    
    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>X</title><path d="M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"/></svg>
  </div>

  
</div>


</a>

        
          

<a href="https://www.linkedin.com/in/relopezbriega" target="_blank" rel="noreferrer me">

<div class="jr-basics__profile-item">
  <div class="jr-basics__profile-icon">
    
    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
  </div>

  
</div>


</a>

        
          

<a href="https://gravatar.com/raulezequiellopezbriega" target="_blank" rel="noreferrer me">

<div class="jr-basics__profile-item">
  <div class="jr-basics__profile-icon">
    
    <svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Gravatar</title><path d="M12 0c-1.326 0-2.4 1.074-2.4 2.4v8.4c0 1.324 1.074 2.398 2.4 2.398s2.4-1.074 2.4-2.398V5.21c2.795.99 4.799 3.654 4.799 6.789 0 3.975-3.225 7.199-7.199 7.199S4.801 15.975 4.801 12c0-1.989.805-3.789 2.108-5.091.938-.938.938-2.458 0-3.396s-2.458-.938-3.396 0C1.344 5.686 0 8.686 0 12c0 6.627 5.373 12 12 12s12-5.373 12-12S18.627 0 12 0"/></svg>
  </div>

  
</div>


</a>

        
      </div>
    
  </div>



      
        <hr />
      
    </aside>
  

  
    <aside>
      


  
  
  
  
  
  


  <div class="tag-cloud">
    
      
      
      
      <a
        href="/tags/algebra"
        style="font-size:1.0137243122648134rem"
        class="tag-cloud__tag"
        >algebra</a
      >
    
      
      
      
      <a
        href="/tags/analisis-de-datos"
        style="font-size:1.8045982461019179rem"
        class="tag-cloud__tag"
        >analisis de datos</a
      >
    
      
      
      
      <a
        href="/tags/batman"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >batman</a
      >
    
      
      
      
      <a
        href="/tags/bayes"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >bayes</a
      >
    
      
      
      
      <a
        href="/tags/binario"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >binario</a
      >
    
      
      
      
      <a
        href="/tags/bit"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >bit</a
      >
    
      
      
      
      <a
        href="/tags/boosting"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >boosting</a
      >
    
      
      
      
      <a
        href="/tags/calculo"
        style="font-size:1.4rem"
        class="tag-cloud__tag"
        >calculo</a
      >
    
      
      
      
      <a
        href="/tags/caos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >caos</a
      >
    
      
      
      
      <a
        href="/tags/causalidad"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >causalidad</a
      >
    
      
      
      
      <a
        href="/tags/ciencia-de-datos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >ciencia de datos</a
      >
    
      
      
      
      <a
        href="/tags/complejidad"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >complejidad</a
      >
    
      
      
      
      <a
        href="/tags/complejos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >complejos</a
      >
    
      
      
      
      <a
        href="/tags/conjuntos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >conjuntos</a
      >
    
      
      
      
      <a
        href="/tags/decimales"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >decimales</a
      >
    
      
      
      
      <a
        href="/tags/deep-learning"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >deep learning</a
      >
    
      
      
      
      <a
        href="/tags/derivada"
        style="font-size:1.1387450204321476rem"
        class="tag-cloud__tag"
        >derivada</a
      >
    
      
      
      
      <a
        href="/tags/derivadas-parciales"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >derivadas parciales</a
      >
    
      
      
      
      <a
        href="/tags/distribuciones"
        style="font-size:1.3524693326969612rem"
        class="tag-cloud__tag"
        >distribuciones</a
      >
    
      
      
      
      <a
        href="/tags/ecuaciones-diferenciales"
        style="font-size:1.1387450204321476rem"
        class="tag-cloud__tag"
        >ecuaciones diferenciales</a
      >
    
      
      
      
      <a
        href="/tags/entropia"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >entropia</a
      >
    
      
      
      
      <a
        href="/tags/estadistica"
        style="font-size:1.6735901846542087rem"
        class="tag-cloud__tag"
        >estadistica</a
      >
    
      
      
      
      <a
        href="/tags/falacias"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >falacias</a
      >
    
      
      
      
      <a
        href="/tags/finanazas"
        style="font-size:1.2274486245296266rem"
        class="tag-cloud__tag"
        >finanazas</a
      >
    
      
      
      
      <a
        href="/tags/fractales"
        style="font-size:1.0137243122648134rem"
        class="tag-cloud__tag"
        >fractales</a
      >
    
      
      
      
      <a
        href="/tags/funcional"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >funcional</a
      >
    
      
      
      
      <a
        href="/tags/futbol"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >futbol</a
      >
    
      
      
      
      <a
        href="/tags/incertidumbre"
        style="font-size:1.2962524852081496rem"
        class="tag-cloud__tag"
        >incertidumbre</a
      >
    
      
      
      
      <a
        href="/tags/inferencia"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >inferencia</a
      >
    
      
      
      
      <a
        href="/tags/infinito"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >infinito</a
      >
    
      
      
      
      <a
        href="/tags/informacion"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >informacion</a
      >
    
      
      
      
      <a
        href="/tags/integral"
        style="font-size:1.1387450204321476rem"
        class="tag-cloud__tag"
        >integral</a
      >
    
      
      
      
      <a
        href="/tags/inteligencia"
        style="font-size:1.1387450204321476rem"
        class="tag-cloud__tag"
        >inteligencia</a
      >
    
      
      
      
      <a
        href="/tags/inteligencia-artificial"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >inteligencia artificial</a
      >
    
      
      
      
      <a
        href="/tags/jd-edwards"
        style="font-size:1.0137243122648134rem"
        class="tag-cloud__tag"
        >jd edwards</a
      >
    
      
      
      
      <a
        href="/tags/juliana"
        style="font-size:1.0137243122648134rem"
        class="tag-cloud__tag"
        >juliana</a
      >
    
      
      
      
      <a
        href="/tags/lenguaje-natural"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >lenguaje natural</a
      >
    
      
      
      
      <a
        href="/tags/limite"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >limite</a
      >
    
      
      
      
      <a
        href="/tags/limites"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >limites</a
      >
    
      
      
      
      <a
        href="/tags/logaritmo"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >logaritmo</a
      >
    
      
      
      
      <a
        href="/tags/logica"
        style="font-size:1.0137243122648134rem"
        class="tag-cloud__tag"
        >logica</a
      >
    
      
      
      
      <a
        href="/tags/machine-learning"
        style="font-size:1.7237011097377763rem"
        class="tag-cloud__tag"
        >machine learning</a
      >
    
      
      
      
      <a
        href="/tags/map-reduce"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >map-reduce</a
      >
    
      
      
      
      <a
        href="/tags/matematica"
        style="font-size:1.7667951680455587rem"
        class="tag-cloud__tag"
        >matematica</a
      >
    
      
      
      
      <a
        href="/tags/matplotlib"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >matplotlib</a
      >
    
      
      
      
      <a
        href="/tags/matrices"
        style="font-size:1.0137243122648134rem"
        class="tag-cloud__tag"
        >matrices</a
      >
    
      
      
      
      <a
        href="/tags/mcmc"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >mcmc</a
      >
    
      
      
      
      <a
        href="/tags/metropolis"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >metropolis</a
      >
    
      
      
      
      <a
        href="/tags/modelos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >modelos</a
      >
    
      
      
      
      <a
        href="/tags/monte-carlo"
        style="font-size:1.0137243122648134rem"
        class="tag-cloud__tag"
        >monte carlo</a
      >
    
      
      
      
      <a
        href="/tags/numeros"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >numeros</a
      >
    
      
      
      
      <a
        href="/tags/optimizacion"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >optimizacion</a
      >
    
      
      
      
      <a
        href="/tags/overfitting"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >overfitting</a
      >
    
      
      
      
      <a
        href="/tags/pensamiento"
        style="font-size:1.1387450204321476rem"
        class="tag-cloud__tag"
        >pensamiento</a
      >
    
      
      
      
      <a
        href="/tags/pi"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >pi</a
      >
    
      
      
      
      <a
        href="/tags/probabilidad"
        style="font-size:1.4774900408642955rem"
        class="tag-cloud__tag"
        >probabilidad</a
      >
    
      
      
      
      <a
        href="/tags/programacion"
        style="font-size:1.8382686471791738rem"
        class="tag-cloud__tag"
        >programacion</a
      >
    
      
      
      
      <a
        href="/tags/programacion-lineal"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >programacion lineal</a
      >
    
      
      
      
      <a
        href="/tags/python"
        style="font-size:1.9936422694914009rem"
        class="tag-cloud__tag"
        >python</a
      >
    
      
      
      
      <a
        href="/tags/redes-neuronales"
        style="font-size:1.4rem"
        class="tag-cloud__tag"
        >redes neuronales</a
      >
    
      
      
      
      <a
        href="/tags/redundancia"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >redundancia</a
      >
    
      
      
      
      <a
        href="/tags/regex"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >regex</a
      >
    
      
      
      
      <a
        href="/tags/seaborn"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >seaborn</a
      >
    
      
      
      
      <a
        href="/tags/series-de-tiempo"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >series de tiempo</a
      >
    
      
      
      
      <a
        href="/tags/sistemas-dinamicos"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >sistemas dinamicos</a
      >
    
      
      
      
      <a
        href="/tags/sobreajuste"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >sobreajuste</a
      >
    
      
      
      
      <a
        href="/tags/tensores"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >tensores</a
      >
    
      
      
      
      <a
        href="/tags/tensorflow"
        style="font-size:1.1387450204321476rem"
        class="tag-cloud__tag"
        >tensorflow</a
      >
    
      
      
      
      <a
        href="/tags/vectores"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >vectores</a
      >
    
      
      
      
      <a
        href="/tags/visualizaciones"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >visualizaciones</a
      >
    
      
      
      
      <a
        href="/tags/xgboost"
        style="font-size:0.8rem"
        class="tag-cloud__tag"
        >xgboost</a
      >
    
  </div>


    </aside>
  
</div>

      </main>
      <footer>
  <div class="copyright">
    
  </div>
</footer>



  







  
  



<script src="/js/main.cd7795d28b80ce821160de11b7556c4da5149179a3ec7f243e3a53d453b1e1fb7f7d82a21dccd3723d92e160b4a7197e900c7ed135ae3ae33bafcec5c05a05bb.js" integrity="sha512-zXeV0ouAzoIRYN4Rt1VsTaUUkXmj7H8kPjpT1FOx4ft/fYKiHczTcj2S4WC0pxl&#43;kAx&#43;0TWuOuM7r87FwFoFuw=="></script>
<script src="/js/flexsearch.1ab5b109bf2ed66903ae10907394415caa12f5c0ee66bc80088ba135ec4a751f62e4961d6a7303b562e4db724392da85945b763b8e1858ea3fd05cc36f9b8156.js" integrity="sha512-GrWxCb8u1mkDrhCQc5RBXKoS9cDuZryACIuhNexKdR9i5JYdanMDtWLk23JDktqFlFt2O44YWOo/0FzDb5uBVg=="></script>






    </div>
  </body>
</html>
